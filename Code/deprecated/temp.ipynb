{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import find\n",
    "import scipy.sparse\n",
    "import graph_tool.all as gt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/tweets_lite.gzip', compression='gzip')\n",
    "print('Shape:', tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function which returns a Boolean specifying if matrix is Non Zero\n",
    "def is_matrix_nonzero(matrix):\n",
    "    return len(matrix.nonzero()[0]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Date'] = pd.to_datetime(tweets['Date'], errors = 'coerce')\n",
    "\n",
    "# List of Twitter users\n",
    "users = np.unique(tweets[['Author ID']].values)\n",
    "print(f\"there are some nan's values. Proof: {users[-1]} at -1\" )\n",
    "users = users[:-1]\n",
    "users = [ int(x) for x in users ]\n",
    "\n",
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date1 = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "v2_start = '2021-04-30 23:59:59'\n",
    "v2_end = '2021-06-29 23:59:59'\n",
    "date2 = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "user_indices = {user: idx for idx, user in enumerate(users)}\n",
    "datestr = list(date2.strftime(\"%d-%m-%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save this file for further usage\n",
    "with open('../../../Data/Pickle/user_indices.pkl', 'wb') as file:\n",
    "    pickle.dump(user_indices, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../Data/Pickle/user_to_party_paro.pkl', 'rb') as file:\n",
    "    user_to_party_paro = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this _for loop_ we create the adjacency matrix for constructing the graph.\n",
    "\n",
    "Each cell _RT<sub>i,j</sub>_ is the amount of Tweets the _i_ user Retweeted from the _j_ user.\n",
    "\n",
    "This process is done for all the tweets done in intervals of 3 days during the Paro Nacional.\n",
    "\n",
    "The Adjacency Matrix will be stored in the Matrices folder of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "os.chdir('../../../Data/Matrices/')\n",
    "for start_date, end_date in tqdm(zip(date1, date2)):\n",
    "    # get tweets by current day between start_date and end_date\n",
    "    test = tweets[(tweets['Date'] >= start_date) & (tweets['Date'] <= end_date)]\n",
    "\n",
    "    # 'rts' dataframe contains the Author ID and the Referenced Author ID in the \n",
    "    # timeframe we are interested.\n",
    "    rts = test.loc[(test[\"Reference Type\"] == \"retweeted\") & (test[\"Referenced Tweet Author ID\"].isin(users)),\n",
    "                                                    [\"Author ID\", \"Referenced Tweet Author ID\"]]\n",
    "\n",
    "    # We rename the 'rts' dataframe columns for code easyness now.\n",
    "    new_column_names = {'Author ID':'user1', 'Referenced Tweet Author ID':'user2'}\n",
    "    rts = rts.rename(columns = new_column_names)\n",
    "    \n",
    "    # Because of the data structure, we use a sparse matrix.\n",
    "    A = sp.csr_matrix((len(users), len(users)), dtype = int)\n",
    "    lil = lil_matrix(A.shape)\n",
    "\n",
    "    for row in rts.itertuples(index = False):\n",
    "        user1, user2 = row.user1, row.user2\n",
    "    \n",
    "        idx_user1 = user_indices[user1]\n",
    "        idx_user2 = user_indices[user2]\n",
    "\n",
    "        lil[idx_user1, idx_user2] += 1\n",
    "        lil[idx_user2, idx_user1] += 1\n",
    "\n",
    "    if is_matrix_nonzero(lil):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Matrix is zero\")\n",
    "    \n",
    "    # This matrices are sparse. Therefore, we save it as such.\n",
    "    A = lil.tocsr()\n",
    "    filename = f'adj_end_of_{datestr[k]}.csr'\n",
    "    sp.save_npz(filename, A, compressed = False)\n",
    "    k += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
