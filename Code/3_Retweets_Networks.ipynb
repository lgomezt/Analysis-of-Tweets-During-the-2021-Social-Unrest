{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we create a daily retweet network. First, we transform our dataset into a Source-Target DataFrame. Afterward, we construct a `graph-tool` object.\n",
    "\n",
    "We have 45,330,718 Tweets from 37330 from which 30,918,011 are ReTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import graph_tool.all as gt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/3_Day_Graphs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas (Tweets): 45,330,718. Cantidad de Columns: 4\n",
      "Total usuarios: 5,759,089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:37:59</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.419439e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:37:16</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>8.628063e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:31:36</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.402301e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:30:41</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>3.824198e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:29:39</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.483430e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author ID                 Date Reference Type  \\\n",
       "0  9.180596e+17  2021/06/29 23:37:59      retweeted   \n",
       "1  9.180596e+17  2021/06/29 23:37:16      retweeted   \n",
       "2  9.180596e+17  2021/06/29 23:31:36      retweeted   \n",
       "3  9.180596e+17  2021/06/29 23:30:41      retweeted   \n",
       "4  9.180596e+17  2021/06/29 23:29:39      retweeted   \n",
       "\n",
       "   Referenced Tweet Author ID  \n",
       "0                1.419439e+08  \n",
       "1                8.628063e+17  \n",
       "2                1.402301e+18  \n",
       "3                3.824198e+08  \n",
       "4                1.483430e+07  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_pickle('../../../Data/Tweets_DataFrames/tweets_lite.gzip', compression='gzip')\n",
    "print(f'Cantidad de filas (Tweets): {tweets.shape[0]:,}. Cantidad de Columns: {tweets.shape[1]:,}')\n",
    "print('Total usuarios: ' + f\"{len(set(tweets['Author ID']).union(set(tweets['Referenced Tweet Author ID']))):,}\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 30,918,011 Retweets y 624,358 Usario con Rts o Retwiteados\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>373097280.0</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>411495598.0</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>411495598.0</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94589151.0</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36158466.0</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author ID        Date  Referenced Tweet Author ID\n",
       "0  373097280.0  2021-06-09                        12.0\n",
       "1  411495598.0  2021-06-10                        12.0\n",
       "2  411495598.0  2021-06-10                        12.0\n",
       "3   94589151.0  2021-06-04                        12.0\n",
       "4   36158466.0  2021-06-04                        12.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will just get the Retweets\n",
    "retweets_total = tweets[tweets['Reference Type'] == 'retweeted']\n",
    "retweets_total = retweets_total.drop(columns=['Reference Type'])\n",
    "retweets_total[\"Date\"] = pd.to_datetime(retweets_total[\"Date\"]).dt.date\n",
    "retweets_total = retweets_total.sort_values('Referenced Tweet Author ID').reset_index(drop = True)\n",
    "\n",
    "users = set(retweets_total['Author ID']).union(set(retweets_total['Referenced Tweet Author ID']))\n",
    "print(f'Tenemos: {retweets_total.shape[0]:,} Retweets y {len(users):,} Usario con Rts o Retwiteados')\n",
    "#del tweets, users\n",
    "# This will be our Sorce-Target List. Will include the weights of each tweets\n",
    "retweets_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faltan clasificar 587,246 usuarios\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Political Affiliation\n",
       "NaN                   587246\n",
       "Retweets Izquierda     23138\n",
       "Retweets Derecha        6812\n",
       "No Retweets             3844\n",
       "Retweets Centro         3543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"../../../Data/Pickle/user_to_party_paro.pkl\")\n",
    "\n",
    "ids_faltantes1 = set(retweets_total[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(retweets_total[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(np.unique(ids_faltantes)):,} usuarios\")\n",
    "\n",
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan\n",
    "\n",
    "affilliation_df = pd.DataFrame(list(user_to_party_paro.items()), columns=['User ID', 'Political Affiliation'])\n",
    "affilliation_df['Political Affiliation'].value_counts(dropna=False)\n",
    "#del affilliation_df,ids_faltantes, ids_faltantes1, ids_faltantes2, usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37339</th>\n",
       "      <td>1.389722e+18</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>1.389737e+18</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Retweets Derecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37341</th>\n",
       "      <td>1.389741e+18</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37342</th>\n",
       "      <td>1.389769e+18</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>1.389784e+18</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID           Label Political Affiliation\n",
       "0      0.000000e+00               0           No Retweets\n",
       "1      1.000000e+00               0           No Retweets\n",
       "2      2.000000e+00               0           No Retweets\n",
       "3      3.000000e+00               0           No Retweets\n",
       "5      4.000000e+00               0           No Retweets\n",
       "...             ...             ...                   ...\n",
       "37339  1.389722e+18  Neoplasticista    Retweets Izquierda\n",
       "37340  1.389737e+18      JC13177979      Retweets Derecha\n",
       "37341  1.389741e+18   JhonatanVRojo           No Retweets\n",
       "37342  1.389769e+18       VaneLen18    Retweets Izquierda\n",
       "37343  1.389784e+18        kars0518    Retweets Izquierda\n",
       "\n",
       "[37337 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos master ids para filtrar\n",
    "# Bring Master ID file\n",
    "users_information = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/users_information.gzip', compression='gzip')\n",
    "master_id = users_information.reset_index()[['Author ID', 'Author Name']]\n",
    "master_id = master_id.rename(columns={\n",
    "    'Author ID': 'ID',\n",
    "    'Author Name': 'Label'\n",
    "})\n",
    "master_id['Political Affiliation'] = master_id['ID'].apply(lambda x: user_to_party_paro[x])\n",
    "master_id = master_id.drop_duplicates(subset = 'ID')\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas (Tweets): 13,784,608. Cantidad de Columns: 7\n",
      "Tenemos: 13,784,608 Retweets y 36,964 Usuarios con Rts o Retwiteados\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12996</td>\n",
       "      <td>alerios</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>777978</td>\n",
       "      <td>ranaberden</td>\n",
       "      <td>Retweets Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>784125</td>\n",
       "      <td>jsanti</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1061601</td>\n",
       "      <td>thisgoblin</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37339</th>\n",
       "      <td>1389721694961651712</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>1389737202742071296</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Retweets Derecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37341</th>\n",
       "      <td>1389741234370064384</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37342</th>\n",
       "      <td>1389769251704147968</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>1389784145417678848</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Retweets Izquierda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID           Label Political Affiliation\n",
       "14                      12               0           No Retweets\n",
       "36                   12996         alerios    Retweets Izquierda\n",
       "37                  777978      ranaberden       Retweets Centro\n",
       "38                  784125          jsanti    Retweets Izquierda\n",
       "39                 1061601      thisgoblin    Retweets Izquierda\n",
       "...                    ...             ...                   ...\n",
       "37339  1389721694961651712  Neoplasticista    Retweets Izquierda\n",
       "37340  1389737202742071296      JC13177979      Retweets Derecha\n",
       "37341  1389741234370064384   JhonatanVRojo           No Retweets\n",
       "37342  1389769251704147968       VaneLen18    Retweets Izquierda\n",
       "37343  1389784145417678848        kars0518    Retweets Izquierda\n",
       "\n",
       "[36964 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Source Labels\n",
    "temp = retweets_total.merge(master_id, how = 'inner', left_on = 'Author ID', right_on='ID')\n",
    "temp = temp.rename(columns = {'Label': 'Source Label', 'Political Affiliation': 'Source PA'}).drop(columns='ID')\n",
    "\n",
    "# Adding Target Labels\n",
    "retweets = temp.merge(master_id, how = 'inner', left_on = 'Referenced Tweet Author ID', right_on='ID')\n",
    "retweets = retweets.rename(columns = {'Label': 'Target Label', 'Political Affiliation': 'Target PA'})\n",
    "retweets = retweets.drop(columns= 'ID')\n",
    "\n",
    "# Count how many tweets and users we have now\n",
    "users = list(set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID'])))\n",
    "print(f'Cantidad de filas (Tweets): {retweets.shape[0]:,}. Cantidad de Columns: {retweets.shape[1]:,}')\n",
    "print(f'Tenemos: {retweets.shape[0]:,} Retweets y {len(users):,} Usuarios con Rts o Retwiteados')\n",
    "\n",
    "# Save this Dataframe for Nodes List\n",
    "master_id = master_id[master_id['ID'].isin(users)] # Filter in Retweets DataFrame\n",
    "master_id = master_id.astype({\n",
    "    'ID': int,\n",
    "    'Label': str,\n",
    "    'Political Affiliation': str\n",
    "})\n",
    "master_id.to_csv(os.path.join(save_path, 'Nodes' + \".csv\"), index = False, sep = \";\")\n",
    "\n",
    "# Save label in a dict for quick lookup\n",
    "ID_Label = master_id.set_index('ID').to_dict()['Label']\n",
    "ID_Label = {int(key): value for key, value in ID_Label.items()}\n",
    "\n",
    "#del temp, retweets_total, users\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos Retweeteados por alguien pero que no Retweetean: 6,510\n",
      "Nodos que Retweetean a alguien pero no son Retweeteados: 833\n",
      "Nodos que tienen un self loop: 7\n",
      "primer nodo: 12.0 último nodo: 1.3897841454176788e+18\n",
      "Total de nodos en la muestra: 36,964\n"
     ]
    }
   ],
   "source": [
    "nodes_no_receipt = set(retweets[\"Author ID\"]) -  set(retweets[\"Referenced Tweet Author ID\"])\n",
    "nodes_no_send = set(retweets[\"Referenced Tweet Author ID\"]) - set(retweets[\"Author ID\"])\n",
    "self_loops = set(retweets[retweets['Author ID'] == retweets['Referenced Tweet Author ID']])\n",
    "\n",
    "print(f'Nodos Retweeteados por alguien pero que no Retweetean: {len(nodes_no_receipt):,}')\n",
    "print(f'Nodos que Retweetean a alguien pero no son Retweeteados: {len(nodes_no_send):,}')\n",
    "print(f'Nodos que tienen un self loop: {len(self_loops)}')\n",
    "\n",
    "print(f'primer nodo: {min(users)} último nodo: {max(users)}')\n",
    "print(f'Total de nodos en la muestra: {len(users):,}')\n",
    "\n",
    "del nodes_no_receipt, nodes_no_send, self_loops, users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date_start = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "del v1_end, v1_start\n",
    "\n",
    "v2_start = '2021-05-01 23:59:59'\n",
    "v2_end = '2021-06-30 23:59:59'\n",
    "date_end = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "del v2_start, v2_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [06:31,  6.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Runtime 7 minutes!!!!!\n",
    "for d_s, d_e in tqdm(zip(date_start, date_end)):\n",
    "    # Get 3 days Retweets\n",
    "    window = retweets[(retweets['Date'] >= d_s.date()) & (retweets['Date'] < d_e.date())] \n",
    "\n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window.groupby('Author ID').size().reset_index(name = 'total')\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number of rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal weight'] = temp['number of rts']/temp['total']\n",
    "    temp['normal weight'] = temp['normal weight'].round(3)\n",
    "    temp.columns = [\"source\", \"target\", \"number of rts\", \"total\", \"normal weight\"]\n",
    "\n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "\n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['source'].apply(lambda x: ID_Label[x])\n",
    "    temp['target_label'] = temp['target'].apply(lambda x: ID_Label[x])\n",
    "\n",
    "    # Add ending date\n",
    "    temp['ending_date'] = d_e.date()\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'source': int,\n",
    "        'target': int,\n",
    "        'number of rts': int,\n",
    "        'total': int,\n",
    "        'normal weight': float\n",
    "    })\n",
    "        \n",
    "    # Save results as csv (1 min. each aprox)\n",
    "    temp.to_csv(os.path.join(save_path, \"Source_Target\", str(d_e.date()) + \".csv\"), index = False, sep = \";\")\n",
    "\n",
    "del d_s, d_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Numero de Arcos: 466,447. Nodos Source: 28,403. Nodos Target 12,584\n"
     ]
    }
   ],
   "source": [
    "# Example of our lists\n",
    "ej_csv = pd.read_csv(save_path + '/Source_Target/2021-05-01.csv', sep = ';')\n",
    "ej_csv.dropna(inplace=True)\n",
    "print(f\" Numero de Arcos: {ej_csv.shape[0]:,}. Nodos Source: {len(ej_csv.source.unique()):,}. Nodos Target {len(ej_csv.target.unique()):,}\")\n",
    "ej_csv.source = ej_csv.source.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partir_y_consultar(lista,k):\n",
    "    import math\n",
    "    concat = []\n",
    "\n",
    "    N = len(lista)\n",
    "    parte = math.floor(N/k)\n",
    "    slices = [i for i in range(0,N+1,parte)]\n",
    "    for i in range(len(slices)-1):\n",
    "        if slices[i+1] == slices[-1]:\n",
    "            sub = lista[slices[i]:]\n",
    "        else:\n",
    "            sub = lista[slices[i]:slices[i+1]]\n",
    "        concat.append(sub)\n",
    "        \n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASE 1 CHECK\n",
      "FASE 2 CHECK\n",
      "FASE 3.1 CHECK\n",
      "FASE 3.2 CHECK\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create Graph\n",
    "files = glob.glob('../../../Data/3_Day_Graphs/Source_Target/*.csv')\n",
    "\n",
    "# Open dict for any case\n",
    "with open('/mnt/disk2/Data/3_Day_Graphs/nodes_dict.pkl', 'rb') as file:\n",
    "    nodes_dict = pickle.load(file)\n",
    "\n",
    "for file in tqdm(files):\n",
    "    # Read Graph\n",
    "    date = file.split('/')[-1].split('.')[0]\n",
    "    temp = pd.read_csv(file, sep = ';')\n",
    "    print('FASE 1 CHECK')\n",
    "    # Initialice Directed Graph\n",
    "    g = gt.Graph(directed = True)\n",
    "    print('FASE 2 CHECK')\n",
    "    # Create Source Target Partition\n",
    "    source_target = [row for row in temp[['source','target']].itertuples(name = None, index=False)]\n",
    "    print('FASE 3.1 CHECK')\n",
    "    partition = partir_y_consultar(source_target, 200000)\n",
    "    print('FASE 3.2 CHECK')\n",
    "    del source_target\n",
    "    \n",
    "    x = 1\n",
    "    n = 0\n",
    "    # Add source Target by peaces\n",
    "    for i in partition:\n",
    "        if x % 10000 == 0:\n",
    "            print(f'Empieza iteración {x:,}')\n",
    "            g.add_edge_list(i)\n",
    "            print(f\"Termina iteración {x:,}\")\n",
    "        else:\n",
    "            g.add_edge_list(i)\n",
    "        x+=1\n",
    "\n",
    "    del i,x,partition\n",
    "    \n",
    "    print('FASE 3.3 CHECK')\n",
    "    # Create an edge property map for weights\n",
    "    edge_weight_map = g.new_edge_property(\"double\")\n",
    "\n",
    "    # Create a Vertex property map for labels\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "\n",
    "    # Assign weights to the edges using a for loop\n",
    "    edge_list = g.get_edges()\n",
    "    weights = list(temp['normal weight'])\n",
    "\n",
    "    for i, e in enumerate(edge_list):\n",
    "        #print(f'Property of {e} is {weights[i]}. Type of Edge: {type(e)}')\n",
    "        edge_weight_map[e] = weights[i]\n",
    "    \n",
    "    del edge_list, weights\n",
    "\n",
    "    # Assign Labels to vertices using loop\n",
    "    vertex_list = g.get_vertices()\n",
    "    labels = nodes_dict['pa']\n",
    "    for i,v in enumerate(vertex_list):\n",
    "        print(i,v)\n",
    "        print(f'Property of {v} is {labels[i]}. Type of Edge: {type(v)}')\n",
    "        label_of_v = nodes_dict['id'].index[v]\n",
    "        vertex_label_map[v] = labels[label_of_v]\n",
    "    \n",
    "    del vertex_list, labels\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_label_map\n",
    "    g.ep['Normal Weights'] = edge_weight_map\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(save_path, date + \".graphml\")\n",
    "    g.save(filename)\n",
    "    print(f\"Successfully Saved file {filename} SIIIIIUUUUU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(save_path + f'/{str(date_end[0].date())}.graphml')\n",
    "ej_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_paro = glob.glob('/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_*')\n",
    "tweets_paro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tweets from Paro but select only the retweets\n",
    "retweets = pd.DataFrame()\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets = pd.read_pickle(file, compression = \"gzip\")\n",
    "\n",
    "    # Select only retweets\n",
    "    rts = tweets.loc[tweets[\"Reference Type\"] == \"retweeted\",:].reset_index(drop = True)\n",
    "    rts = rts.drop(columns = 'Reference Type')\n",
    "    retweets = pd.concat([retweets, rts], axis = 0)\n",
    "retweets = retweets.reset_index(drop = True)\n",
    "del rts, tweets \n",
    "print('Shape:', retweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types\n",
    "retweets[\"ID\"] = retweets[\"ID\"].astype(int)\n",
    "retweets[\"Author ID\"] = retweets[\"Author ID\"].astype(int)\n",
    "retweets['Referenced Tweet Author ID'] = retweets['Referenced Tweet Author ID'].astype(int)\n",
    "retweets['Referenced Tweet'] = retweets['Referenced Tweet'].astype(int)\n",
    "\n",
    "# Remove time from retweets date\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"/mnt/disk2/Data/Pickle/user_to_party_paro.pkl\")\n",
    "\n",
    "ids_faltantes1 = set(retweets[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(retweets[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(np.unique(ids_faltantes))} usuarios\")\n",
    "\n",
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_min = retweets[\"Date\"].min()\n",
    "fecha_max = retweets[\"Date\"].max()\n",
    "print(f\"We have retweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = pd.read_pickle(\"../../../Data/Tweets_DataFrames/users_information.gzip\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Referenced Tweet Author\n",
    "retweets = users_information.reset_index()[[\"Author ID\", \"Author Name\"]] \\\n",
    "    .rename(columns = {\"Author ID\": \"Referenced Tweet Author ID\", \n",
    "                       \"Author Name\": \"Referenced Tweet Author Name\"}) \\\n",
    "                       .merge(retweets, how = \"right\", on = \"Referenced Tweet Author ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users without name\n",
    "retweets.iloc[:, 0:2].drop_duplicates().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(daily_grid):\n",
    "    # Select the retweets from the desired date\n",
    "    temp = retweets[retweets['Date'] == d.date()]\n",
    "    temp = temp.groupby([\"Author ID\", \"Author Name\", \"Date\", \"Referenced Tweet Author ID\", \"Referenced Tweet Author Name\"]).size().reset_index(name = \"w\")\n",
    "    temp.columns = [\"source\", \"source_label\", \"date\", \"target\", \"target_label\", \"w\"]\n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target\"].apply(lambda x: user_to_party_paro[x])\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source-Target\", str(d.date()) + \".csv\"), index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node list\n",
    "nodes_id = list(set(retweets[\"Author ID\"]).union(set(retweets[\"Referenced Tweet Author ID\"])))\n",
    "len(nodes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = users_information.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert users_information DataFrame to a dictionary for fast lookup\n",
    "users_info_dict = users_information.set_index('Author ID')['Author Name'].to_dict()\n",
    "\n",
    "nodes_label = []\n",
    "nodes_political_affilitation = []\n",
    "for i in tqdm(nodes_id):\n",
    "    # Assign label\n",
    "    label = users_info_dict.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_label.append(label)\n",
    "\n",
    "    # Assign Political Affiliation\n",
    "    pa = user_to_party_paro.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_political_affilitation.append(pa)\n",
    "\n",
    "num_nodes = len(nodes_id)\n",
    "nodes_idx = [i for i in range(num_nodes)]\n",
    "\n",
    "# Create dictionary\n",
    "nodes_dict = {\n",
    "    'id': nodes_id,\n",
    "    'idx': nodes_idx,\n",
    "    'label': nodes_label,\n",
    "    'pa': nodes_political_affilitation\n",
    "}\n",
    "\n",
    "# Save as pickle\n",
    "with open(\"../../../Data/Daily_graphs/nodes_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nodes_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for O(1) lookup time of indices\n",
    "id_to_idx = {node_id: idx for idx, node_id in enumerate(nodes_dict['id'])}\n",
    "\n",
    "for d in tqdm(daily_grid):\n",
    "    # Filter retweets first\n",
    "    filtered_retweets = retweets[retweets['Date'] == d.date()]\n",
    "    \n",
    "    # Create weights\n",
    "    test = filtered_retweets.groupby(['Author ID', 'Referenced Tweet Author ID']).size().reset_index(name=\"w\")\n",
    "    \n",
    "    # Use dictionary lookups for index mappings\n",
    "    test['idx_s'] = [id_to_idx.get(x, np.nan) for x in test['Author ID']]\n",
    "    test['idx_t'] = [id_to_idx.get(x, np.nan) for x in test['Referenced Tweet Author ID']]\n",
    "    \n",
    "    # The edge list should be based on the idx of the nodes and include weights\n",
    "    edges_list_with_weights = list(zip(test['idx_s'].dropna().astype(int), test['idx_t'].dropna().astype(int), test['w']))\n",
    "    \n",
    "    # Create graph\n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(num_nodes)\n",
    "    \n",
    "    # Node attributes\n",
    "    node_id = g.new_vertex_property(\"string\", vals=nodes_dict['id'])\n",
    "    node_label = g.new_vertex_property(\"string\", vals=nodes_dict['label'])\n",
    "    node_affiliation = g.new_vertex_property(\"string\", vals=nodes_dict['pa'])\n",
    "    \n",
    "    # Assign attributes to graph\n",
    "    g.vertex_properties[\"ID\"] = node_id\n",
    "    g.vertex_properties[\"Label\"] = node_label\n",
    "    g.vertex_properties[\"Political Affiliation\"] = node_affiliation\n",
    "    \n",
    "    # Edge weight attribute\n",
    "    edge_weights = g.new_edge_property(\"int\")\n",
    "    \n",
    "    # Add edges and assign weights\n",
    "    for source, target, weight in edges_list_with_weights:\n",
    "        e = g.add_edge(source, target)\n",
    "        edge_weights[e] = weight\n",
    "\n",
    "    g.edge_properties[\"weight\"] = edge_weights\n",
    "    \n",
    "    g.save(os.path.join(save_path, str(d.date()) + \".graphml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g)\n",
    "print(g.vp[\"ID\"][624353])\n",
    "print(g.vp[\"Label\"][624353])\n",
    "print(g.vp[\"Political Affiliation\"][624353])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
