{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets Networks\n",
    "\n",
    "In this notebook, we create a daily retweet network. First, we transform our dataset into a Source-Target DataFrame. Afterward, we construct a `graph-tool` object.\n",
    "\n",
    "We have 45,330,718 Tweets from 37330 from which 30,918,011 are ReTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/anaconda3/envs/gt_global/lib/python3.11/site-packages/graph_tool/draw/cairo_draw.py:1544: RuntimeWarning: Error importing Gtk module: ; GTK+ drawing will not work.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Mathematical and Data Managment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Graph Managment\n",
    "import graph_tool.all as gt\n",
    "from utils.Bojanowski import *\n",
    "\n",
    "# Miscellaneous\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/3_Day_Graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Retweets\n",
    "retweets = pd.read_pickle('../../../Data/Tweets_DataFrames/retweets_lite.gzip', compression='gzip')\n",
    "\n",
    "retweets = retweets.astype({\n",
    "    'Author ID': float,\n",
    "    'Referenced Tweet Author ID': float\n",
    "})\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"], errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faltan clasificar 587,246 usuarios\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Political Affiliation\n",
       "NaN               587246\n",
       "Izquierda          23138\n",
       "Derecha             6812\n",
       "Sin Clasificar      3844\n",
       "Centro              3543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"../../../Data/Pickle/user_to_party_paro.pkl\")\n",
    "\n",
    "ids_faltantes1 = set(retweets[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(retweets[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(np.unique(ids_faltantes)):,} usuarios\")\n",
    "\n",
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan\n",
    "\n",
    "affilliation_df = pd.DataFrame(list(user_to_party_paro.items()), columns=['User ID', 'Political Affiliation'])\n",
    "affilliation_df['Political Affiliation'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated IDs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37339</th>\n",
       "      <td>1.389722e+18</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>1.389737e+18</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37341</th>\n",
       "      <td>1.389741e+18</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37342</th>\n",
       "      <td>1.389769e+18</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>1.389784e+18</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            User ID           Label Political Affiliation\n",
       "0      0.000000e+00               0        Sin Clasificar\n",
       "1      1.000000e+00               0        Sin Clasificar\n",
       "2      2.000000e+00               0        Sin Clasificar\n",
       "3      3.000000e+00               0        Sin Clasificar\n",
       "5      4.000000e+00               0        Sin Clasificar\n",
       "...             ...             ...                   ...\n",
       "37339  1.389722e+18  Neoplasticista             Izquierda\n",
       "37340  1.389737e+18      JC13177979               Derecha\n",
       "37341  1.389741e+18   JhonatanVRojo        Sin Clasificar\n",
       "37342  1.389769e+18       VaneLen18             Izquierda\n",
       "37343  1.389784e+18        kars0518             Izquierda\n",
       "\n",
       "[37337 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Master Id\n",
    "#del affilliation_df,ids_faltantes, ids_faltantes1, ids_faltantes2, usuario\n",
    "users_information = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/users_information.gzip', compression='gzip')\n",
    "master_id = users_information.reset_index()[['Author ID', 'Author Name']]\n",
    "master_id = master_id.rename(columns={\n",
    "    'Author ID': 'User ID',\n",
    "    'Author Name': 'Label'\n",
    "})\n",
    "del users_information\n",
    "master_id['Political Affiliation'] = master_id['User ID'].apply(lambda x: user_to_party_paro[x])\n",
    "print(f\"Duplicated IDs: {sum(master_id.duplicated(subset = 'User ID'))}\")\n",
    "master_id = master_id.drop_duplicates(subset = 'User ID')\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13784608, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Referenced Tweet Author Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Source Label</th>\n",
       "      <th>Source PA</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.407536e+18</td>\n",
       "      <td>7.882507e+08</td>\n",
       "      <td>Laura_Milena98</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>1.407204e+18</td>\n",
       "      <td>Laura_Milena98</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.393521e+18</td>\n",
       "      <td>1.265236e+08</td>\n",
       "      <td>sandrapulga</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>2021-05-15</td>\n",
       "      <td>1.393368e+18</td>\n",
       "      <td>sandrapulga</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.404837e+18</td>\n",
       "      <td>8.996701e+17</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>1.404697e+18</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.402071e+18</td>\n",
       "      <td>8.996701e+17</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>1.401913e+18</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.391067e+18</td>\n",
       "      <td>8.996701e+17</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>1.391020e+18</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID     Author ID     Author Name  Referenced Tweet Author ID  \\\n",
       "0  1.407536e+18  7.882507e+08  Laura_Milena98                 270668814.0   \n",
       "1  1.393521e+18  1.265236e+08     sandrapulga                 270668814.0   \n",
       "2  1.404837e+18  8.996701e+17        rchicave                 270668814.0   \n",
       "3  1.402071e+18  8.996701e+17        rchicave                 270668814.0   \n",
       "4  1.391067e+18  8.996701e+17        rchicave                 270668814.0   \n",
       "\n",
       "  Referenced Tweet Author Name        Date  Referenced Tweet    Source Label  \\\n",
       "0                gabocifuentes  2021-06-22      1.407204e+18  Laura_Milena98   \n",
       "1                gabocifuentes  2021-05-15      1.393368e+18     sandrapulga   \n",
       "2                gabocifuentes  2021-06-15      1.404697e+18        rchicave   \n",
       "3                gabocifuentes  2021-06-07      1.401913e+18        rchicave   \n",
       "4                gabocifuentes  2021-05-08      1.391020e+18        rchicave   \n",
       "\n",
       "   Source PA   Target Label Target PA  \n",
       "0  Izquierda  gabocifuentes    Centro  \n",
       "1  Izquierda  gabocifuentes    Centro  \n",
       "2  Izquierda  gabocifuentes    Centro  \n",
       "3  Izquierda  gabocifuentes    Centro  \n",
       "4  Izquierda  gabocifuentes    Centro  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Source Labels\n",
    "temp = retweets.merge(master_id, how = 'inner', left_on = 'Author ID', right_on='User ID', validate = 'm:1')\n",
    "temp = temp.rename(columns = {'Label': 'Source Label', 'Political Affiliation': 'Source PA'}).drop(columns=['User ID'])\n",
    "\n",
    "# Adding Target Labels\n",
    "retweets = temp.merge(master_id, how = 'inner', left_on = 'Referenced Tweet Author ID', right_on='User ID', validate = 'm:1')\n",
    "retweets = retweets.rename(columns = {'Label': 'Target Label', 'Political Affiliation': 'Target PA'})\n",
    "\n",
    "retweets = retweets.drop(columns= ['User ID'])\n",
    "print(retweets.shape)\n",
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 36,964 Usuarios con Rts o Retwiteados. Usuarios sin tweets 373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "      <th>User ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>alerios</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>12996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ranaberden</td>\n",
       "      <td>Centro</td>\n",
       "      <td>777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jsanti</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>784125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>thisgoblin</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1061601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36959</th>\n",
       "      <td>36959</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1389721694961651712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36960</th>\n",
       "      <td>36960</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>1389737202742071296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36961</th>\n",
       "      <td>36961</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>1389741234370064384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>36962</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1389769251704147968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>36963</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1389784145417678848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID           Label Political Affiliation              User ID\n",
       "0          0               0        Sin Clasificar                   12\n",
       "1          1         alerios             Izquierda                12996\n",
       "2          2      ranaberden                Centro               777978\n",
       "3          3          jsanti             Izquierda               784125\n",
       "4          4      thisgoblin             Izquierda              1061601\n",
       "...      ...             ...                   ...                  ...\n",
       "36959  36959  Neoplasticista             Izquierda  1389721694961651712\n",
       "36960  36960      JC13177979               Derecha  1389737202742071296\n",
       "36961  36961   JhonatanVRojo        Sin Clasificar  1389741234370064384\n",
       "36962  36962       VaneLen18             Izquierda  1389769251704147968\n",
       "36963  36963        kars0518             Izquierda  1389784145417678848\n",
       "\n",
       "[36964 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many tweets and users we have now\n",
    "users_rts = set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID']))\n",
    "non_singletons = master_id[master_id['User ID'].isin(users_rts)] # Nodes conected by a Rt\n",
    "singletons = master_id[~master_id['User ID'].isin(users_rts)] # Nodes that aren't in Rts during Paro (Perhaps only Twitted or Retwitted with replies) \n",
    "\n",
    "# Insights\n",
    "print(f\"Tenemos: {len(non_singletons):,} Usuarios con Rts o Retwiteados. Usuarios sin tweets {len(singletons)}\")\n",
    "# Save this Dataframe for Nodes List\n",
    "master_id = non_singletons # Aislamos a los singletons del Master ID\n",
    "master_id = master_id.astype({\n",
    "    'User ID': int,\n",
    "    'Label': str,\n",
    "    'Political Affiliation': str\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "master_id = master_id.reset_index().rename(columns = {'index': 'ID'})\n",
    "id_to_label = master_id.set_index('User ID').to_dict()['Label']\n",
    "\n",
    "master_id = master_id[['ID', 'Label', 'Political Affiliation', 'User ID']]\n",
    "\n",
    "# Save\n",
    "master_id.to_csv(os.path.join(save_path, 'Master_Index' + \".csv\"), index = False, sep = \";\")\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Master Index in Any case\n",
    "master_id = pd.read_csv('/mnt/disk2/Data/3_Day_Graphs/Master_Index.csv', sep = ';')\n",
    "\n",
    "# Useful Dicts\n",
    "idx_to_id = master_id['User ID'].reset_index().to_dict()['User ID']\n",
    "idx_to_pa = master_id['Political Affiliation'].reset_index().to_dict()['Political Affiliation']\n",
    "idx_to_label = master_id['Label'].reset_index().to_dict()['Label']\n",
    "\n",
    "# Dict for lookup in Graph\n",
    "id_to_idx = {id:idx for idx, id in idx_to_id.items()}\n",
    "\n",
    "# dict for color\n",
    "color = {\n",
    "    'Izquierda': 'blue',\n",
    "    'Derecha': 'red',\n",
    "    'Centro': 'green',\n",
    "    'Sin Clasificar': 'gray'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos Retweeteados por alguien pero que no Retweetean: 6,510\n",
      "Nodos que Retweetean a alguien pero no son Retweeteados: 833\n",
      "Nodos que tienen un self loop: 11\n",
      "primer nodo: 12.0 último nodo: 1.3897841454176788e+18\n",
      "Total de nodos en conectados: 36,964\n",
      "Total de nodos Singletons: 373\n",
      "Total de usuarios que TWITTEARON Durante el paro: 37,337\n"
     ]
    }
   ],
   "source": [
    "# Insights using only retweets\n",
    "nodes_no_receipt = set(retweets[\"Author ID\"]) -  set(retweets[\"Referenced Tweet Author ID\"])\n",
    "nodes_no_send = set(retweets[\"Referenced Tweet Author ID\"]) - set(retweets[\"Author ID\"])\n",
    "self_loops = set(retweets[retweets['Author ID'] == retweets['Referenced Tweet Author ID']])\n",
    "\n",
    "print(f'Nodos Retweeteados por alguien pero que no Retweetean: {len(nodes_no_receipt):,}')\n",
    "print(f'Nodos que Retweetean a alguien pero no son Retweeteados: {len(nodes_no_send):,}')\n",
    "print(f'Nodos que tienen un self loop: {len(self_loops)}')\n",
    "\n",
    "print(f'primer nodo: {min(users_rts)} último nodo: {max(users_rts):,}')\n",
    "print(f'Total de nodos en conectados: {len(users_rts):,}')\n",
    "print(f'Total de nodos Singletons: {len(singletons):,}')\n",
    "print(f'Total de usuarios que TWITTEARON Durante el paro: {len(singletons) + len(non_singletons):,}')\n",
    "\n",
    "del nodes_no_receipt, nodes_no_send, self_loops, users_rts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date_start = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "del v1_end, v1_start\n",
    "\n",
    "v2_start = '2021-05-01 23:59:59'\n",
    "v2_end = '2021-06-30 23:59:59'\n",
    "date_end = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "del v2_start, v2_end\n",
    "\n",
    "# date_start = date_start[7:8]\n",
    "# date_end = date_end[7:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Original Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:04<00:00, 12.85it/s]\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/original.gzip', compression='gzip')\n",
    "\n",
    "# Get the amount of tweets for each day\n",
    "def create_tweets_per_day(date_tuple):\n",
    "    d_s, d_e = date_tuple\n",
    "    window = original[(original['Date'] >= d_s.date()) & (original['Date'] < d_e.date())]\n",
    "    \n",
    "    # CAlculate number of tweets\n",
    "    tweets_per_user = window.groupby('Author ID').size().reset_index(name = 'Original Tweets')\n",
    "    tweets_per_user.rename(columns = {'Author ID': 'User ID'}, inplace=True)\n",
    "    \n",
    "    # Merge with master Index to get the tweets of relevant people\n",
    "    tweets_per_user = tweets_per_user.merge(master_id, on='User ID', how = 'right')\n",
    "    \n",
    "    # Filling na as 0 (No original tweet registerd)\n",
    "    tweets_per_user.fillna(0, inplace=True)\n",
    "    tweets_per_user.set_index('User ID', inplace = True)\n",
    "    \n",
    "    id_to_tweets = tweets_per_user.to_dict()['Original Tweets']\n",
    "    filename = os.path.join(save_path, 'Tweets_Per_Day', f'starting_{str(d_s.date())}' + \".pkl\")\n",
    "    \n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(id_to_tweets,file)\n",
    "    \n",
    "\n",
    "def main():\n",
    "    dates = list(zip(date_start, date_end))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_tweets_per_day, dates), total = len(dates)))\n",
    "    return futures\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:31<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_source_target(date_tuple):\n",
    "    d_s, d_e = date_tuple\n",
    "    # Get 3 days Retweets\n",
    "    window_rts = retweets[(retweets['Date'] >= d_s.date()) & (retweets['Date'] < d_e.date())]\n",
    "    \n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window_rts.groupby('Author ID').size().reset_index(name = 'total')\n",
    "    \n",
    "    # Get Tweets that were retweeted (Grouping by Referenced Tweet to avoid duplicating (Counting al retweets and not the original retweeted tweet))\n",
    "    tweets_og_per_user = window_rts.groupby(['Referenced Tweet Author ID', 'Referenced Tweet']).agg('size').reset_index()\n",
    "    tweets_og_per_user = tweets_og_per_user.groupby('Referenced Tweet Author ID').size()\n",
    "    tweets_og_per_user.index.astype(int)\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window_rts.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number_of_rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal_weight'] = temp['number_of_rts']/temp['total']\n",
    "    temp['normal_weight'] = temp['normal_weight']\n",
    "    temp.drop(columns='total', inplace=True)\n",
    "    temp.rename(columns = {'Author ID': \"source_user_id\", \"Referenced Tweet Author ID\": \"target_user_id\"}, inplace=True)\n",
    "    \n",
    "    # Assign Index\n",
    "    temp['Source'] = temp['source_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    temp['Target'] = temp['target_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    \n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source_user_id\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target_user_id\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "    \n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['source_user_id'].apply(lambda x: id_to_label[x])\n",
    "    temp['target_label'] = temp['target_user_id'].apply(lambda x: id_to_label[x])\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'Source': int,\n",
    "        'Target': int,\n",
    "        'number_of_rts': int,\n",
    "        'normal_weight': float,\n",
    "        'source_user_id': int,\n",
    "        'target_user_id': int\n",
    "    })\n",
    "    columns = list(temp.columns)\n",
    "    columns.remove('Source')\n",
    "    columns.insert(0, 'Source')\n",
    "    columns.remove('Target')\n",
    "    columns.insert(1, 'Target')\n",
    "    temp = temp[columns]\n",
    "\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source_Target\", 'starting_' + str(d_s.date()) + \".csv\"), index = False, sep = \";\")\n",
    "    \n",
    "def main():\n",
    "    dates = list(zip(date_start, date_end))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_source_target, dates), total = len(dates)))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Numero de Arcos: 234,657. Nodos Source: 24,254. Nodos Target 8,981. Total de Nodos 26,015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1140</td>\n",
       "      <td>12996</td>\n",
       "      <td>53855557</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>CathyJuvinao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1712</td>\n",
       "      <td>12996</td>\n",
       "      <td>62528273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>AntonioSanguino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1939</td>\n",
       "      <td>12996</td>\n",
       "      <td>66740100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>alerios</td>\n",
       "      <td>ZuluagaCamila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3504</td>\n",
       "      <td>12996</td>\n",
       "      <td>98781946</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>IvanCepedaCast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3782</td>\n",
       "      <td>12996</td>\n",
       "      <td>104622520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>valentinabz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6170</td>\n",
       "      <td>12996</td>\n",
       "      <td>142448269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>maryluzherran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7882</td>\n",
       "      <td>12996</td>\n",
       "      <td>165748292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>angelamrobledo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>9727</td>\n",
       "      <td>12996</td>\n",
       "      <td>201256928</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>marthaperaltae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10570</td>\n",
       "      <td>12996</td>\n",
       "      <td>221466950</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>wilsonariasc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>11057</td>\n",
       "      <td>12996</td>\n",
       "      <td>233001872</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>jorgerojas2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target  source_user_id  target_user_id  number_of_rts  \\\n",
       "0       1    1140           12996        53855557              1   \n",
       "1       1    1712           12996        62528273              1   \n",
       "2       1    1939           12996        66740100              1   \n",
       "3       1    3504           12996        98781946              2   \n",
       "4       1    3782           12996       104622520              1   \n",
       "5       1    6170           12996       142448269              1   \n",
       "6       1    7882           12996       165748292              1   \n",
       "7       1    9727           12996       201256928              1   \n",
       "8       1   10570           12996       221466950              4   \n",
       "9       1   11057           12996       233001872              1   \n",
       "\n",
       "   normal_weight source_political_afilliation target_political_afilliation  \\\n",
       "0       0.027778                    Izquierda                       Centro   \n",
       "1       0.027778                    Izquierda                       Centro   \n",
       "2       0.027778                    Izquierda               Sin Clasificar   \n",
       "3       0.055556                    Izquierda                    Izquierda   \n",
       "4       0.027778                    Izquierda                    Izquierda   \n",
       "5       0.027778                    Izquierda                    Izquierda   \n",
       "6       0.027778                    Izquierda                       Centro   \n",
       "7       0.027778                    Izquierda                    Izquierda   \n",
       "8       0.111111                    Izquierda                    Izquierda   \n",
       "9       0.027778                    Izquierda                    Izquierda   \n",
       "\n",
       "  source_label     target_label  \n",
       "0      alerios     CathyJuvinao  \n",
       "1      alerios  AntonioSanguino  \n",
       "2      alerios    ZuluagaCamila  \n",
       "3      alerios   IvanCepedaCast  \n",
       "4      alerios      valentinabz  \n",
       "5      alerios    maryluzherran  \n",
       "6      alerios   angelamrobledo  \n",
       "7      alerios   marthaperaltae  \n",
       "8      alerios     wilsonariasc  \n",
       "9      alerios   jorgerojas2022  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of our lists\n",
    "ej_csv = pd.read_csv(save_path + f'/Source_Target/starting_2021-06-16.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\" Numero de Arcos: {ej_csv.shape[0]:,}. Nodos Source: {len(set(ej_csv['Source'])):,}. Nodos Target {len(set(ej_csv['Target'])):,}. Total de Nodos {len(nodes):,}\")\n",
    "ej_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:30<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_graph(file_tuple):\n",
    "    file1, file2 = file_tuple\n",
    "    starting_date_str = file1.split('.')[-2].split('/')[-1].split('_')[-1]\n",
    "    starting_date = datetime.strptime(starting_date_str, '%Y-%m-%d')\n",
    "    ending_date = starting_date + timedelta(days=3)\n",
    "    ending_date_str = ending_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    csv = pd.read_csv(file1, delimiter=';')\n",
    "    \n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(len(master_id))\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "    \n",
    "    for row in csv.itertuples(index = False):\n",
    "        e = g.add_edge(row[0], row[1])\n",
    "        number_of_rts[e] = row[4]\n",
    "        normal_weight[e] = row[5]\n",
    "\n",
    "    g.ep['Number of rts'] = number_of_rts\n",
    "    g.ep['Normal Weight'] = normal_weight\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "\n",
    "    # Create a Vertex property maps\n",
    "    vertex_PA_map = g.new_vertex_property('string')\n",
    "    vertex_ID_map = g.new_vertex_property('int64_t')\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "    vertex_color_map = g.new_vertex_property('string')\n",
    "    vertex_isolate_map = g.new_vertex_property('bool')\n",
    "    vertex_tweets_map = g.new_vertex_property('int64_t')\n",
    "    \n",
    "    # Get Different categories\n",
    "    categories = [cat for cat in set(idx_to_pa.values())]\n",
    "    for cat in categories:\n",
    "        # Create a dummy property map\n",
    "        vertex_dummy_map = g.new_vertex_property('bool')\n",
    "        globals()['map_'+cat] = vertex_dummy_map\n",
    "    \n",
    "    with open(file2, \"rb\") as file:\n",
    "        tweets_per_day = pickle.load(file)\n",
    "\n",
    "    # Assign Labels to vertices using loop (Create one VertexPropertyMap for every Political Label)\n",
    "    for v_index in g.iter_vertices():\n",
    "        v = g.vertex(v_index)\n",
    "        # Add tweets information of users\n",
    "        vertex_tweets_map[v] = tweets_per_day[idx_to_id[v]]\n",
    "        \n",
    "        # Add Master Index Information\n",
    "        vertex_PA_map[v] = idx_to_pa[v]\n",
    "        vertex_ID_map[v] = idx_to_id[v]\n",
    "        vertex_label_map[v] = idx_to_label[v]\n",
    "        vertex_color_map[v] = color[idx_to_pa[v]]\n",
    "        \n",
    "        # Add categories Information\n",
    "        for cat in categories:\n",
    "            if idx_to_pa[v] == cat:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = True\n",
    "                globals()['map_'+cat] = map\n",
    "            else:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = False\n",
    "                globals()['map_'+cat] = map\n",
    "        \n",
    "        # Add isolated\n",
    "        if v.out_degree() == 0 and v.in_degree() == 0:\n",
    "            vertex_isolate_map[v] = True\n",
    "        else: \n",
    "            vertex_isolate_map[v] = False\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_PA_map\n",
    "    g.vp['User ID'] = vertex_ID_map\n",
    "    g.vp['Label'] = vertex_label_map\n",
    "    g.vp['Color'] = vertex_color_map\n",
    "    g.vp['Isolate'] = vertex_isolate_map\n",
    "    g.vp['Tweets'] = vertex_tweets_map\n",
    "    \n",
    "    # Add dummy maps\n",
    "    for cat in categories:\n",
    "        map = globals()['map_'+cat]\n",
    "        g.vp[cat] = map\n",
    "    \n",
    "    # Add graph properties\n",
    "    graph_starting_date = g.new_graph_property('string')\n",
    "    graph_ending_date = g.new_graph_property('string')\n",
    "    graph_starting_date[g] = starting_date_str\n",
    "    graph_ending_date[g] = ending_date_str\n",
    "    g.gp['Starting Date'] = graph_starting_date\n",
    "    g.gp['Ending Date'] = graph_ending_date\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(save_path, 'Graphs' ,'starting_' + starting_date_str + \".graphml\")\n",
    "    g.save(filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    source_target_files = glob('../../../Data/3_Day_Graphs/Source_Target/starting_*.csv')\n",
    "    tweets_files = glob('../../../Data/3_Day_Graphs/Tweets_Per_Day/starting_*.pkl')\n",
    "    source_target_files.sort()\n",
    "    tweets_files.sort()\n",
    "    files = list(zip(source_target_files, tweets_files))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_graph, files), total = len(files)))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge List\n",
      "Non Isolate Vertices 32,886 and 718,230 edges\n",
      "Graph\n",
      "Non Isolate Vertices 32,886 and 718,230 edges\n"
     ]
    }
   ],
   "source": [
    "print('Edge List')\n",
    "ej_csv = pd.read_csv(save_path + f'/Source_Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\"Non Isolate Vertices {len(nodes):,} and {len(ej_csv):,} edges\")\n",
    "\n",
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(save_path + f'/Graphs/starting_2021-05-04.graphml')\n",
    "print('Graph')\n",
    "print(f\"Non Isolate Vertices {ej_g.num_vertices() - sum(ej_g.vp['Isolate']):,} and {ej_g.num_edges():,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87b17c0d0, at 0x7fc927682310>,\n",
       " 'Color': <VertexPropertyMap object with value type 'string', for Graph 0x7fc87b17c0d0, at 0x7fc8890a5e90>,\n",
       " 'Derecha': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87b17c0d0, at 0x7fc703b9fc50>,\n",
       " 'Isolate': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87b17c0d0, at 0x7fc703b9fd10>,\n",
       " 'Izquierda': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87b17c0d0, at 0x7fc703e82850>,\n",
       " 'Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fc87b17c0d0, at 0x7fc7038aba10>,\n",
       " 'Political Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fc87b17c0d0, at 0x7fc7038abcd0>,\n",
       " 'Sin Clasificar': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87b17c0d0, at 0x7fc6fc31dad0>,\n",
       " 'Tweets': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fc87b17c0d0, at 0x7fc6fc31e9d0>,\n",
       " 'User ID': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fc87b17c0d0, at 0x7fc6fc31ebd0>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ej_g.vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal Weight': <EdgePropertyMap object with value type 'double', for Graph 0x7fc87b17c0d0, at 0x7fc6fc31f550>,\n",
       " 'Number of rts': <EdgePropertyMap object with value type 'int32_t', for Graph 0x7fc87b17c0d0, at 0x7fc6fc31e010>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ej_g.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx in Graph: 23639\n",
      "1920140406\n",
      "Santialarconu\n",
      "Izquierda\n",
      "blue\n",
      "---------Checking on Master Index----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                               23639\n",
       "Label                    Santialarconu\n",
       "Political Affiliation        Izquierda\n",
       "User ID                     1920140406\n",
       "Name: 23639, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(ej_g.vp['User ID'][test_idx])\n",
    "print(ej_g.vp['Label'][test_idx])\n",
    "print(ej_g.vp['Political Label'][test_idx])\n",
    "print(ej_g.vp['Color'][test_idx])\n",
    "print('---------Checking on Master Index----------')\n",
    "master_id.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (36963, 31708)\n",
      "Edge In graph: (36963, 31708)\n",
      "Normal Weights 0.088235294117647\n",
      "Number of rts 3\n",
      "--------Value in Edge List---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>718229</th>\n",
       "      <td>36963</td>\n",
       "      <td>31708</td>\n",
       "      <td>1389784145417678848</td>\n",
       "      <td>1010113508233699328</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>LevyRincon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  Target       source_user_id       target_user_id  \\\n",
       "718229   36963   31708  1389784145417678848  1010113508233699328   \n",
       "\n",
       "        number_of_rts  normal_weight source_political_afilliation  \\\n",
       "718229              3       0.088235                    Izquierda   \n",
       "\n",
       "       target_political_afilliation source_label target_label  \n",
       "718229                    Izquierda     kars0518   LevyRincon  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id_source = 1389784145417678848\n",
    "test_id_target = 1010113508233699328\n",
    "\n",
    "source_idx = id_to_idx[test_id_source]\n",
    "target_idx = id_to_idx[test_id_target]\n",
    "test_edge_idx = (source_idx, target_idx)\n",
    "\n",
    "edge_index = ej_g.edge_index[test_edge_idx]\n",
    "print(f'Edge: {test_edge_idx}')\n",
    "print(f'Edge In graph: {test_edge_idx}')\n",
    "print(f\"Normal Weights {ej_g.ep['Normal Weight'][test_edge_idx]}\")\n",
    "print(f\"Number of rts {ej_g.ep['Number of rts'][test_edge_idx]}\")\n",
    "print('--------Value in Edge List---------')\n",
    "ej_csv.loc[(ej_csv['Source'] == source_idx) & (ej_csv['Target'] == target_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have retweets from 2021-04-28 to 2021-06-29\n"
     ]
    }
   ],
   "source": [
    "fecha_min = retweets[\"Date\"].min()\n",
    "fecha_max = retweets[\"Date\"].max()\n",
    "print(f\"We have retweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get original Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 18.00it/s]\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/original.gzip', compression='gzip')\n",
    "\n",
    "# Get the amount of tweets for each day\n",
    "def create_tweets_per_day(date):\n",
    "    window = original[original['Date'] == date.date()]\n",
    "    \n",
    "    # CAlculate number of tweets\n",
    "    tweets_per_user = window.groupby('Author ID').size().reset_index(name = 'Original Tweets')\n",
    "    tweets_per_user.rename(columns = {'Author ID': 'User ID'}, inplace=True)\n",
    "    \n",
    "    # Merge with master Index to get the tweets of relevant people\n",
    "    tweets_per_user = tweets_per_user.merge(master_id, on='User ID', how = 'right')\n",
    "    \n",
    "    # Filling na as 0 (No original tweet registerd)\n",
    "    tweets_per_user.fillna(0, inplace=True)\n",
    "    tweets_per_user.set_index('User ID', inplace = True)\n",
    "    \n",
    "    id_to_tweets = tweets_per_user.to_dict()['Original Tweets']\n",
    "    filename = os.path.join(save_path, 'Tweets_Per_Day', f'starting_{str(date.date())}' + \".pkl\")\n",
    "    \n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(id_to_tweets,file)\n",
    "    \n",
    "\n",
    "def main(daily_grid):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_tweets_per_day, daily_grid), total = len(daily_grid)))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(daily_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:16<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_source_target(date):\n",
    "    window_rts = retweets[retweets['Date'] == date.date()]\n",
    "    \n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window_rts.groupby('Author ID').size().reset_index(name = 'total')\n",
    "    \n",
    "    # Get Tweets that were retweeted (Grouping by Referenced Tweet to avoid duplicating (Counting al retweets and not the original retweeted tweet))\n",
    "    tweets_og_per_user = window_rts.groupby(['Referenced Tweet Author ID', 'Referenced Tweet']).agg('size').reset_index()\n",
    "    tweets_og_per_user = tweets_og_per_user.groupby('Referenced Tweet Author ID').size()\n",
    "    tweets_og_per_user.index.astype(int)\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window_rts.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number_of_rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal_weight'] = temp['number_of_rts']/temp['total']\n",
    "    temp['normal_weight'] = temp['normal_weight']\n",
    "    temp.drop(columns='total', inplace=True)\n",
    "    temp.rename(columns = {'Author ID': \"source_user_id\", \"Referenced Tweet Author ID\": \"target_user_id\"}, inplace=True)\n",
    "    \n",
    "    # Assign Index\n",
    "    temp['Source'] = temp['source_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    temp['Target'] = temp['target_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    \n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source_user_id\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target_user_id\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "    \n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['source_user_id'].apply(lambda x: id_to_label[x])\n",
    "    temp['target_label'] = temp['target_user_id'].apply(lambda x: id_to_label[x])\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'Source': int,\n",
    "        'Target': int,\n",
    "        'number_of_rts': int,\n",
    "        'normal_weight': float,\n",
    "        'source_user_id': int,\n",
    "        'target_user_id': int\n",
    "    })\n",
    "    columns = list(temp.columns)\n",
    "    columns.remove('Source')\n",
    "    columns.insert(0, 'Source')\n",
    "    columns.remove('Target')\n",
    "    columns.insert(1, 'Target')\n",
    "    temp = temp[columns]\n",
    "\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source-Target\", 'starting_' + str(date.date()) + \".csv\"), index = False, sep = \";\")\n",
    "    \n",
    "def main(daily_grid):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_source_target, daily_grid), total = len(daily_grid)))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(daily_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:15<00:00,  4.02it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_graph(file_tuple):\n",
    "    file1, file2 = file_tuple\n",
    "    date_str = file1.split('.')[-2].split('/')[-1].split('_')[-1]\n",
    "    \n",
    "    csv = pd.read_csv(file1, delimiter=';')\n",
    "    \n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(len(master_id))\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "    \n",
    "    for row in csv.itertuples(index = False):\n",
    "        e = g.add_edge(row[0], row[1])\n",
    "        number_of_rts[e] = row[4]\n",
    "        normal_weight[e] = row[5]\n",
    "\n",
    "    g.ep['Number of rts'] = number_of_rts\n",
    "    g.ep['Normal Weight'] = normal_weight\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "\n",
    "    # Create a Vertex property maps\n",
    "    vertex_PA_map = g.new_vertex_property('string')\n",
    "    vertex_ID_map = g.new_vertex_property('int64_t')\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "    vertex_color_map = g.new_vertex_property('string')\n",
    "    vertex_isolate_map = g.new_vertex_property('bool')\n",
    "    vertex_tweets_map = g.new_vertex_property('int64_t')\n",
    "    \n",
    "    # Get Different categories\n",
    "    categories = [cat for cat in set(idx_to_pa.values())]\n",
    "    for cat in categories:\n",
    "        # Create a dummy property map\n",
    "        vertex_dummy_map = g.new_vertex_property('bool')\n",
    "        globals()['map_'+cat] = vertex_dummy_map\n",
    "    \n",
    "    with open(file2, \"rb\") as file:\n",
    "        tweets_per_day = pickle.load(file)\n",
    "\n",
    "    # Assign Labels to vertices using loop (Create one VertexPropertyMap for every Political Label)\n",
    "    for v_index in g.iter_vertices():\n",
    "        v = g.vertex(v_index)\n",
    "        # Add tweets information of users\n",
    "        vertex_tweets_map[v] = tweets_per_day[idx_to_id[v]]\n",
    "        \n",
    "        # Add Master Index Information\n",
    "        vertex_PA_map[v] = idx_to_pa[v]\n",
    "        vertex_ID_map[v] = idx_to_id[v]\n",
    "        vertex_label_map[v] = idx_to_label[v]\n",
    "        vertex_color_map[v] = color[idx_to_pa[v]]\n",
    "        \n",
    "        # Add categories Information\n",
    "        for cat in categories:\n",
    "            if idx_to_pa[v] == cat:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = True\n",
    "                globals()['map_'+cat] = map\n",
    "            else:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = False\n",
    "                globals()['map_'+cat] = map\n",
    "        \n",
    "        # Add isolated\n",
    "        if v.out_degree() == 0 and v.in_degree() == 0:\n",
    "            vertex_isolate_map[v] = True\n",
    "        else: \n",
    "            vertex_isolate_map[v] = False\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_PA_map\n",
    "    g.vp['User ID'] = vertex_ID_map\n",
    "    g.vp['Label'] = vertex_label_map\n",
    "    g.vp['Color'] = vertex_color_map\n",
    "    g.vp['Isolate'] = vertex_isolate_map\n",
    "    g.vp['Tweets'] = vertex_tweets_map\n",
    "    \n",
    "    # Add dummy maps\n",
    "    for cat in categories:\n",
    "        map = globals()['map_'+cat]\n",
    "        g.vp[cat] = map\n",
    "    \n",
    "    # Add graph properties\n",
    "    graph_date_map = g.new_graph_property('string')\n",
    "    graph_date_map[g] = date_str\n",
    "    g.gp['Date'] = graph_date_map\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(save_path, 'Graphs' ,'starting_' + date_str + \".graphml\")\n",
    "    g.save(filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    source_target_files = glob('../../../Data/Daily_graphs/Source-Target/starting_*.csv')\n",
    "    tweets_files = glob('../../../Data/Daily_graphs/Tweets_Per_Day/starting_*.pkl')\n",
    "    source_target_files.sort()\n",
    "    tweets_files.sort()\n",
    "    files = list(zip(source_target_files, tweets_files))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_graph, files), total = len(files)))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge List\n",
      "Non Isolate Vertices 28,329 and 327,632 edges\n",
      "Graph\n",
      "Non Isolate Vertices 28,329 and 327,632 edges\n"
     ]
    }
   ],
   "source": [
    "print('Edge List')\n",
    "ej_csv = pd.read_csv(save_path + f'/Source-Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\"Non Isolate Vertices {len(nodes):,} and {len(ej_csv):,} edges\")\n",
    "\n",
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(save_path + f'/Graphs/starting_2021-05-04.graphml')\n",
    "print('Graph')\n",
    "print(f\"Non Isolate Vertices {ej_g.num_vertices() - sum(ej_g.vp['Isolate']):,} and {ej_g.num_edges():,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87ac9ec50, at 0x7fc74241e050>,\n",
       " 'Color': <VertexPropertyMap object with value type 'string', for Graph 0x7fc87ac9ec50, at 0x7fc74241dfd0>,\n",
       " 'Derecha': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87ac9ec50, at 0x7fc74241de50>,\n",
       " 'Isolate': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87ac9ec50, at 0x7fc74241dd50>,\n",
       " 'Izquierda': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87ac9ec50, at 0x7fc74241dc50>,\n",
       " 'Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fc87ac9ec50, at 0x7fc74241db50>,\n",
       " 'Political Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fc87ac9ec50, at 0x7fc74241da50>,\n",
       " 'Sin Clasificar': <VertexPropertyMap object with value type 'bool', for Graph 0x7fc87ac9ec50, at 0x7fc74241d990>,\n",
       " 'Tweets': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fc87ac9ec50, at 0x7fc74241d890>,\n",
       " 'User ID': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fc87ac9ec50, at 0x7fc74241d790>}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ej_g.vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal Weight': <EdgePropertyMap object with value type 'double', for Graph 0x7fc87ac9ec50, at 0x7fc74241d690>,\n",
       " 'Number of rts': <EdgePropertyMap object with value type 'int32_t', for Graph 0x7fc87ac9ec50, at 0x7fc74241d5d0>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ej_g.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx in Graph: 23639\n",
      "1920140406\n",
      "Santialarconu\n",
      "Izquierda\n",
      "blue\n",
      "---------Checking on Master Index----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                               23639\n",
       "Label                    Santialarconu\n",
       "Political Affiliation        Izquierda\n",
       "User ID                     1920140406\n",
       "Name: 23639, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(ej_g.vp['User ID'][test_idx])\n",
    "print(ej_g.vp['Label'][test_idx])\n",
    "print(ej_g.vp['Political Label'][test_idx])\n",
    "print(ej_g.vp['Color'][test_idx])\n",
    "print('---------Checking on Master Index----------')\n",
    "master_id.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (36963, 31708)\n",
      "Edge In graph: (36963, 31708)\n",
      "Normal Weights 0.1666666666666666\n",
      "Number of rts 1\n",
      "--------Value in Edge List---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327631</th>\n",
       "      <td>36963</td>\n",
       "      <td>31708</td>\n",
       "      <td>1389784145417678848</td>\n",
       "      <td>1010113508233699328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>LevyRincon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  Target       source_user_id       target_user_id  \\\n",
       "327631   36963   31708  1389784145417678848  1010113508233699328   \n",
       "\n",
       "        number_of_rts  normal_weight source_political_afilliation  \\\n",
       "327631              1       0.166667                    Izquierda   \n",
       "\n",
       "       target_political_afilliation source_label target_label  \n",
       "327631                    Izquierda     kars0518   LevyRincon  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id_source = 1389784145417678848\n",
    "test_id_target = 1010113508233699328\n",
    "\n",
    "source_idx = id_to_idx[test_id_source]\n",
    "target_idx = id_to_idx[test_id_target]\n",
    "test_edge_idx = (source_idx, target_idx)\n",
    "\n",
    "edge_index = ej_g.edge_index[test_edge_idx]\n",
    "print(f'Edge: {test_edge_idx}')\n",
    "print(f'Edge In graph: {test_edge_idx}')\n",
    "print(f\"Normal Weights {ej_g.ep['Normal Weight'][test_edge_idx]}\")\n",
    "print(f\"Number of rts {ej_g.ep['Number of rts'][test_edge_idx]}\")\n",
    "print('--------Value in Edge List---------')\n",
    "ej_csv.loc[(ej_csv['Source'] == source_idx) & (ej_csv['Target'] == target_idx)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
