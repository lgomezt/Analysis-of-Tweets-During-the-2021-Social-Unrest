{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets Networks\n",
    "\n",
    "In this notebook, we create a daily retweet network. First, we transform our dataset into a Source-Target DataFrame. Afterward, we construct a `graph-tool` object.\n",
    "\n",
    "We have 45,330,718 Tweets from 37330 from which 30,918,011 are ReTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/anaconda3/envs/gt_global/lib/python3.11/site-packages/graph_tool/draw/cairo_draw.py:1544: RuntimeWarning: Error importing Gtk module: ; GTK+ drawing will not work.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Mathematical and Data Managment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Graph Managment\n",
    "import graph_tool.all as gt\n",
    "from utils.Bojanowski import *\n",
    "\n",
    "# Miscellaneous\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from time import perf_counter\n",
    "\n",
    "# Paths\n",
    "path = r\"/mnt/disk2/Data\"\n",
    "path_3_day = os.path.join(path,\"3_Day_Graphs\")\n",
    "path_daily = os.path.join(path,\"Daily_Graphs\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Retweets 11,694,492\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Referenced Tweet Author Name</th>\n",
       "      <th>Referenced Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source Label</th>\n",
       "      <th>Source PA</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.407536e+18</td>\n",
       "      <td>7.882507e+08</td>\n",
       "      <td>Laura_Milena98</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>1.407204e+18</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>Laura_Milena98</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.393521e+18</td>\n",
       "      <td>1.265236e+08</td>\n",
       "      <td>sandrapulga</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>1.393368e+18</td>\n",
       "      <td>2021-05-15</td>\n",
       "      <td>sandrapulga</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.404837e+18</td>\n",
       "      <td>8.996701e+17</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>1.404697e+18</td>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.402071e+18</td>\n",
       "      <td>8.996701e+17</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>1.401913e+18</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.391067e+18</td>\n",
       "      <td>8.996701e+17</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>270668814.0</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>1.391020e+18</td>\n",
       "      <td>2021-05-08</td>\n",
       "      <td>rchicave</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>gabocifuentes</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet ID     Author ID     Author Name  Referenced Tweet Author ID  \\\n",
       "0  1.407536e+18  7.882507e+08  Laura_Milena98                 270668814.0   \n",
       "1  1.393521e+18  1.265236e+08     sandrapulga                 270668814.0   \n",
       "2  1.404837e+18  8.996701e+17        rchicave                 270668814.0   \n",
       "3  1.402071e+18  8.996701e+17        rchicave                 270668814.0   \n",
       "4  1.391067e+18  8.996701e+17        rchicave                 270668814.0   \n",
       "\n",
       "  Referenced Tweet Author Name  Referenced Tweet ID        Date  \\\n",
       "0                gabocifuentes         1.407204e+18  2021-06-22   \n",
       "1                gabocifuentes         1.393368e+18  2021-05-15   \n",
       "2                gabocifuentes         1.404697e+18  2021-06-15   \n",
       "3                gabocifuentes         1.401913e+18  2021-06-07   \n",
       "4                gabocifuentes         1.391020e+18  2021-05-08   \n",
       "\n",
       "     Source Label  Source PA   Target Label Target PA  \n",
       "0  Laura_Milena98  Izquierda  gabocifuentes    Centro  \n",
       "1     sandrapulga  Izquierda  gabocifuentes    Centro  \n",
       "2        rchicave  Izquierda  gabocifuentes    Centro  \n",
       "3        rchicave  Izquierda  gabocifuentes    Centro  \n",
       "4        rchicave  Izquierda  gabocifuentes    Centro  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Retweets\n",
    "retweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames\",\"retweets.gzip\"), compression='gzip')\n",
    "\n",
    "# Time not needed, only date\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"], errors='coerce').dt.date\n",
    "\n",
    "# Import master\n",
    "master = pd.read_csv('/mnt/disk2/Data/Master.csv')\n",
    "\n",
    "# Adding Source Labels\n",
    "temp = retweets.merge(master, how = 'inner', left_on = 'Author ID', right_on='User ID', validate = 'm:1')\n",
    "temp = temp.rename(columns = {'Label': 'Source Label', 'Political Affiliation': 'Source PA'}).drop(columns=['User ID'])\n",
    "\n",
    "# Adding Target Labels\n",
    "retweets = temp.merge(master, how = 'inner', left_on = 'Referenced Tweet Author ID', right_on='User ID', validate = 'm:1')\n",
    "retweets = retweets.rename(columns = {'Label': 'Target Label', 'Political Affiliation': 'Target PA'})\n",
    "\n",
    "retweets = retweets.drop(columns= ['User ID'])\n",
    "print(f\"Total de Retweets {retweets.shape[0]:,.0f}\")\n",
    "\n",
    "# # Save this edge list for future checkpoints\n",
    "# retweets.to_pickle(os.path.join(path, \"Tweets_DataFrames\", \"retweets_edge_list.gzip\"), compression = \"gzip\")\n",
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 34,840 Usuarios con Rts o Retwiteados. Usuarios sin tweets 2497\n",
      "Nodos Retweeteados por alguien pero que no Retweetean: 6,220\n",
      "Nodos que Retweetean a alguien pero no son Retweeteados: 1,575\n",
      "Nodos que tienen un self loop: 11\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "primer nodo: 12.0 Ãºltimo nodo: 1.3897841454176788e+18\n",
      "Total de nodos en conectados: 34,840\n",
      "Total de nodos Singletons: 2,497\n",
      "Total de usuarios que TWITTEARON Durante el paro: 37,337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "      <th>User ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>alerios</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1.299600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ranaberden</td>\n",
       "      <td>Centro</td>\n",
       "      <td>7.779780e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jsanti</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>7.841250e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>thisgoblin</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1.061601e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34835</th>\n",
       "      <td>34835</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1.389722e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34836</th>\n",
       "      <td>34836</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>1.389737e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34837</th>\n",
       "      <td>34837</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>1.389741e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34838</th>\n",
       "      <td>34838</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1.389769e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34839</th>\n",
       "      <td>34839</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1.389784e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34840 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID           Label Political Affiliation       User ID\n",
       "0          0               0        Sin Clasificar  1.200000e+01\n",
       "1          1         alerios             Izquierda  1.299600e+04\n",
       "2          2      ranaberden                Centro  7.779780e+05\n",
       "3          3          jsanti             Izquierda  7.841250e+05\n",
       "4          4      thisgoblin             Izquierda  1.061601e+06\n",
       "...      ...             ...                   ...           ...\n",
       "34835  34835  Neoplasticista             Izquierda  1.389722e+18\n",
       "34836  34836      JC13177979               Derecha  1.389737e+18\n",
       "34837  34837   JhonatanVRojo        Sin Clasificar  1.389741e+18\n",
       "34838  34838       VaneLen18             Izquierda  1.389769e+18\n",
       "34839  34839        kars0518             Izquierda  1.389784e+18\n",
       "\n",
       "[34840 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many tweets and users we have now\n",
    "users_rts = set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID']))\n",
    "non_singletons = master[master['User ID'].isin(users_rts)] # Nodes conected by a Rt\n",
    "singletons = master[~master['User ID'].isin(users_rts)] # Nodes that aren't in Rts during Paro (Perhaps only Twitted or Retwitted with replies) \n",
    "\n",
    "# Insights\n",
    "print(f\"Tenemos: {len(non_singletons):,} Usuarios con Rts o Retwiteados. Usuarios sin tweets {len(singletons)}\")\n",
    "\n",
    "# Save this Dataframe for Nodes List\n",
    "master = non_singletons # Aislamos a los singletons del Master ID\n",
    "master = (\n",
    "    master.astype({\n",
    "        'User ID': 'float64',\n",
    "        'Label': str,\n",
    "        'Political Affiliation': str\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    "    .reset_index(names = 'ID')\n",
    ")\n",
    "\n",
    "# Reordenamos las columnas\n",
    "master_id = master[['ID', 'Label', 'Political Affiliation','User ID']]\n",
    "\n",
    "# Save\n",
    "master_id.to_csv(os.path.join(path, 'Master_Index' + \".csv\"), index = False, sep = \";\")\n",
    "\n",
    "# Insights using only retweets\n",
    "nodes_no_receipt = set(retweets[\"Author ID\"]) -  set(retweets[\"Referenced Tweet Author ID\"])\n",
    "nodes_no_send = set(retweets[\"Referenced Tweet Author ID\"]) - set(retweets[\"Author ID\"])\n",
    "self_loops = set(retweets[retweets['Author ID'] == retweets['Referenced Tweet Author ID']])\n",
    "\n",
    "print(f'Nodos Retweeteados por alguien pero que no Retweetean: {len(nodes_no_receipt):,}')\n",
    "print(f'Nodos que Retweetean a alguien pero no son Retweeteados: {len(nodes_no_send):,}')\n",
    "print(f'Nodos que tienen un self loop: {len(self_loops)}')\n",
    "print(\"\\n\"+\"*\"*100+\"\\n\")\n",
    "print(f'primer nodo: {min(users_rts)} Ãºltimo nodo: {max(users_rts):,}')\n",
    "print(f'Total de nodos en conectados: {len(users_rts):,}')\n",
    "print(f'Total de nodos Singletons: {len(singletons):,}')\n",
    "print(f'Total de usuarios que TWITTEARON Durante el paro: {len(singletons) + len(non_singletons):,}')\n",
    "\n",
    "del nodes_no_receipt, nodes_no_send, self_loops, users_rts\n",
    "\n",
    "master_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: Cargar Master ID y retweets edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Master Index in Any case\n",
    "master_id = pd.read_csv('/mnt/disk2/Data/3_Day_Graphs/Master_Index.csv', sep = ';')\n",
    "\n",
    "# Open retweets edge list in any case\n",
    "retweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames\", \"retweets_edge_list.gzip\"), compression = \"gzip\")\n",
    "\n",
    "# Useful Dicts Index to Var\n",
    "idx_to_id = master_id['User ID'].reset_index().to_dict()['User ID']\n",
    "idx_to_pa = master_id['Political Affiliation'].reset_index().to_dict()['Political Affiliation']\n",
    "idx_to_label = master_id['Label'].reset_index().to_dict()['Label']\n",
    "\n",
    "# Useful Dicts User ID to Var\n",
    "id_to_pa = master_id.set_index('User ID')['Political Affiliation'].to_dict()\n",
    "id_to_idx = master_id.set_index('User ID')['ID'].to_dict()\n",
    "id_to_label = master_id.set_index('User ID')['Label'].to_dict()\n",
    "\n",
    "# dict for color\n",
    "color = {\n",
    "    'Izquierda': 'blue',\n",
    "    'Derecha': 'red',\n",
    "    'Centro': 'green',\n",
    "    'Sin Clasificar': 'gray'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date_start = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "del v1_end, v1_start\n",
    "\n",
    "v2_start = '2021-05-01 23:59:59'\n",
    "v2_end = '2021-06-30 23:59:59'\n",
    "date_end = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "del v2_start, v2_end\n",
    "\n",
    "# date_start = date_start[7:8]\n",
    "# date_end = date_end[7:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Original Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardar Original Tweets: 100%|ââââââââââ| 61/61 [00:04<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish whole cell in 0.0 minutes and 7 secs.\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_pickle(os.path.join(path,\"Tweets_DataFrames\",\"original.gzip\"), compression='gzip')\n",
    "\n",
    "# Get the amount of tweets for each day\n",
    "def create_tweets_per_day(date_tuple):\n",
    "    d_s, d_e = date_tuple\n",
    "    window = original[(original['Date'] >= d_s.date()) & (original['Date'] < d_e.date())]\n",
    "    \n",
    "    # CAlculate number of tweets\n",
    "    tweets_per_user = window.groupby('Author ID').size().reset_index(name = 'Original Tweets')\n",
    "    tweets_per_user.rename(columns = {'Author ID': 'User ID'}, inplace=True)\n",
    "    \n",
    "    # Merge with master Index to get the tweets of relevant people\n",
    "    tweets_per_user = tweets_per_user.merge(master_id, on='User ID', how = 'right')\n",
    "    \n",
    "    # Filling na as 0 (No original tweet registerd)\n",
    "    tweets_per_user.fillna(0, inplace=True)\n",
    "    tweets_per_user.set_index('User ID', inplace = True)\n",
    "    \n",
    "    id_to_tweets = tweets_per_user.to_dict()['Original Tweets']\n",
    "    filename = os.path.join(path_3_day, 'Tweets_Per_Day', f'starting_{str(d_s.date())}' + \".pkl\")\n",
    "    \n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(id_to_tweets,file)\n",
    "    \n",
    "\n",
    "def main():\n",
    "    dates = list(zip(date_start, date_end))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_tweets_per_day, dates), total = len(dates), desc=\"Guardar Original Tweets: \"))\n",
    "    return futures\n",
    "if __name__ == '__main__':\n",
    "    tic = perf_counter()\n",
    "    main()\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardando Source-Target files: 100%|ââââââââââ| 61/61 [00:27<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish whole cell in 0.0 minutes and 30 secs.\n"
     ]
    }
   ],
   "source": [
    "def create_source_target(date_tuple):\n",
    "    d_s, d_e = date_tuple\n",
    "    # Get 3 days Retweets\n",
    "    window_rts = retweets[(retweets['Date'] >= d_s.date()) & (retweets['Date'] < d_e.date())]\n",
    "    \n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window_rts.groupby('Author ID').size().reset_index(name = 'total')\n",
    "    \n",
    "    # Get Tweets that were retweeted (Grouping by Referenced Tweet ID to avoid duplicating (Counting al retweets and not the original retweeted tweet))\n",
    "    tweets_og_per_user = window_rts.groupby(['Referenced Tweet Author ID', 'Referenced Tweet ID']).agg('size').reset_index()\n",
    "    tweets_og_per_user = tweets_og_per_user.groupby('Referenced Tweet Author ID').size()\n",
    "    tweets_og_per_user.index.astype(int)\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window_rts.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number_of_rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal_weight'] = temp['number_of_rts']/temp['total']\n",
    "    temp['normal_weight'] = temp['normal_weight']\n",
    "    temp.drop(columns='total', inplace=True)\n",
    "    temp.rename(columns = {'Author ID': \"source_user_id\", \"Referenced Tweet Author ID\": \"target_user_id\"}, inplace=True)\n",
    "    \n",
    "    # Assign Index\n",
    "    temp['Source'] = temp['source_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    temp['Target'] = temp['target_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    \n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source_user_id\"].apply(lambda x: id_to_pa[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target_user_id\"].apply(lambda x: id_to_pa[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "    \n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['source_user_id'].apply(lambda x: id_to_label[x])\n",
    "    temp['target_label'] = temp['target_user_id'].apply(lambda x: id_to_label[x])\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'Source': int,\n",
    "        'Target': int,\n",
    "        'number_of_rts': int,\n",
    "        'normal_weight': float,\n",
    "        'source_user_id': 'float64',\n",
    "        'target_user_id': 'float64'\n",
    "    })\n",
    "    columns = list(temp.columns)\n",
    "    columns.remove('Source')\n",
    "    columns.insert(0, 'Source')\n",
    "    columns.remove('Target')\n",
    "    columns.insert(1, 'Target')\n",
    "    temp = temp[columns]\n",
    "\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(path_3_day, \"Source_Target\", 'starting_' + str(d_s.date()) + \".csv\"), index = False, sep = \";\")\n",
    "    \n",
    "def main():\n",
    "    dates = list(zip(date_start, date_end))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_source_target, dates), total = len(dates), desc = \"Guardando Source-Target files: \"))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tic = perf_counter()\n",
    "    main()\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Numero de Arcos: 613,074. Nodos Source: 28,792. Nodos Target 13,979. Total de Nodos 30,443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>17813487.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>alerios</td>\n",
       "      <td>NoticiasCaracol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>25185308.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>sergio_fajardo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>970</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>49681553.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>CamiloRomero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1543</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>59976153.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>Nataliaescribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1936</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>66711542.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>CristoBustos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2185</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>70594101.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>josegreghg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2494</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>76664119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>alerios</td>\n",
       "      <td>vanguardiacom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3855</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>106131505.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>LaCaballero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4952</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>127657219.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>AlfonsoOspina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5526</td>\n",
       "      <td>12996.0</td>\n",
       "      <td>134855279.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>DanielSamperO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target  source_user_id  target_user_id  number_of_rts  \\\n",
       "0       1     191         12996.0      17813487.0              1   \n",
       "1       1     365         12996.0      25185308.0              1   \n",
       "2       1     970         12996.0      49681553.0              2   \n",
       "3       1    1543         12996.0      59976153.0              1   \n",
       "4       1    1936         12996.0      66711542.0              1   \n",
       "5       1    2185         12996.0      70594101.0              1   \n",
       "6       1    2494         12996.0      76664119.0              1   \n",
       "7       1    3855         12996.0     106131505.0              1   \n",
       "8       1    4952         12996.0     127657219.0              1   \n",
       "9       1    5526         12996.0     134855279.0              4   \n",
       "\n",
       "   normal_weight source_political_afilliation target_political_afilliation  \\\n",
       "0       0.029412                    Izquierda               Sin Clasificar   \n",
       "1       0.029412                    Izquierda                       Centro   \n",
       "2       0.058824                    Izquierda                    Izquierda   \n",
       "3       0.029412                    Izquierda                    Izquierda   \n",
       "4       0.029412                    Izquierda                       Centro   \n",
       "5       0.029412                    Izquierda                    Izquierda   \n",
       "6       0.029412                    Izquierda               Sin Clasificar   \n",
       "7       0.029412                    Izquierda                    Izquierda   \n",
       "8       0.029412                    Izquierda                    Izquierda   \n",
       "9       0.117647                    Izquierda                       Centro   \n",
       "\n",
       "  source_label     target_label  \n",
       "0      alerios  NoticiasCaracol  \n",
       "1      alerios   sergio_fajardo  \n",
       "2      alerios     CamiloRomero  \n",
       "3      alerios   Nataliaescribe  \n",
       "4      alerios     CristoBustos  \n",
       "5      alerios       josegreghg  \n",
       "6      alerios    vanguardiacom  \n",
       "7      alerios      LaCaballero  \n",
       "8      alerios    AlfonsoOspina  \n",
       "9      alerios    DanielSamperO  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of our lists\n",
    "ej_csv = pd.read_csv(path_3_day + f'/Source_Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\" Numero de Arcos: {ej_csv.shape[0]:,}. Nodos Source: {len(set(ej_csv['Source'])):,}. Nodos Target {len(set(ej_csv['Target'])):,}. Total de Nodos {len(nodes):,}\")\n",
    "ej_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardando Objetos de Grafos: 100%|ââââââââââ| 61/61 [00:26<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish whole cell in 0.0 minutes and 27 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_graph(file_tuple):\n",
    "    file1, file2 = file_tuple\n",
    "    starting_date_str = file1.split('.')[-2].split('/')[-1].split('_')[-1]\n",
    "    starting_date = datetime.strptime(starting_date_str, '%Y-%m-%d')\n",
    "    ending_date = starting_date + timedelta(days=3)\n",
    "    ending_date_str = ending_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    csv = pd.read_csv(file1, delimiter=';')\n",
    "    \n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(len(master_id))\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "    \n",
    "    for row in csv.itertuples(index = False):\n",
    "        e = g.add_edge(row[0], row[1])\n",
    "        number_of_rts[e] = row[4]\n",
    "        normal_weight[e] = row[5]\n",
    "\n",
    "    g.ep['Number of rts'] = number_of_rts\n",
    "    g.ep['Normal Weight'] = normal_weight\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "\n",
    "    # Create a Vertex property maps\n",
    "    vertex_PA_map = g.new_vertex_property('string')\n",
    "    vertex_ID_map = g.new_vertex_property('double')\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "    vertex_color_map = g.new_vertex_property('string')\n",
    "    vertex_isolate_map = g.new_vertex_property('bool')\n",
    "    vertex_tweets_map = g.new_vertex_property('int64_t')\n",
    "    \n",
    "    # Get Different categories\n",
    "    categories = [cat for cat in set(idx_to_pa.values())]\n",
    "    for cat in categories:\n",
    "        # Create a dummy property map\n",
    "        vertex_dummy_map = g.new_vertex_property('bool')\n",
    "        globals()['map_'+cat] = vertex_dummy_map\n",
    "    \n",
    "    with open(file2, \"rb\") as file:\n",
    "        tweets_per_day = pickle.load(file)\n",
    "\n",
    "    # Assign Labels to vertices using loop (Create one VertexPropertyMap for every Political Label)\n",
    "    for v_index in g.iter_vertices():\n",
    "        v = g.vertex(v_index)\n",
    "        # Add tweets information of users\n",
    "        vertex_tweets_map[v] = tweets_per_day[idx_to_id[v]]\n",
    "        \n",
    "        # Add Master Index Information\n",
    "        vertex_PA_map[v] = idx_to_pa[v]\n",
    "        vertex_ID_map[v] = idx_to_id[v]\n",
    "        vertex_label_map[v] = idx_to_label[v]\n",
    "        vertex_color_map[v] = color[idx_to_pa[v]]\n",
    "        \n",
    "        # Add categories Information\n",
    "        for cat in categories:\n",
    "            if idx_to_pa[v] == cat:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = True\n",
    "                globals()['map_'+cat] = map\n",
    "            else:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = False\n",
    "                globals()['map_'+cat] = map\n",
    "        \n",
    "        # Add isolated\n",
    "        if v.out_degree() == 0 and v.in_degree() == 0:\n",
    "            vertex_isolate_map[v] = True\n",
    "        else: \n",
    "            vertex_isolate_map[v] = False\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_PA_map\n",
    "    g.vp['User ID'] = vertex_ID_map\n",
    "    g.vp['Label'] = vertex_label_map\n",
    "    g.vp['Color'] = vertex_color_map\n",
    "    g.vp['Isolate'] = vertex_isolate_map\n",
    "    g.vp['Tweets'] = vertex_tweets_map\n",
    "    \n",
    "    # Add dummy maps\n",
    "    for cat in categories:\n",
    "        map = globals()['map_'+cat]\n",
    "        g.vp[cat] = map\n",
    "    \n",
    "    # Add graph properties\n",
    "    graph_starting_date = g.new_graph_property('string')\n",
    "    graph_ending_date = g.new_graph_property('string')\n",
    "    graph_starting_date[g] = starting_date_str\n",
    "    graph_ending_date[g] = ending_date_str\n",
    "    g.gp['Starting Date'] = graph_starting_date\n",
    "    g.gp['Ending Date'] = graph_ending_date\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(path_3_day, 'Graphs' ,'starting_' + starting_date_str + \".graphml\")\n",
    "    g.save(filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    source_target_files = glob(os.path.join(path_3_day,\"Source_Target\", \"starting_*.csv\"))\n",
    "    tweets_files = glob(os.path.join(path_3_day,\"Tweets_Per_Day\", \"starting_*.pkl\"))\n",
    "    source_target_files.sort()\n",
    "    tweets_files.sort()\n",
    "    files = list(zip(source_target_files, tweets_files))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_graph, files), total = len(files), desc=\"Guardando Objetos de Grafos: \"))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tic = perf_counter()\n",
    "    main()\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge List\n",
      "Non Isolate Vertices 30,443 and 613,074 edges\n",
      "Graph\n",
      "Non Isolate Vertices 30,443 and 613,074 edges\n"
     ]
    }
   ],
   "source": [
    "print('Edge List')\n",
    "ej_csv = pd.read_csv(path_3_day + f'/Source_Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\"Non Isolate Vertices {len(nodes):,} and {len(ej_csv):,} edges\")\n",
    "\n",
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(path_3_day + f'/Graphs/starting_2021-05-04.graphml')\n",
    "print('Graph')\n",
    "print(f\"Non Isolate Vertices {ej_g.num_vertices() - sum(ej_g.vp['Isolate']):,} and {ej_g.num_edges():,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': <VertexPropertyMap object with value type 'bool', for Graph 0x7f4ab4b736d0, at 0x7f4b48be20d0>,\n",
       " 'Color': <VertexPropertyMap object with value type 'string', for Graph 0x7f4ab4b736d0, at 0x7f4ab4a2be90>,\n",
       " 'Derecha': <VertexPropertyMap object with value type 'bool', for Graph 0x7f4ab4b736d0, at 0x7f4b48aece90>,\n",
       " 'Isolate': <VertexPropertyMap object with value type 'bool', for Graph 0x7f4ab4b736d0, at 0x7f4b48973750>,\n",
       " 'Izquierda': <VertexPropertyMap object with value type 'bool', for Graph 0x7f4ab4b736d0, at 0x7f4b489fa010>,\n",
       " 'Label': <VertexPropertyMap object with value type 'string', for Graph 0x7f4ab4b736d0, at 0x7f4b489f9d10>,\n",
       " 'Political Label': <VertexPropertyMap object with value type 'string', for Graph 0x7f4ab4b736d0, at 0x7f4b488822d0>,\n",
       " 'Sin Clasificar': <VertexPropertyMap object with value type 'bool', for Graph 0x7f4ab4b736d0, at 0x7f4b48882190>,\n",
       " 'Tweets': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7f4ab4b736d0, at 0x7f4b59d36a50>,\n",
       " 'User ID': <VertexPropertyMap object with value type 'double', for Graph 0x7f4ab4b736d0, at 0x7f4b48cd0b10>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos los VertexPropertyMaps\n",
    "dict(ej_g.vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal Weight': <EdgePropertyMap object with value type 'double', for Graph 0x7f4ab4b736d0, at 0x7f4b48cd0d10>,\n",
       " 'Number of rts': <EdgePropertyMap object with value type 'int32_t', for Graph 0x7f4ab4b736d0, at 0x7f4b48cd0cd0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos los EdgePropertyMaps\n",
    "dict(ej_g.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx in Graph: 23631\n",
      "1920140406.0\n",
      "Santialarconu\n",
      "Izquierda\n",
      "blue\n",
      "---------Checking on Master Index----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                               23631\n",
       "Label                    Santialarconu\n",
       "Political Affiliation        Izquierda\n",
       "User ID                   1920140406.0\n",
       "Name: 23631, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(ej_g.vp['User ID'][test_idx])\n",
    "print(ej_g.vp['Label'][test_idx])\n",
    "print(ej_g.vp['Political Label'][test_idx])\n",
    "print(ej_g.vp['Color'][test_idx])\n",
    "print('---------Checking on Master Index----------')\n",
    "master_id.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (584, 21864)\n",
      "Edge In graph: (584, 21864)\n",
      "Normal Weights 0.0052631578947368\n",
      "Number of rts 1\n",
      "--------Value in Edge List---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>584</td>\n",
       "      <td>21864</td>\n",
       "      <td>37698374.0</td>\n",
       "      <td>1.146347e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>jairocor</td>\n",
       "      <td>DefensoyCFM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Source  Target  source_user_id  target_user_id  number_of_rts  \\\n",
       "10283     584   21864      37698374.0    1.146347e+09              1   \n",
       "\n",
       "       normal_weight source_political_afilliation  \\\n",
       "10283       0.005263                      Derecha   \n",
       "\n",
       "      target_political_afilliation source_label target_label  \n",
       "10283                      Derecha     jairocor  DefensoyCFM  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id_source = 37698374\n",
    "test_id_target = 1146346814\n",
    "\n",
    "source_idx = id_to_idx[test_id_source]\n",
    "target_idx = id_to_idx[test_id_target]\n",
    "test_edge_idx = (source_idx, target_idx)\n",
    "\n",
    "edge_index = ej_g.edge_index[test_edge_idx]\n",
    "print(f'Edge: {test_edge_idx}')\n",
    "print(f'Edge In graph: {test_edge_idx}')\n",
    "print(f\"Normal Weights {ej_g.ep['Normal Weight'][test_edge_idx]}\")\n",
    "print(f\"Number of rts {ej_g.ep['Number of rts'][test_edge_idx]}\")\n",
    "print('--------Value in Edge List---------')\n",
    "ej_csv.loc[(ej_csv['Source'] == source_idx) & (ej_csv['Target'] == target_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: Cargar Master ID y retweets edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Master Index in Any case\n",
    "master_id = pd.read_csv('/mnt/disk2/Data/3_Day_Graphs/Master_Index.csv', sep = ';')\n",
    "\n",
    "# Open retweets edge list in any case\n",
    "retweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames\", \"retweets_edge_list.gzip\"), compression = \"gzip\")\n",
    "\n",
    "# Useful Dicts Index to Var\n",
    "idx_to_id = master_id['User ID'].reset_index().to_dict()['User ID']\n",
    "idx_to_pa = master_id['Political Affiliation'].reset_index().to_dict()['Political Affiliation']\n",
    "idx_to_label = master_id['Label'].reset_index().to_dict()['Label']\n",
    "\n",
    "# Useful Dicts User ID to Var\n",
    "id_to_pa = master_id.set_index('User ID')['Political Affiliation'].to_dict()\n",
    "id_to_idx = master_id.set_index('User ID')['ID'].to_dict()\n",
    "id_to_label = master_id.set_index('User ID')['Label'].to_dict()\n",
    "\n",
    "# dict for color\n",
    "color = {\n",
    "    'Izquierda': 'blue',\n",
    "    'Derecha': 'red',\n",
    "    'Centro': 'green',\n",
    "    'Sin Clasificar': 'gray'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have retweets from 2021-04-28 to 2021-06-29\n"
     ]
    }
   ],
   "source": [
    "fecha_min = retweets[\"Date\"].min()\n",
    "fecha_max = retweets[\"Date\"].max()\n",
    "print(f\"We have retweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get original Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardando Tweets Originales: 100%|ââââââââââ| 63/63 [00:03<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish whole cell in 0.0 minutes and 5 secs.\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_pickle(os.path.join(path,\"Tweets_DataFrames\",\"original.gzip\"), compression='gzip')\n",
    "\n",
    "# Get the amount of tweets for each day\n",
    "def create_tweets_per_day(date):\n",
    "    window = original[original['Date'] == date.date()]\n",
    "    \n",
    "    # CAlculate number of tweets\n",
    "    tweets_per_user = window.groupby('Author ID').size().reset_index(name = 'Original Tweets')\n",
    "    tweets_per_user.rename(columns = {'Author ID': 'User ID'}, inplace=True)\n",
    "    \n",
    "    # Merge with master Index to get the tweets of relevant people\n",
    "    tweets_per_user = tweets_per_user.merge(master_id, on='User ID', how = 'right')\n",
    "    \n",
    "    # Filling na as 0 (No original tweet registerd)\n",
    "    tweets_per_user.fillna(0, inplace=True)\n",
    "    tweets_per_user.set_index('User ID', inplace = True)\n",
    "    \n",
    "    id_to_tweets = tweets_per_user.to_dict()['Original Tweets']\n",
    "    filename = os.path.join(path_daily, 'Tweets_Per_Day', f'starting_{str(date.date())}' + \".pkl\")\n",
    "    \n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(id_to_tweets,file)\n",
    "    \n",
    "\n",
    "def main(daily_grid):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_tweets_per_day, daily_grid), total = len(daily_grid), desc= \"Guardando Tweets Originales: \"))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tic = perf_counter()\n",
    "    main(daily_grid)\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Guardando Source-Target files: 100%|ââââââââââ| 63/63 [00:09<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish whole cell in 0.0 minutes and 10 secs.\n"
     ]
    }
   ],
   "source": [
    "def create_source_target(date):\n",
    "    window_rts = retweets[retweets['Date'] == date.date()]\n",
    "    \n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window_rts.groupby('Author ID').size().reset_index(name = 'total')\n",
    "    \n",
    "    # Get Tweets that were retweeted (Grouping by Referenced Tweet to avoid duplicating (Counting al retweets and not the original retweeted tweet))\n",
    "    tweets_og_per_user = window_rts.groupby(['Referenced Tweet Author ID', 'Referenced Tweet ID']).agg('size').reset_index()\n",
    "    tweets_og_per_user = tweets_og_per_user.groupby('Referenced Tweet Author ID').size()\n",
    "    tweets_og_per_user.index.astype(int)\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window_rts.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number_of_rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal_weight'] = temp['number_of_rts']/temp['total']\n",
    "    temp['normal_weight'] = temp['normal_weight']\n",
    "    temp.drop(columns='total', inplace=True)\n",
    "    temp.rename(columns = {'Author ID': \"source_user_id\", \"Referenced Tweet Author ID\": \"target_user_id\"}, inplace=True)\n",
    "    \n",
    "    # Assign Index\n",
    "    temp['Source'] = temp['source_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    temp['Target'] = temp['target_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    \n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source_user_id\"].apply(lambda x: id_to_pa[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target_user_id\"].apply(lambda x: id_to_pa[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "    \n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['source_user_id'].apply(lambda x: id_to_label[x])\n",
    "    temp['target_label'] = temp['target_user_id'].apply(lambda x: id_to_label[x])\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'Source': int,\n",
    "        'Target': int,\n",
    "        'number_of_rts': int,\n",
    "        'normal_weight': float,\n",
    "        'source_user_id': 'float64',\n",
    "        'target_user_id': 'float64'\n",
    "    })\n",
    "    columns = list(temp.columns)\n",
    "    columns.remove('Source')\n",
    "    columns.insert(0, 'Source')\n",
    "    columns.remove('Target')\n",
    "    columns.insert(1, 'Target')\n",
    "    temp = temp[columns]\n",
    "\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(path_daily, \"Source-Target\", 'starting_' + str(date.date()) + \".csv\"), index = False, sep = \";\")\n",
    "    \n",
    "def main(daily_grid):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_source_target, daily_grid), total = len(daily_grid),desc=\"Guardando Source-Target files: \"))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tic = perf_counter()\n",
    "    main(daily_grid)\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 63/63 [00:13<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish whole cell in 0.0 minutes and 15 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_graph(file_tuple):\n",
    "    file1, file2 = file_tuple\n",
    "    date_str = file1.split('.')[-2].split('/')[-1].split('_')[-1]\n",
    "    \n",
    "    csv = pd.read_csv(file1, delimiter=';')\n",
    "    \n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(len(master_id))\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "    \n",
    "    for row in csv.itertuples(index = False):\n",
    "        e = g.add_edge(row[0], row[1])\n",
    "        number_of_rts[e] = row[4]\n",
    "        normal_weight[e] = row[5]\n",
    "\n",
    "    g.ep['Number of rts'] = number_of_rts\n",
    "    g.ep['Normal Weight'] = normal_weight\n",
    "\n",
    "    # Create a Vertex property maps\n",
    "    vertex_PA_map = g.new_vertex_property('string')\n",
    "    vertex_ID_map = g.new_vertex_property('double')\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "    vertex_color_map = g.new_vertex_property('string')\n",
    "    vertex_isolate_map = g.new_vertex_property('bool')\n",
    "    vertex_tweets_map = g.new_vertex_property('int64_t')\n",
    "    \n",
    "    # Get Different categories\n",
    "    categories = [cat for cat in set(idx_to_pa.values())]\n",
    "    for cat in categories:\n",
    "        # Create a dummy property map\n",
    "        vertex_dummy_map = g.new_vertex_property('bool')\n",
    "        globals()['map_'+cat] = vertex_dummy_map\n",
    "    \n",
    "    with open(file2, \"rb\") as file:\n",
    "        tweets_per_day = pickle.load(file)\n",
    "\n",
    "    # Assign Labels to vertices using loop (Create one VertexPropertyMap for every Political Label)\n",
    "    for v_index in g.iter_vertices():\n",
    "        v = g.vertex(v_index)\n",
    "        # Add tweets information of users\n",
    "        vertex_tweets_map[v] = tweets_per_day[idx_to_id[v]]\n",
    "        \n",
    "        # Add Master Index Information\n",
    "        vertex_PA_map[v] = idx_to_pa[v]\n",
    "        vertex_ID_map[v] = idx_to_id[v]\n",
    "        vertex_label_map[v] = idx_to_label[v]\n",
    "        vertex_color_map[v] = color[idx_to_pa[v]]\n",
    "        \n",
    "        # Add categories Information\n",
    "        for cat in categories:\n",
    "            if idx_to_pa[v] == cat:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = True\n",
    "                globals()['map_'+cat] = map\n",
    "            else:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = False\n",
    "                globals()['map_'+cat] = map\n",
    "        \n",
    "        # Add isolated\n",
    "        if v.out_degree() == 0 and v.in_degree() == 0:\n",
    "            vertex_isolate_map[v] = True\n",
    "        else: \n",
    "            vertex_isolate_map[v] = False\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_PA_map\n",
    "    g.vp['User ID'] = vertex_ID_map\n",
    "    g.vp['Label'] = vertex_label_map\n",
    "    g.vp['Color'] = vertex_color_map\n",
    "    g.vp['Isolate'] = vertex_isolate_map\n",
    "    g.vp['Tweets'] = vertex_tweets_map\n",
    "    \n",
    "    # Add dummy maps\n",
    "    for cat in categories:\n",
    "        map = globals()['map_'+cat]\n",
    "        g.vp[cat] = map\n",
    "    \n",
    "    # Add graph properties\n",
    "    graph_date_map = g.new_graph_property('string')\n",
    "    graph_date_map[g] = date_str\n",
    "    g.gp['Date'] = graph_date_map\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(path_daily, 'Graphs' ,'starting_' + date_str + \".graphml\")\n",
    "    g.save(filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    source_target_files = glob(os.path.join(path_daily,\"Source-Target\",\"starting_*.csv\"))\n",
    "    tweets_files = glob(os.path.join(path_daily,\"Tweets_Per_Day\",\"starting_*.pkl\"))\n",
    "    source_target_files.sort()\n",
    "    tweets_files.sort()\n",
    "    files = list(zip(source_target_files, tweets_files))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = list(tqdm(executor.map(create_graph, files), total = len(files)))\n",
    "    return futures\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tic = perf_counter()\n",
    "    main()\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge List\n",
      "Non Isolate Vertices 25,960 and 278,382 edges\n",
      "Graph\n",
      "Non Isolate Vertices 25,960 and 278,382 edges\n"
     ]
    }
   ],
   "source": [
    "print('Edge List')\n",
    "ej_csv = pd.read_csv(path_daily + f'/Source-Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\"Non Isolate Vertices {len(nodes):,} and {len(ej_csv):,} edges\")\n",
    "\n",
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(path_daily + f'/Graphs/starting_2021-05-04.graphml')\n",
    "print('Graph')\n",
    "print(f\"Non Isolate Vertices {ej_g.num_vertices() - sum(ej_g.vp['Isolate']):,} and {ej_g.num_edges():,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': <VertexPropertyMap object with value type 'bool', for Graph 0x7fd27fa1dc10, at 0x7fd1ba23fd90>,\n",
       " 'Color': <VertexPropertyMap object with value type 'string', for Graph 0x7fd27fa1dc10, at 0x7fd234b743d0>,\n",
       " 'Derecha': <VertexPropertyMap object with value type 'bool', for Graph 0x7fd27fa1dc10, at 0x7fd1be2632d0>,\n",
       " 'Isolate': <VertexPropertyMap object with value type 'bool', for Graph 0x7fd27fa1dc10, at 0x7fd2346f1210>,\n",
       " 'Izquierda': <VertexPropertyMap object with value type 'bool', for Graph 0x7fd27fa1dc10, at 0x7fd265b06850>,\n",
       " 'Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fd27fa1dc10, at 0x7fd265b06990>,\n",
       " 'Political Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fd27fa1dc10, at 0x7fd265a43b10>,\n",
       " 'Sin Clasificar': <VertexPropertyMap object with value type 'bool', for Graph 0x7fd27fa1dc10, at 0x7fd265a43c50>,\n",
       " 'Tweets': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fd27fa1dc10, at 0x7fd265a43d10>,\n",
       " 'User ID': <VertexPropertyMap object with value type 'double', for Graph 0x7fd27fa1dc10, at 0x7fd265a43dd0>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos los VertexPropertyMaps\n",
    "dict(ej_g.vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal Weight': <EdgePropertyMap object with value type 'double', for Graph 0x7fd27fa1dc10, at 0x7fd265a43e90>,\n",
       " 'Number of rts': <EdgePropertyMap object with value type 'int32_t', for Graph 0x7fd27fa1dc10, at 0x7fd265a43f50>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos los EdgePropertyMaps\n",
    "dict(ej_g.ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx in Graph: 23631\n",
      "1920140406.0\n",
      "Santialarconu\n",
      "Izquierda\n",
      "blue\n",
      "---------Checking on Master Index----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                               23631\n",
       "Label                    Santialarconu\n",
       "Political Affiliation        Izquierda\n",
       "User ID                   1920140406.0\n",
       "Name: 23631, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(ej_g.vp['User ID'][test_idx])\n",
    "print(ej_g.vp['Label'][test_idx])\n",
    "print(ej_g.vp['Political Label'][test_idx])\n",
    "print(ej_g.vp['Color'][test_idx])\n",
    "print('---------Checking on Master Index----------')\n",
    "master_id.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (584, 21864)\n",
      "Edge In graph: (584, 21864)\n",
      "Normal Weights 0.0133333333333333\n",
      "Number of rts 1\n",
      "--------Value in Edge List---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>584</td>\n",
       "      <td>21864</td>\n",
       "      <td>37698374.0</td>\n",
       "      <td>1.146347e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>jairocor</td>\n",
       "      <td>DefensoyCFM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Source  Target  source_user_id  target_user_id  number_of_rts  \\\n",
       "4502     584   21864      37698374.0    1.146347e+09              1   \n",
       "\n",
       "      normal_weight source_political_afilliation target_political_afilliation  \\\n",
       "4502       0.013333                      Derecha                      Derecha   \n",
       "\n",
       "     source_label target_label  \n",
       "4502     jairocor  DefensoyCFM  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id_source = 37698374\n",
    "test_id_target = 1146346814\n",
    "\n",
    "source_idx = id_to_idx[test_id_source]\n",
    "target_idx = id_to_idx[test_id_target]\n",
    "test_edge_idx = (source_idx, target_idx)\n",
    "\n",
    "edge_index = ej_g.edge_index[test_edge_idx]\n",
    "print(f'Edge: {test_edge_idx}')\n",
    "print(f'Edge In graph: {test_edge_idx}')\n",
    "print(f\"Normal Weights {ej_g.ep['Normal Weight'][test_edge_idx]}\")\n",
    "print(f\"Number of rts {ej_g.ep['Number of rts'][test_edge_idx]}\")\n",
    "print('--------Value in Edge List---------')\n",
    "ej_csv.loc[(ej_csv['Source'] == source_idx) & (ej_csv['Target'] == target_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No me acuerdo pa que era esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 63/63 [06:57<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "graphs = glob(os.path.join(path_daily, 'Graphs','*.graphml'))\n",
    "\n",
    "rts_node_day = pd.DataFrame(columns=daily_grid, index=range(len(master_id)))\n",
    "tweets_node_day = pd.DataFrame(columns=daily_grid, index=range(len(master_id)))\n",
    "for graph in tqdm(graphs):\n",
    "    g = gt.load_graph(graph)\n",
    "    date = g.gp['Date']\n",
    "    \n",
    "    for v in g.vertices():\n",
    "        row = int(v)\n",
    "        number_of_rts = sum(g.ep['Number of rts'][e] for e in v.out_edges())\n",
    "        tweets = g.vp['Tweets'][v]\n",
    "        \n",
    "        rts_node_day.loc[row,date] = number_of_rts\n",
    "        tweets_node_day.loc[row,date] = tweets\n",
    "\n",
    "rts_node_day.to_pickle(os.path.join(path,\"Pickle\",\"rts_node_day.pkl\"))\n",
    "tweets_node_day.to_pickle(os.path.join(path,\"Pickle\",\"tweets_node_day.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
