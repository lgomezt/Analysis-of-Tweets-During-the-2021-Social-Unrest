{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we create a daily retweet network. First, we transform our dataset into a Source-Target DataFrame. Afterward, we construct a `graph-tool` object.\n",
    "\n",
    "We have 45,330,718 Tweets from 37330 from which 30,918,011 are ReTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/anaconda3/envs/gt_global/lib/python3.11/site-packages/graph_tool/draw/cairo_draw.py:1544: RuntimeWarning: Error importing Gtk module: ; GTK+ drawing will not work.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Mathematical and Data Managment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Graph Managment\n",
    "import graph_tool.all as gt\n",
    "from utils.Functions import *\n",
    "\n",
    "# Miscellaneous\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/3_Day_Graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 30,918,011 Retweets, 45,330,718 Tweets, 624,358 Rewitteros y 5,759,089 Twitteros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>1.348553e+08</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.409586e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>1.131821e+09</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.409192e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>6.233750e+07</td>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.409298e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>5.766474e+08</td>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.407171e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>1.268326e+08</td>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.406750e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author ID  Author Name  Referenced Tweet Author ID        Date  \\\n",
       "0  138377765.0  hmauriciojg                1.348553e+08  2021-06-28   \n",
       "1  138377765.0  hmauriciojg                1.131821e+09  2021-06-28   \n",
       "2  138377765.0  hmauriciojg                6.233750e+07  2021-06-27   \n",
       "3  138377765.0  hmauriciojg                5.766474e+08  2021-06-22   \n",
       "4  138377765.0  hmauriciojg                1.268326e+08  2021-06-21   \n",
       "\n",
       "  Reference Type  Referenced Tweet  \n",
       "0     replied_to      1.409586e+18  \n",
       "1     replied_to      1.409192e+18  \n",
       "2     replied_to      1.409298e+18  \n",
       "3     replied_to      1.407171e+18  \n",
       "4     replied_to      1.406750e+18  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Tweets\n",
    "tweets = pd.read_pickle('../../../Data/Tweets_DataFrames/tweets_lite.gzip', compression='gzip')\n",
    "tweets = tweets.astype({\n",
    "    'Author ID': float,\n",
    "    'Referenced Tweet Author ID': float\n",
    "})\n",
    "# Fix date\n",
    "tweets[\"Date\"] = pd.to_datetime(tweets[\"Date\"], errors='coerce').dt.date\n",
    "\n",
    "# get retweets\n",
    "retweets = tweets[tweets['Reference Type'] == 'retweeted']\n",
    "\n",
    "# Count Users and tweets\n",
    "users_that_retweet = set(retweets['Author ID']).union()\n",
    "users_retweeted = set(retweets['Referenced Tweet Author ID'])\n",
    "retweets_users = users_retweeted.union(users_that_retweet)\n",
    "tweets_users = set(tweets['Author ID']).union(set(tweets['Referenced Tweet Author ID']))\n",
    "\n",
    "print(f\"Tenemos: {len(retweets):,} Retweets, {len(tweets):,} Tweets, {len(retweets_users):,} Rewitteros y {len(tweets_users):,} Twitteros\")\n",
    "del tweets_users, retweets_users, users_retweeted, users_that_retweet\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faltan clasificar 587,246 usuarios\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Political Affiliation\n",
       "NaN               587246\n",
       "Izquierda          23138\n",
       "Derecha             6812\n",
       "Sin Clasificar      3844\n",
       "Centro              3543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"../../../Data/Pickle/user_to_party_paro.pkl\")\n",
    "\n",
    "ids_faltantes1 = set(retweets[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(retweets[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(np.unique(ids_faltantes)):,} usuarios\")\n",
    "\n",
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan\n",
    "\n",
    "affilliation_df = pd.DataFrame(list(user_to_party_paro.items()), columns=['User ID', 'Political Affiliation'])\n",
    "affilliation_df['Political Affiliation'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated IDs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37339</th>\n",
       "      <td>1.389722e+18</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>1.389737e+18</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37341</th>\n",
       "      <td>1.389741e+18</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37342</th>\n",
       "      <td>1.389769e+18</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>1.389784e+18</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37337 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            User ID           Label Political Affiliation\n",
       "0      0.000000e+00               0        Sin Clasificar\n",
       "1      1.000000e+00               0        Sin Clasificar\n",
       "2      2.000000e+00               0        Sin Clasificar\n",
       "3      3.000000e+00               0        Sin Clasificar\n",
       "5      4.000000e+00               0        Sin Clasificar\n",
       "...             ...             ...                   ...\n",
       "37339  1.389722e+18  Neoplasticista             Izquierda\n",
       "37340  1.389737e+18      JC13177979               Derecha\n",
       "37341  1.389741e+18   JhonatanVRojo        Sin Clasificar\n",
       "37342  1.389769e+18       VaneLen18             Izquierda\n",
       "37343  1.389784e+18        kars0518             Izquierda\n",
       "\n",
       "[37337 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Master Id\n",
    "del affilliation_df,ids_faltantes, ids_faltantes1, ids_faltantes2, usuario\n",
    "users_information = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/users_information.gzip', compression='gzip')\n",
    "master_id = users_information.reset_index()[['Author ID', 'Author Name']]\n",
    "master_id = master_id.rename(columns={\n",
    "    'Author ID': 'User ID',\n",
    "    'Author Name': 'Label'\n",
    "})\n",
    "del users_information\n",
    "master_id['Political Affiliation'] = master_id['User ID'].apply(lambda x: user_to_party_paro[x])\n",
    "print(f\"Duplicated IDs: {sum(master_id.duplicated(subset = 'User ID'))}\")\n",
    "master_id = master_id.drop_duplicates(subset = 'User ID')\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 17,761,847 tweets, 13,784,608 retweets\n",
      "Tenemos: 37,112 Usuarios con Rts o Retwiteados. Usuarios sin tweets 225\n",
      "Tenemos: 2,309,812 Tweets referenciados (Originales)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Source Label</th>\n",
       "      <th>Source PA</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>134855279.0</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.409586e+18</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>134855279.0</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.397903e+18</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>134855279.0</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.390699e+18</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>134855279.0</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.389664e+18</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>134855279.0</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.389664e+18</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>Centro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author ID  Author Name  Referenced Tweet Author ID        Date  \\\n",
       "0  138377765.0  hmauriciojg                 134855279.0  2021-06-28   \n",
       "1  138377765.0  hmauriciojg                 134855279.0  2021-05-27   \n",
       "2  138377765.0  hmauriciojg                 134855279.0  2021-05-07   \n",
       "3  138377765.0  hmauriciojg                 134855279.0  2021-05-04   \n",
       "4  138377765.0  hmauriciojg                 134855279.0  2021-05-04   \n",
       "\n",
       "  Reference Type  Referenced Tweet Source Label       Source PA  \\\n",
       "0     replied_to      1.409586e+18  hmauriciojg  Sin Clasificar   \n",
       "1     replied_to      1.397903e+18  hmauriciojg  Sin Clasificar   \n",
       "2     replied_to      1.390699e+18  hmauriciojg  Sin Clasificar   \n",
       "3     replied_to      1.389664e+18  hmauriciojg  Sin Clasificar   \n",
       "4     replied_to      1.389664e+18  hmauriciojg  Sin Clasificar   \n",
       "\n",
       "    Target Label Target PA  \n",
       "0  DanielSamperO    Centro  \n",
       "1  DanielSamperO    Centro  \n",
       "2  DanielSamperO    Centro  \n",
       "3  DanielSamperO    Centro  \n",
       "4  DanielSamperO    Centro  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Source Labels\n",
    "temp = tweets.merge(master_id, how = 'inner', left_on = 'Author ID', right_on='User ID', validate = 'm:1')\n",
    "temp = temp.rename(columns = {'Label': 'Source Label', 'Political Affiliation': 'Source PA'}).drop(columns='User ID')\n",
    "\n",
    "# Adding Target Labels\n",
    "tweets = temp.merge(master_id, how = 'inner', left_on = 'Referenced Tweet Author ID', right_on='User ID', validate = 'm:1')\n",
    "tweets = tweets.rename(columns = {'Label': 'Target Label', 'Political Affiliation': 'Target PA'})\n",
    "\n",
    "tweets = tweets.drop(columns= ['User ID'])\n",
    "\n",
    "# Count how many tweets and users we have now\n",
    "users_rts = set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID']))\n",
    "non_singletons = master_id[master_id['User ID'].isin(users_rts)] # Nodes conected by a Rt\n",
    "singletons = master_id[~master_id['User ID'].isin(users_rts)] # Nodes that aren't in Rts during Paro (Perhaps only Twitted or Retwitted with replies) \n",
    "\n",
    "# Insights\n",
    "print(f\"Tenemos: {tweets.shape[0]:,} tweets, {len(tweets[tweets['Reference Type'] == 'retweeted']):,} retweets\")\n",
    "print(f\"Tenemos: {len(non_singletons):,} Usuarios con Rts o Retwiteados. Usuarios sin tweets {len(singletons)}\")\n",
    "print(f\"Tenemos: {len(tweets['Referenced Tweet'].unique()):,} Tweets referenciados (Originales)\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "      <th>User ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>alerios</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>12996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ranaberden</td>\n",
       "      <td>Centro</td>\n",
       "      <td>777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jsanti</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>784125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>thisgoblin</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1061601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36959</th>\n",
       "      <td>36959</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1389721694961651712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36960</th>\n",
       "      <td>36960</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>1389737202742071296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36961</th>\n",
       "      <td>36961</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>1389741234370064384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>36962</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1389769251704147968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>36963</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>1389784145417678848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36964 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID           Label Political Affiliation              User ID\n",
       "0          0               0        Sin Clasificar                   12\n",
       "1          1         alerios             Izquierda                12996\n",
       "2          2      ranaberden                Centro               777978\n",
       "3          3          jsanti             Izquierda               784125\n",
       "4          4      thisgoblin             Izquierda              1061601\n",
       "...      ...             ...                   ...                  ...\n",
       "36959  36959  Neoplasticista             Izquierda  1389721694961651712\n",
       "36960  36960      JC13177979               Derecha  1389737202742071296\n",
       "36961  36961   JhonatanVRojo        Sin Clasificar  1389741234370064384\n",
       "36962  36962       VaneLen18             Izquierda  1389769251704147968\n",
       "36963  36963        kars0518             Izquierda  1389784145417678848\n",
       "\n",
       "[36964 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save this Dataframe for Nodes List\n",
    "master_id = non_singletons # Aislamos a los singletons del Master ID\n",
    "master_id = master_id.astype({\n",
    "    'User ID': int,\n",
    "    'Label': str,\n",
    "    'Political Affiliation': str\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "master_id = master_id.reset_index().rename(columns = {'index': 'ID'})\n",
    "id_to_label = master_id.set_index('User ID').to_dict()['Label']\n",
    "\n",
    "master_id = master_id[['ID', 'Label', 'Political Affiliation', 'User ID']]\n",
    "\n",
    "# Save\n",
    "master_id.to_csv(os.path.join(save_path, 'Master_Index' + \".csv\"), index = False, sep = \";\")\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos Retweeteados por alguien pero que no Retweetean: 6,510\n",
      "Nodos que Retweetean a alguien pero no son Retweeteados: 833\n",
      "Nodos que tienen un self loop: 10\n",
      "primer nodo: 12.0 último nodo: 1.3897841454176788e+18\n",
      "Total de nodos en conectados: 36,964\n",
      "Total de nodos Singletons: 373\n",
      "Total de usuarios que TWITTEARON Durante el paro: 37,337\n"
     ]
    }
   ],
   "source": [
    "# Insights using only retweets\n",
    "nodes_no_receipt = set(retweets[\"Author ID\"]) -  set(retweets[\"Referenced Tweet Author ID\"])\n",
    "nodes_no_send = set(retweets[\"Referenced Tweet Author ID\"]) - set(retweets[\"Author ID\"])\n",
    "self_loops = set(retweets[retweets['Author ID'] == retweets['Referenced Tweet Author ID']])\n",
    "\n",
    "print(f'Nodos Retweeteados por alguien pero que no Retweetean: {len(nodes_no_receipt):,}')\n",
    "print(f'Nodos que Retweetean a alguien pero no son Retweeteados: {len(nodes_no_send):,}')\n",
    "print(f'Nodos que tienen un self loop: {len(self_loops)}')\n",
    "\n",
    "print(f'primer nodo: {min(users_rts)} último nodo: {max(users_rts):,}')\n",
    "print(f'Total de nodos en conectados: {len(users_rts):,}')\n",
    "print(f'Total de nodos Singletons: {len(singletons):,}')\n",
    "print(f'Total de usuarios que TWITTEARON Durante el paro: {len(singletons) + len(non_singletons):,}')\n",
    "\n",
    "del nodes_no_receipt, nodes_no_send, self_loops, users_rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Master Index in Any case\n",
    "master_id = pd.read_csv('/mnt/disk2/Data/3_Day_Graphs/Master_Index.csv', sep = ';')\n",
    "\n",
    "# Useful Dicts\n",
    "idx_to_id = master_id['User ID'].reset_index().to_dict()['User ID']\n",
    "idx_to_pa = master_id['Political Affiliation'].reset_index().to_dict()['Political Affiliation']\n",
    "idx_to_label = master_id['Label'].reset_index().to_dict()['Label']\n",
    "\n",
    "# Dict for lookup in Graph\n",
    "id_to_idx = {id:idx for idx, id in idx_to_id.items()}\n",
    "\n",
    "# dict for color\n",
    "color = {\n",
    "    'Izquierda': 'blue',\n",
    "    'Derecha': 'red',\n",
    "    'Centro': 'green',\n",
    "    'Sin Clasificar': 'gray'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date_start = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "del v1_end, v1_start\n",
    "\n",
    "v2_start = '2021-05-01 23:59:59'\n",
    "v2_end = '2021-06-30 23:59:59'\n",
    "date_end = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "del v2_start, v2_end\n",
    "\n",
    "# date_start = date_start[7:8]\n",
    "# date_end = date_end[7:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_idx(x):\n",
    "    try:\n",
    "        return int(id_to_idx[x])\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "# Get the amount of tweets for each day\n",
    "def create_tweets_per_day(date_tuple):\n",
    "    d_s, d_e = date_tuple\n",
    "    window = tweets[(tweets['Date'] >= d_s.date()) & (tweets['Date'] < d_e.date())]\n",
    "    window_rts = window[window['Reference Type'] == 'retweeted']\n",
    "    \n",
    "    # Get Tweets that were retweeted (Grouping by Referenced Tweet to avoid duplicating (Counting al retweets and not the original retweeted tweet))\n",
    "    tweets_og_per_user = window_rts.groupby(['Referenced Tweet Author ID', 'Referenced Tweet']).agg('size').reset_index()\n",
    "    tweets_og_per_user = tweets_og_per_user.groupby('Referenced Tweet Author ID').size()\n",
    "    tweets_og_per_user.index.astype(int)\n",
    "    temp = tweets_og_per_user.reset_index(name = 'tweet').rename(columns={'Referenced Tweet Author ID': 'User ID'})\n",
    "\n",
    "    # Pivot table\n",
    "    tweets_per_user = window.pivot_table(index='Author ID', columns='Reference Type', aggfunc='size', fill_value=0).reset_index()\n",
    "    tweets_per_user = tweets_per_user.rename(columns = {'Author ID': 'User ID'})\n",
    "    tweets_per_user = tweets_per_user.astype({'User ID': int})\n",
    "    \n",
    "    # Add Master Id Index and remove people that aren't there\n",
    "    tweets_per_user['ID'] = tweets_per_user['User ID'].apply(lambda x: put_idx(x))\n",
    "    tweets_per_user['ID'] = tweets_per_user['ID'].fillna(-1).astype(int)\n",
    "    tweets_per_user = tweets_per_user[tweets_per_user['ID'] != -1]\n",
    "    tweets_per_user.columns.name = None\n",
    "    \n",
    "    # Add other nodes from master Index\n",
    "    tweets_per_user = tweets_per_user.merge(master_id[['ID', 'User ID']], on='ID', how = 'outer').drop(columns = 'User ID_x')\n",
    "    tweets_per_user = tweets_per_user.rename(columns = {'User ID_y': 'User ID'})\n",
    "    tweets_per_user = tweets_per_user.merge(temp, on='User ID', how = 'outer')\n",
    "    tweets_per_user.fillna(0, inplace=True)\n",
    "    tweets_per_user.set_index('ID', inplace=True)\n",
    "    \n",
    "    tweets_per_user = tweets_per_user.astype({\n",
    "        'quoted': int,\n",
    "        'replied_to': int,\n",
    "        'retweeted': int,\n",
    "        'tweet': int,\n",
    "        'User ID': int\n",
    "    })\n",
    "    tweets_per_user = tweets_per_user[['User ID', 'replied_to', 'quoted', 'retweeted', 'tweet']]\n",
    " \n",
    "    # Save file\n",
    "    filename = os.path.join(save_path, 'Tweets_Per_Day', f'starting_{str(d_s.date())}' + \".csv\")\n",
    "    tweets_per_user.to_csv(filename, sep = \";\")\n",
    "    \n",
    "\n",
    "def main():\n",
    "    dates = list(zip(date_start, date_end))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        executor.map(create_tweets_per_day, dates)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_target(date_tuple):\n",
    "    d_s, d_e = date_tuple\n",
    "    # Get 3 days Retweets\n",
    "    window_rts = retweets[(retweets['Date'] >= d_s.date()) & (retweets['Date'] < d_e.date())]\n",
    "    \n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window_rts.groupby('Author ID').size().reset_index(name = 'total')\n",
    "    \n",
    "    # Get Tweets that were retweeted (Grouping by Referenced Tweet to avoid duplicating (Counting al retweets and not the original retweeted tweet))\n",
    "    tweets_og_per_user = window_rts.groupby(['Referenced Tweet Author ID', 'Referenced Tweet']).agg('size').reset_index()\n",
    "    tweets_og_per_user = tweets_og_per_user.groupby('Referenced Tweet Author ID').size()\n",
    "    tweets_og_per_user.index.astype(int)\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window_rts.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number_of_rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal_weight'] = temp['number_of_rts']/temp['total']\n",
    "    temp['normal_weight'] = temp['normal_weight']\n",
    "    temp.drop(columns='total', inplace=True)\n",
    "    temp.rename(columns = {'Author ID': \"source_user_id\", \"Referenced Tweet Author ID\": \"target_user_id\"}, inplace=True)\n",
    "    \n",
    "    # Assign Index\n",
    "    temp['Source'] = temp['source_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    temp['Target'] = temp['target_user_id'].apply(lambda x: int(id_to_idx[x]))\n",
    "    \n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source_user_id\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target_user_id\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "    \n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['source_user_id'].apply(lambda x: id_to_label[x])\n",
    "    temp['target_label'] = temp['target_user_id'].apply(lambda x: id_to_label[x])\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'Source': int,\n",
    "        'Target': int,\n",
    "        'number_of_rts': int,\n",
    "        'normal_weight': float,\n",
    "        'source_user_id': int,\n",
    "        'target_user_id': int\n",
    "    })\n",
    "    columns = list(temp.columns)\n",
    "    columns.remove('Source')\n",
    "    columns.insert(0, 'Source')\n",
    "    columns.remove('Target')\n",
    "    columns.insert(1, 'Target')\n",
    "    temp = temp[columns]\n",
    "\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source_Target\", 'starting_' + str(d_s.date()) + \".csv\"), index = False, sep = \";\")\n",
    "    \n",
    "def main():\n",
    "    dates = list(zip(date_start, date_end))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        executor.map(create_source_target, dates)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Numero de Arcos: 234,657. Nodos Source: 24,254. Nodos Target 8,981. Total de Nodos 26,015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1140</td>\n",
       "      <td>12996</td>\n",
       "      <td>53855557</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>CathyJuvinao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1712</td>\n",
       "      <td>12996</td>\n",
       "      <td>62528273</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>AntonioSanguino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1939</td>\n",
       "      <td>12996</td>\n",
       "      <td>66740100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Sin Clasificar</td>\n",
       "      <td>alerios</td>\n",
       "      <td>ZuluagaCamila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3504</td>\n",
       "      <td>12996</td>\n",
       "      <td>98781946</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>IvanCepedaCast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3782</td>\n",
       "      <td>12996</td>\n",
       "      <td>104622520</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>valentinabz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6170</td>\n",
       "      <td>12996</td>\n",
       "      <td>142448269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>maryluzherran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7882</td>\n",
       "      <td>12996</td>\n",
       "      <td>165748292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Centro</td>\n",
       "      <td>alerios</td>\n",
       "      <td>angelamrobledo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>9727</td>\n",
       "      <td>12996</td>\n",
       "      <td>201256928</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>marthaperaltae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10570</td>\n",
       "      <td>12996</td>\n",
       "      <td>221466950</td>\n",
       "      <td>4</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>wilsonariasc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>11057</td>\n",
       "      <td>12996</td>\n",
       "      <td>233001872</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>alerios</td>\n",
       "      <td>jorgerojas2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target  source_user_id  target_user_id  number_of_rts  \\\n",
       "0       1    1140           12996        53855557              1   \n",
       "1       1    1712           12996        62528273              1   \n",
       "2       1    1939           12996        66740100              1   \n",
       "3       1    3504           12996        98781946              2   \n",
       "4       1    3782           12996       104622520              1   \n",
       "5       1    6170           12996       142448269              1   \n",
       "6       1    7882           12996       165748292              1   \n",
       "7       1    9727           12996       201256928              1   \n",
       "8       1   10570           12996       221466950              4   \n",
       "9       1   11057           12996       233001872              1   \n",
       "\n",
       "   normal_weight source_political_afilliation target_political_afilliation  \\\n",
       "0       0.027778                    Izquierda                       Centro   \n",
       "1       0.027778                    Izquierda                       Centro   \n",
       "2       0.027778                    Izquierda               Sin Clasificar   \n",
       "3       0.055556                    Izquierda                    Izquierda   \n",
       "4       0.027778                    Izquierda                    Izquierda   \n",
       "5       0.027778                    Izquierda                    Izquierda   \n",
       "6       0.027778                    Izquierda                       Centro   \n",
       "7       0.027778                    Izquierda                    Izquierda   \n",
       "8       0.111111                    Izquierda                    Izquierda   \n",
       "9       0.027778                    Izquierda                    Izquierda   \n",
       "\n",
       "  source_label     target_label  \n",
       "0      alerios     CathyJuvinao  \n",
       "1      alerios  AntonioSanguino  \n",
       "2      alerios    ZuluagaCamila  \n",
       "3      alerios   IvanCepedaCast  \n",
       "4      alerios      valentinabz  \n",
       "5      alerios    maryluzherran  \n",
       "6      alerios   angelamrobledo  \n",
       "7      alerios   marthaperaltae  \n",
       "8      alerios     wilsonariasc  \n",
       "9      alerios   jorgerojas2022  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of our lists\n",
    "ej_csv = pd.read_csv(save_path + f'/Source_Target/starting_2021-06-16.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\" Numero de Arcos: {ej_csv.shape[0]:,}. Nodos Source: {len(set(ej_csv['Source'])):,}. Nodos Target {len(set(ej_csv['Target'])):,}. Total de Nodos {len(nodes):,}\")\n",
    "ej_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(file_tuple):\n",
    "    file1, file2 = file_tuple\n",
    "    starting_date_str = file1.split('.')[-2].split('/')[-1].split('_')[-1]\n",
    "    starting_date = datetime.strptime(starting_date_str, '%Y-%m-%d')\n",
    "    ending_date = starting_date + timedelta(days=3)\n",
    "    ending_date_str = ending_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    csv = pd.read_csv(file1, delimiter=';')\n",
    "    \n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(len(master_id))\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "    \n",
    "    for row in csv.itertuples(index = False):\n",
    "        e = g.add_edge(row[0], row[1])\n",
    "        number_of_rts[e] = row[4]\n",
    "        normal_weight[e] = row[5]\n",
    "\n",
    "    g.ep['Number of rts'] = number_of_rts\n",
    "    g.ep['Normal Weights'] = normal_weight\n",
    "    \n",
    "    # Create Edge property map\n",
    "    number_of_rts = g.new_edge_property('int')\n",
    "    normal_weight = g.new_edge_property('float')\n",
    "\n",
    "    # Create a Vertex property maps\n",
    "    vertex_PA_map = g.new_vertex_property('string')\n",
    "    vertex_ID_map = g.new_vertex_property('int64_t')\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "    vertex_color_map = g.new_vertex_property('string')\n",
    "    vertex_isolate_map = g.new_vertex_property('bool')\n",
    "    vertex_quoted_map = g.new_vertex_property('int64_t')\n",
    "    vertex_replies_map = g.new_vertex_property('int64_t')\n",
    "    vertex_retweeted_map = g.new_vertex_property('int64_t')\n",
    "    vertex_tweets_map = g.new_vertex_property('int64_t')\n",
    "    \n",
    "    # Get Different categories\n",
    "    categories = [cat for cat in set(idx_to_pa.values())]\n",
    "    for cat in categories:\n",
    "        # Create a dummy property map\n",
    "        vertex_dummy_map = g.new_vertex_property('bool')\n",
    "        globals()['map_'+cat] = vertex_dummy_map\n",
    "    \n",
    "    tweets_per_day = pd.read_csv(file2, delimiter=';', index_col='ID')\n",
    "\n",
    "    # Assign Labels to vertices using loop (Create one VertexPropertyMap for every Political Label)\n",
    "    for v_index in g.iter_vertices():\n",
    "        v = g.vertex(v_index)\n",
    "        # Add tweets information of users\n",
    "        vertex_quoted_map[v] = tweets_per_day['quoted'].loc[v_index]\n",
    "        vertex_retweeted_map[v] = tweets_per_day['retweeted'].loc[v_index]\n",
    "        vertex_replies_map[v] = tweets_per_day['replied_to'].loc[v_index]\n",
    "        vertex_tweets_map[v] = tweets_per_day['tweet'].loc[v_index]\n",
    "        \n",
    "        # Add Master Index Information\n",
    "        vertex_PA_map[v] = idx_to_pa[v]\n",
    "        vertex_ID_map[v] = idx_to_id[v]\n",
    "        vertex_label_map[v] = idx_to_label[v]\n",
    "        vertex_color_map[v] = color[idx_to_pa[v]]\n",
    "        \n",
    "        # Add categories Information\n",
    "        for cat in categories:\n",
    "            if idx_to_pa[v] == cat:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = True\n",
    "                globals()['map_'+cat] = map\n",
    "            else:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = False\n",
    "                globals()['map_'+cat] = map\n",
    "        \n",
    "        # Add isolated\n",
    "        if v.out_degree() == 0 and v.in_degree() == 0:\n",
    "            vertex_isolate_map[v] = True\n",
    "        else: \n",
    "            vertex_isolate_map[v] = False\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_PA_map\n",
    "    g.vp['User ID'] = vertex_ID_map\n",
    "    g.vp['Label'] = vertex_label_map\n",
    "    g.vp['Color'] = vertex_color_map\n",
    "    g.vp['Isolate'] = vertex_isolate_map\n",
    "    g.vp['Replies'] = vertex_replies_map\n",
    "    g.vp['Retweets'] = vertex_retweeted_map\n",
    "    g.vp['Quoted'] = vertex_quoted_map\n",
    "    g.vp['Tweets'] = vertex_tweets_map\n",
    "    \n",
    "    # Add dummy maps\n",
    "    for cat in categories:\n",
    "        map = globals()['map_'+cat]\n",
    "        g.vp[cat] = map\n",
    "    \n",
    "    # Add graph properties\n",
    "    graph_starting_date = g.new_graph_property('string')\n",
    "    graph_ending_date = g.new_graph_property('string')\n",
    "    graph_starting_date[g] = starting_date_str\n",
    "    graph_ending_date[g] = ending_date_str\n",
    "    g.gp['Starting Date'] = graph_starting_date\n",
    "    g.gp['Ending Date'] = graph_ending_date\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(save_path, 'Graphs' ,'starting_' + starting_date_str + \".graphml\")\n",
    "    g.save(filename)\n",
    "\n",
    "\n",
    "def main():\n",
    "    source_target_files = glob('../../../Data/3_Day_Graphs/Source_Target/starting_*.csv')\n",
    "    tweets_files = glob('../../../Data/3_Day_Graphs/Tweets_Per_Day/starting_*.csv')\n",
    "    source_target_files.sort()\n",
    "    tweets_files.sort()\n",
    "    files = list(zip(source_target_files, tweets_files))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        executor.map(create_graph, files)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge List\n",
      "Non Isolate Vertices 31,078 and 547,260 edges\n",
      "Graph\n",
      "Non Isolate Vertices 31,078 and 547,260 edges\n",
      "29,504 Active Nodes on Graph and 29,504 Active Nodes on df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>replied_to</th>\n",
       "      <th>quoted</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>777978</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>784125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1061601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1488031</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  replied_to  quoted  retweeted  tweet\n",
       "ID                                               \n",
       "1     12996           0       0         31      0\n",
       "2    777978           9       0          1      2\n",
       "3    784125           0       0         12      0\n",
       "4   1061601           0       0         21      0\n",
       "5   1488031           6       1          2      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Edge List')\n",
    "ej_csv = pd.read_csv(save_path + f'/Source_Target/starting_2021-05-07.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source'].unique()).union(set(ej_csv['Target'].unique())))\n",
    "print(f\"Non Isolate Vertices {len(nodes):,} and {len(ej_csv):,} edges\")\n",
    "\n",
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(save_path + f'/Graphs/starting_2021-05-07.graphml')\n",
    "print('Graph')\n",
    "print(f\"Non Isolate Vertices {ej_g.num_vertices() - sum(ej_g.vp['Isolate']):,} and {ej_g.num_edges():,} edges\")\n",
    "\n",
    "# Example of Tweets df\n",
    "ej_t = pd.read_csv(save_path + f'/Tweets_Per_Day/starting_2021-05-07.csv', sep = ';', index_col='ID')\n",
    "source_nodes_count = sum(1 for v in ej_g.vertices() if v.out_degree() > 0)\n",
    "print(f\"{source_nodes_count:,} Active Nodes on Graph and {len(ej_t[ej_t['retweeted']>0]):,} Active Nodes on df\")\n",
    "ej_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Centro': <VertexPropertyMap object with value type 'bool', for Graph 0x7fecd07aec10, at 0x7fecd07af050>,\n",
       " 'Color': <VertexPropertyMap object with value type 'string', for Graph 0x7fecd07aec10, at 0x7fecd07ac850>,\n",
       " 'Derecha': <VertexPropertyMap object with value type 'bool', for Graph 0x7fecd07aec10, at 0x7fecc7a57a50>,\n",
       " 'Isolate': <VertexPropertyMap object with value type 'bool', for Graph 0x7fecd07aec10, at 0x7fecc7a57950>,\n",
       " 'Izquierda': <VertexPropertyMap object with value type 'bool', for Graph 0x7fecd07aec10, at 0x7fecc7a57850>,\n",
       " 'Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fecd07aec10, at 0x7fecc7a57750>,\n",
       " 'Political Label': <VertexPropertyMap object with value type 'string', for Graph 0x7fecd07aec10, at 0x7fecc7a57650>,\n",
       " 'Quoted': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fecd07aec10, at 0x7fecc7a57550>,\n",
       " 'Replies': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fecd07aec10, at 0x7fecc7a57450>,\n",
       " 'Retweets': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fecd07aec10, at 0x7fecc7a562d0>,\n",
       " 'Sin Clasificar': <VertexPropertyMap object with value type 'bool', for Graph 0x7fecd07aec10, at 0x7fecc7a56150>,\n",
       " 'Tweets': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fecd07aec10, at 0x7fecc7a57250>,\n",
       " 'User ID': <VertexPropertyMap object with value type 'int64_t', for Graph 0x7fecd07aec10, at 0x7fecc7a57150>}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ej_g.vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idx in Graph: 23639\n",
      "1920140406\n",
      "Santialarconu\n",
      "Izquierda\n",
      "blue\n",
      "---------Checking on Master Index----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                               23639\n",
       "Label                    Santialarconu\n",
       "Political Affiliation        Izquierda\n",
       "User ID                     1920140406\n",
       "Name: 23639, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(ej_g.vp['User ID'][test_idx])\n",
    "print(ej_g.vp['Label'][test_idx])\n",
    "print(ej_g.vp['Political Label'][test_idx])\n",
    "print(ej_g.vp['Color'][test_idx])\n",
    "print('---------Checking on Master Index----------')\n",
    "master_id.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: (36963, 31708)\n",
      "Edge In graph: (36963, 31708)\n",
      "Normal Weights 0.0454545454545454\n",
      "Number of rts 1\n",
      "--------Value in Edge List---------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>source_user_id</th>\n",
       "      <th>target_user_id</th>\n",
       "      <th>number_of_rts</th>\n",
       "      <th>normal_weight</th>\n",
       "      <th>source_political_afilliation</th>\n",
       "      <th>target_political_afilliation</th>\n",
       "      <th>source_label</th>\n",
       "      <th>target_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547258</th>\n",
       "      <td>36963</td>\n",
       "      <td>31708</td>\n",
       "      <td>1389784145417678848</td>\n",
       "      <td>1010113508233699328</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>LevyRincon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source  Target       source_user_id       target_user_id  \\\n",
       "547258   36963   31708  1389784145417678848  1010113508233699328   \n",
       "\n",
       "        number_of_rts  normal_weight source_political_afilliation  \\\n",
       "547258              1       0.045455                    Izquierda   \n",
       "\n",
       "       target_political_afilliation source_label target_label  \n",
       "547258                    Izquierda     kars0518   LevyRincon  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id_source = 1389784145417678848\n",
    "test_id_target = 1010113508233699328\n",
    "\n",
    "source_idx = id_to_idx[test_id_source]\n",
    "target_idx = id_to_idx[test_id_target]\n",
    "test_edge_idx = (source_idx, target_idx)\n",
    "\n",
    "edge_index = ej_g.edge_index[test_edge_idx]\n",
    "print(f'Edge: {test_edge_idx}')\n",
    "print(f'Edge In graph: {test_edge_idx}')\n",
    "print(f\"Normal Weights {ej_g.ep['Normal Weights'][test_edge_idx]}\")\n",
    "print(f\"Number of rts {ej_g.ep['Number of rts'][test_edge_idx]}\")\n",
    "print('--------Value in Edge List---------')\n",
    "ej_csv.loc[(ej_csv['Source'] == source_idx) & (ej_csv['Target'] == target_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quoted Tweets: 3\n",
      "Replies Tweets: 0\n",
      "Retweets Tweets: 6\n",
      "Original Tweets: 21\n",
      "Idx in Graph: 23639\n",
      "User ID: 1920140406\n",
      "---------Checking on Tweets Df----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "User ID       1920140406\n",
       "replied_to             0\n",
       "quoted                 3\n",
       "retweeted              6\n",
       "tweet                 21\n",
       "Name: 23639, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f\"Quoted Tweets: {ej_g.vp['Quoted'][test_idx]}\")\n",
    "print(f\"Replies Tweets: {ej_g.vp['Replies'][test_idx]}\")\n",
    "print(f\"Retweets Tweets: {ej_g.vp['Retweets'][test_idx]}\")\n",
    "print(f\"Original Tweets: {ej_g.vp['Tweets'][test_idx]}\")\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(f\"User ID: {ej_g.vp['User ID'][test_idx]}\")\n",
    "print('---------Checking on Tweets Df----------')\n",
    "ej_t.loc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_4.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_5.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_3.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_2.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_1.gzip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_paro = glob('/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_*')\n",
    "tweets_paro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:45<00:00, 45.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30918011, 24)\n"
     ]
    }
   ],
   "source": [
    "# Import the tweets from Paro but select only the retweets\n",
    "retweets = pd.DataFrame()\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets = pd.read_pickle(file, compression = \"gzip\")\n",
    "\n",
    "    # Select only retweets\n",
    "    rts = tweets.loc[tweets[\"Reference Type\"] == \"retweeted\",:].reset_index(drop = True)\n",
    "    rts = rts.drop(columns = 'Reference Type')\n",
    "    retweets = pd.concat([retweets, rts], axis = 0)\n",
    "retweets = retweets.reset_index(drop = True)\n",
    "del rts, tweets \n",
    "print('Shape:', retweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 30,918,011 Retweets y 624,358 Usario con Rts o Retwiteados\n"
     ]
    }
   ],
   "source": [
    "users = set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID']))\n",
    "print(f'Tenemos: {retweets.shape[0]:,} Retweets y {len(users):,} Usario con Rts o Retwiteados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types\n",
    "retweets[\"ID\"] = retweets[\"ID\"].astype(int)\n",
    "retweets[\"Author ID\"] = retweets[\"Author ID\"].astype(int)\n",
    "retweets['Referenced Tweet Author ID'] = retweets['Referenced Tweet Author ID'].astype(int)\n",
    "retweets['Referenced Tweet'] = retweets['Referenced Tweet'].astype(int)\n",
    "\n",
    "# Remove time from retweets date\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have retweets from 2021-04-28 to 2021-06-29\n"
     ]
    }
   ],
   "source": [
    "fecha_min = retweets[\"Date\"].min()\n",
    "fecha_max = retweets[\"Date\"].max()\n",
    "print(f\"We have retweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = pd.read_pickle(\"../../../Data/Tweets_DataFrames/users_information.gzip\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Referenced Tweet Author\n",
    "retweets = users_information.reset_index()[[\"Author ID\", \"Author Name\"]] \\\n",
    "    .rename(columns = {\"Author ID\": \"Referenced Tweet Author ID\", \n",
    "                       \"Author Name\": \"Referenced Tweet Author Name\"}) \\\n",
    "                       .merge(retweets, how = \"right\", on = \"Referenced Tweet Author ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Referenced Tweet Author ID           0\n",
       "Referenced Tweet Author Name    587246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users without name\n",
    "retweets.iloc[:, 0:2].drop_duplicates().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(daily_grid):\n",
    "    # Select the retweets from the desired date\n",
    "    temp = retweets[retweets['Date'] == d.date()]\n",
    "    temp = temp.groupby([\"Author ID\", \"Author Name\", \"Date\", \"Referenced Tweet Author ID\", \"Referenced Tweet Author Name\"]).size().reset_index(name = \"w\")\n",
    "    temp.columns = [\"source\", \"source_label\", \"date\", \"target\", \"target_label\", \"w\"]\n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target\"].apply(lambda x: user_to_party_paro[x])\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source-Target\", str(d.date()) + \".csv\"), index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Node list\n",
    "nodes_id = list(set(retweets[\"Author ID\"]).union(set(retweets[\"Referenced Tweet Author ID\"])))\n",
    "len(nodes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37344, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = users_information.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"../../../Data/Pickle/user_to_party_paro.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624358/624358 [00:00<00:00, 1256998.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert users_information DataFrame to a dictionary for fast lookup\n",
    "users_info_dict = users_information.set_index('Author ID')['Author Name'].to_dict()\n",
    "\n",
    "nodes_label = []\n",
    "nodes_political_affilitation = []\n",
    "for i in tqdm(nodes_id):\n",
    "    # Assign label\n",
    "    label = users_info_dict.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_label.append(label)\n",
    "\n",
    "    # Assign Political Affiliation\n",
    "    pa = user_to_party_paro.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_political_affilitation.append(pa)\n",
    "\n",
    "num_nodes = len(nodes_id)\n",
    "nodes_idx = [i for i in range(num_nodes)]\n",
    "\n",
    "# Create dictionary\n",
    "nodes_dict = {\n",
    "    'id': nodes_id,\n",
    "    'idx': nodes_idx,\n",
    "    'label': nodes_label,\n",
    "    'pa': nodes_political_affilitation\n",
    "}\n",
    "\n",
    "# Save as pickle\n",
    "with open(\"../../../Data/Daily_graphs/nodes_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nodes_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624358"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_dict[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify indices where \"pa\" is not nan\n",
    "indices_to_keep = [i for i, pa_value in enumerate(nodes_dict[\"pa\"]) if str(pa_value) != \"nan\"]\n",
    "\n",
    "# Create a new dictionary with filtered values\n",
    "nodes_dict_filtered = {key: [value[i] for i in indices_to_keep] for key, value in nodes_dict.items()}\n",
    "\n",
    "# Fix idx\n",
    "nodes_dict_filtered[\"idx\"] = [i for i in range(num_nodes)]\n",
    "# Fix id\n",
    "nodes_dict_filtered[\"id\"] = [int(i) for i in nodes_dict_filtered[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = len(nodes_dict_filtered[\"id\"])\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_dict_filtered[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets['Author ID'] = retweets['Author ID'].astype(int)\n",
    "retweets['Referenced Tweet Author ID'] = retweets['Referenced Tweet Author ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_dict_filtered[\"id\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_filtered = retweets.copy()\n",
    "retweets_filtered = retweets_filtered.loc[retweets['Author ID'].isin(nodes_dict_filtered[\"id\"]),:]\n",
    "retweets_filtered = retweets_filtered.loc[retweets['Referenced Tweet Author ID'].isin(nodes_dict_filtered[\"id\"]),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/63 [00:07<03:56,  3.88s/it]"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for O(1) lookup time of indices\n",
    "id_to_idx = {node_id: idx for idx, node_id in enumerate(nodes_dict_filtered['id'])}\n",
    "\n",
    "for d in tqdm(daily_grid):\n",
    "    # Filter retweets first\n",
    "    retweets_filtered2 = retweets_filtered[retweets_filtered['Date'] == d.date()]\n",
    "    \n",
    "    # Create weights\n",
    "    test = retweets_filtered2.groupby(['Author ID', 'Referenced Tweet Author ID']).size().reset_index(name=\"w\")\n",
    "    \n",
    "    # Use dictionary lookups for index mappings\n",
    "    test['idx_s'] = [id_to_idx.get(x, np.nan) for x in test['Author ID']]\n",
    "    test['idx_t'] = [id_to_idx.get(x, np.nan) for x in test['Referenced Tweet Author ID']]\n",
    "    \n",
    "    # The edge list should be based on the idx of the nodes and include weights\n",
    "    edges_list_with_weights = list(zip(test['idx_s'].dropna().astype(int), test['idx_t'].dropna().astype(int), test['w']))\n",
    "    \n",
    "    # Create graph\n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(num_nodes)\n",
    "    \n",
    "    # Node attributes\n",
    "    node_id = g.new_vertex_property(\"string\", vals=nodes_dict_filtered['id'])\n",
    "    node_label = g.new_vertex_property(\"string\", vals=nodes_dict_filtered['label'])\n",
    "    node_affiliation = g.new_vertex_property(\"string\", vals=nodes_dict_filtered['pa'])\n",
    "    \n",
    "    # Assign attributes to graph\n",
    "    g.vertex_properties[\"ID\"] = node_id\n",
    "    g.vertex_properties[\"Label\"] = node_label\n",
    "    g.vertex_properties[\"Political Affiliation\"] = node_affiliation\n",
    "    \n",
    "    # Edge weight attribute\n",
    "    edge_weights = g.new_edge_property(\"int\")\n",
    "    \n",
    "    # Add edges and assign weights\n",
    "    for source, target, weight in edges_list_with_weights:\n",
    "        e = g.add_edge(source, target)\n",
    "        edge_weights[e] = weight\n",
    "\n",
    "    g.edge_properties[\"weight\"] = edge_weights\n",
    "    \n",
    "    g.save(os.path.join(\"../../../Data/Daily_graphs/Full network\", str(d.date()) + \".graphml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g)\n",
    "print(g.vp[\"ID\"][624353])\n",
    "print(g.vp[\"Label\"][624353])\n",
    "print(g.vp[\"Political Affiliation\"][624353])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
