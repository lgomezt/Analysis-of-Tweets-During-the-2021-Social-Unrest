{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we create a daily retweet network. First, we transform our dataset into a Source-Target DataFrame. Afterward, we construct a `graph-tool` object.\n",
    "\n",
    "We have 45,330,718 Tweets from 37330 from which 30,918,011 are ReTweets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 10,
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/anaconda3/envs/gt_global/lib/python3.11/site-packages/graph_tool/draw/cairo_draw.py:1544: RuntimeWarning: Error importing Gtk module: ; GTK+ drawing will not work.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Mathematical and Data Managment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Graph Managment\n",
    "import graph_tool.all as gt\n",
    "from utils.Functions import *\n",
    "\n",
    "# Miscellaneous\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/3_Day_Graphs\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas (Tweets): 45,330,718. Cantidad de Columnas: 5\n",
      "Total usuarios: 5,759,089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/29 22:48:50</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.391738e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/29 22:44:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/29 22:38:22</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>5.703026e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/29 22:34:26</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.402825e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/29 22:28:58</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.402825e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Author ID Author Name                 Date Reference Type  \\\n",
       "0  325932532.0   wilman_86  2021/06/29 22:48:50     replied_to   \n",
       "1  325932532.0   wilman_86  2021/06/29 22:44:00            NaN   \n",
       "2  325932532.0   wilman_86  2021/06/29 22:38:22     replied_to   \n",
       "3  325932532.0   wilman_86  2021/06/29 22:34:26     replied_to   \n",
       "4  325932532.0   wilman_86  2021/06/29 22:28:58     replied_to   \n",
       "\n",
       "   Referenced Tweet Author ID  \n",
       "0                1.391738e+18  \n",
       "1                         NaN  \n",
       "2                5.703026e+07  \n",
       "3                1.402825e+18  \n",
       "4                1.402825e+18  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# Load Tweets\n",
    "tweets = pd.read_pickle('../../../Data/Tweets_DataFrames/tweets_lite.gzip', compression='gzip')\n",
    "print(f'Cantidad de filas (Tweets): {tweets.shape[0]:,}. Cantidad de Columnas: {tweets.shape[1]:,}')\n",
    "print('Total usuarios: ' + f\"{len(set(tweets['Author ID']).union(set(tweets['Referenced Tweet Author ID']))):,}\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 30,918,011 Retweets y 624,358 Usario con Rts o Retwiteados\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.715849e+08</td>\n",
       "      <td>Tati_Reloaded</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.615847e+07</td>\n",
       "      <td>laraquet</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.354310e+09</td>\n",
       "      <td>jonathan_sole</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.847251e+17</td>\n",
       "      <td>tipo_listo</td>\n",
       "      <td>2021-06-12</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.114956e+08</td>\n",
       "      <td>CamiloGuerreroB</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author ID      Author Name        Date  Referenced Tweet Author ID\n",
       "0  1.715849e+08    Tati_Reloaded  2021-05-10                        12.0\n",
       "1  3.615847e+07         laraquet  2021-06-04                        12.0\n",
       "2  3.354310e+09    jonathan_sole  2021-05-10                        12.0\n",
       "3  7.847251e+17       tipo_listo  2021-06-12                        12.0\n",
       "4  4.114956e+08  CamiloGuerreroB  2021-06-10                        12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# We will just get the Retweets\n",
    "retweets_total = tweets[tweets['Reference Type'] == 'retweeted']\n",
    "retweets_total = retweets_total.drop(columns=['Reference Type'])\n",
    "retweets_total[\"Date\"] = pd.to_datetime(retweets_total[\"Date\"]).dt.date\n",
    "retweets_total = retweets_total.sort_values('Referenced Tweet Author ID').reset_index(drop = True)\n",
    "\n",
    "users = set(retweets_total['Author ID']).union(set(retweets_total['Referenced Tweet Author ID']))\n",
    "print(f'Tenemos: {retweets_total.shape[0]:,} Retweets y {len(users):,} Usario con Rts o Retwiteados')\n",
    "del tweets, users\n",
    "\n",
    "# This will be our Sorce-Target List. Will include the weights of each tweets\n",
    "retweets_total.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faltan clasificar 587,246 usuarios\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Political Affiliation\n",
       "NaN            587246\n",
       "Izquierda       23138\n",
       "Derecha          6812\n",
       "No Retweets      3844\n",
       "Centro           3543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"../../../Data/Pickle/user_to_party_paro.pkl\")\n",
    "\n",
    "ids_faltantes1 = set(retweets_total[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(retweets_total[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(np.unique(ids_faltantes)):,} usuarios\")\n",
    "\n",
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan\n",
    "\n",
    "affilliation_df = pd.DataFrame(list(user_to_party_paro.items()), columns=['User ID', 'Political Affiliation'])\n",
    "affilliation_df['Political Affiliation'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated IDs: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37339</th>\n",
       "      <td>1.389722e+18</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37340</th>\n",
       "      <td>1.389737e+18</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>(1, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37341</th>\n",
       "      <td>1.389741e+18</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37342</th>\n",
       "      <td>1.389769e+18</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37343</th>\n",
       "      <td>1.389784e+18</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37337 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID           Label Political Affiliation           Color\n",
       "0      0.000000e+00               0           No Retweets  (0, 0, 0, 0.7)\n",
       "1      1.000000e+00               0           No Retweets  (0, 0, 0, 0.7)\n",
       "2      2.000000e+00               0           No Retweets  (0, 0, 0, 0.7)\n",
       "3      3.000000e+00               0           No Retweets  (0, 0, 0, 0.7)\n",
       "5      4.000000e+00               0           No Retweets  (0, 0, 0, 0.7)\n",
       "...             ...             ...                   ...             ...\n",
       "37339  1.389722e+18  Neoplasticista             Izquierda  (0, 0, 1, 0.7)\n",
       "37340  1.389737e+18      JC13177979               Derecha  (1, 0, 0, 0.7)\n",
       "37341  1.389741e+18   JhonatanVRojo           No Retweets  (0, 0, 0, 0.7)\n",
       "37342  1.389769e+18       VaneLen18             Izquierda  (0, 0, 1, 0.7)\n",
       "37343  1.389784e+18        kars0518             Izquierda  (0, 0, 1, 0.7)\n",
       "\n",
       "[37337 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# Create Master Id\n",
    "#del affilliation_df,ids_faltantes, ids_faltantes1, ids_faltantes2, usuario\n",
    "users_information = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/users_information.gzip', compression='gzip')\n",
    "master_id = users_information.reset_index()[['Author ID', 'Author Name']]\n",
    "master_id = master_id.rename(columns={\n",
    "    'Author ID': 'ID',\n",
    "    'Author Name': 'Label'\n",
    "})\n",
    "\n",
    "# dict for color\n",
    "color = {\n",
    "    'Izquierda': (0,0,1, 0.7),\n",
    "    'Derecha': (1,0,0, 0.7),\n",
    "    'Centro': (0,1,0, 0.7),\n",
    "    'No Retweets': (0,0,0,0.7)\n",
    "}\n",
    "\n",
    "master_id['Political Affiliation'] = master_id['ID'].apply(lambda x: user_to_party_paro[x])\n",
    "master_id['Color'] = master_id['Political Affiliation'].apply(lambda x: color[x])\n",
    "print(f\"Duplicated IDs: {sum(master_id.duplicated(subset = 'ID'))}\")\n",
    "master_id = master_id.drop_duplicates(subset = 'ID')\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 13,784,608 Retweets y 36,964 Usuarios con Rts o Retwiteados. Usuarios sin Retweets 373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Source Label</th>\n",
       "      <th>Source PA</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.715849e+08</td>\n",
       "      <td>Tati_Reloaded</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Tati_Reloaded</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.615847e+07</td>\n",
       "      <td>laraquet</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>12.0</td>\n",
       "      <td>laraquet</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.354310e+09</td>\n",
       "      <td>jonathan_sole</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>jonathan_sole</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.847251e+17</td>\n",
       "      <td>tipo_listo</td>\n",
       "      <td>2021-06-12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>tipo_listo</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.114956e+08</td>\n",
       "      <td>CamiloGuerreroB</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CamiloGuerreroB</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author ID      Author Name        Date  Referenced Tweet Author ID  \\\n",
       "0  1.715849e+08    Tati_Reloaded  2021-05-10                        12.0   \n",
       "1  3.615847e+07         laraquet  2021-06-04                        12.0   \n",
       "2  3.354310e+09    jonathan_sole  2021-05-10                        12.0   \n",
       "3  7.847251e+17       tipo_listo  2021-06-12                        12.0   \n",
       "4  4.114956e+08  CamiloGuerreroB  2021-06-10                        12.0   \n",
       "\n",
       "      Source Label    Source PA Target Label    Target PA  \n",
       "0    Tati_Reloaded  No Retweets            0  No Retweets  \n",
       "1         laraquet    Izquierda            0  No Retweets  \n",
       "2    jonathan_sole    Izquierda            0  No Retweets  \n",
       "3       tipo_listo    Izquierda            0  No Retweets  \n",
       "4  CamiloGuerreroB      Derecha            0  No Retweets  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# Adding Source Labels\n",
    "temp = retweets_total.merge(master_id, how = 'inner', left_on = 'Author ID', right_on='ID', validate = 'm:1')\n",
    "temp = temp.rename(columns = {'Label': 'Source Label', 'Political Affiliation': 'Source PA'}).drop(columns='ID')\n",
    "\n",
    "# Adding Target Labels\n",
    "retweets = temp.merge(master_id, how = 'inner', left_on = 'Referenced Tweet Author ID', right_on='ID', validate = 'm:1')\n",
    "retweets = retweets.rename(columns = {'Label': 'Target Label', 'Political Affiliation': 'Target PA'})\n",
    "\n",
    "retweets = retweets.drop(columns= ['ID', 'Color_y', 'Color_x'])\n",
    "\n",
    "# Count how many tweets and users we have now\n",
    "users_rts = list(set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID'])))\n",
    "non_singletons = master_id[master_id['ID'].isin(users_rts)] # Nodes conected by a Rt\n",
    "singletons = master_id[~master_id['ID'].isin(users_rts)] # Nodes that aren't in Rts during Paro (Perhaps only Twitted or Retwitted with replies) \n",
    "print(f'Tenemos: {retweets.shape[0]:,} Retweets y {len(non_singletons):,} Usuarios con Rts o Retwiteados. Usuarios sin Retweets {len(singletons)}')\n",
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idx in Graph</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Political Affiliation</th>\n",
       "      <th>Color</th>\n",
       "      <th>Fechas Source</th>\n",
       "      <th>Fechas Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12996</td>\n",
       "      <td>alerios</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>777978</td>\n",
       "      <td>ranaberden</td>\n",
       "      <td>Centro</td>\n",
       "      <td>(0, 1, 0, 0.7)</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>784125</td>\n",
       "      <td>jsanti</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1061601</td>\n",
       "      <td>thisgoblin</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36959</th>\n",
       "      <td>36959</td>\n",
       "      <td>1389721694961651712</td>\n",
       "      <td>Neoplasticista</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36960</th>\n",
       "      <td>36960</td>\n",
       "      <td>1389737202742071296</td>\n",
       "      <td>JC13177979</td>\n",
       "      <td>Derecha</td>\n",
       "      <td>(1, 0, 0, 0.7)</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36961</th>\n",
       "      <td>36961</td>\n",
       "      <td>1389741234370064384</td>\n",
       "      <td>JhonatanVRojo</td>\n",
       "      <td>No Retweets</td>\n",
       "      <td>(0, 0, 0, 0.7)</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>36962</td>\n",
       "      <td>1389769251704147968</td>\n",
       "      <td>VaneLen18</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36963</th>\n",
       "      <td>36963</td>\n",
       "      <td>1389784145417678848</td>\n",
       "      <td>kars0518</td>\n",
       "      <td>Izquierda</td>\n",
       "      <td>(0, 0, 1, 0.7)</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36964 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Idx in Graph                   ID           Label  \\\n",
       "0                 0                   12               0   \n",
       "1                 1                12996         alerios   \n",
       "2                 2               777978      ranaberden   \n",
       "3                 3               784125          jsanti   \n",
       "4                 4              1061601      thisgoblin   \n",
       "...             ...                  ...             ...   \n",
       "36959         36959  1389721694961651712  Neoplasticista   \n",
       "36960         36960  1389737202742071296      JC13177979   \n",
       "36961         36961  1389741234370064384   JhonatanVRojo   \n",
       "36962         36962  1389769251704147968       VaneLen18   \n",
       "36963         36963  1389784145417678848        kars0518   \n",
       "\n",
       "      Political Affiliation           Color  Fechas Source  Fechas Target  \n",
       "0               No Retweets  (0, 0, 0, 0.7)              0              9  \n",
       "1                 Izquierda  (0, 0, 1, 0.7)             57              6  \n",
       "2                    Centro  (0, 1, 0, 0.7)             17              4  \n",
       "3                 Izquierda  (0, 0, 1, 0.7)             57              2  \n",
       "4                 Izquierda  (0, 0, 1, 0.7)             44              7  \n",
       "...                     ...             ...            ...            ...  \n",
       "36959             Izquierda  (0, 0, 1, 0.7)             16              1  \n",
       "36960               Derecha  (1, 0, 0, 0.7)             34             18  \n",
       "36961           No Retweets  (0, 0, 0, 0.7)              5              0  \n",
       "36962             Izquierda  (0, 0, 1, 0.7)             30              2  \n",
       "36963             Izquierda  (0, 0, 1, 0.7)             27              0  \n",
       "\n",
       "[36964 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# Save this Dataframe for Nodes List\n",
    "master_id = non_singletons # Aislamos a los singletons del Master ID\n",
    "master_id = master_id.astype({\n",
    "    'ID': int,\n",
    "    'Label': str,\n",
    "    'Political Affiliation': str\n",
    "}).reset_index(drop=True)\n",
    "master_id = master_id.reset_index().rename(columns = {'index': 'Idx in Graph'})\n",
    "id_to_label = master_id.set_index('ID').to_dict()['Label']\n",
    "\n",
    "id_fecha_counts = retweets.groupby('Author ID')['Date'].nunique().reset_index(name='Fechas Source').rename(columns={'Author ID': 'ID'})\n",
    "master_id = master_id.merge(id_fecha_counts, on = 'ID', how='left')\n",
    "id_fecha_counts = retweets.groupby('Referenced Tweet Author ID')['Date'].nunique().reset_index(name='Fechas Target').rename(columns={'Referenced Tweet Author ID': 'ID'})\n",
    "master_id = master_id.merge(id_fecha_counts, on = 'ID', how='left')\n",
    "\n",
    "master_id['Fechas Source'] = master_id['Fechas Source'].fillna(0).astype(int)\n",
    "master_id['Fechas Target'] = master_id['Fechas Target'].fillna(0).astype(int)\n",
    "\n",
    "# Save\n",
    "master_id.to_csv(os.path.join(save_path, 'Nodes' + \".csv\"), index = False, sep = \";\")\n",
    "master_id"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos Retweeteados por alguien pero que no Retweetean: 6,510\n",
      "Nodos que Retweetean a alguien pero no son Retweeteados: 833\n",
      "Nodos que tienen un self loop: 8\n",
      "primer nodo: 12.0 último nodo: 1.3897841454176788e+18\n",
      "Total de nodos en conectados: 36,964\n",
      "Total de nodos Singletons: 373\n",
      "Total de usuarios que TWITTEARON Durante el paro: 37,337\n"
     ]
    }
   ],
>>>>>>> 76123e9f2078f3d8da12455b3fab88d5c3368509
   "source": [
    "# Insights\n",
    "nodes_no_receipt = set(retweets[\"Author ID\"]) -  set(retweets[\"Referenced Tweet Author ID\"])\n",
    "nodes_no_send = set(retweets[\"Referenced Tweet Author ID\"]) - set(retweets[\"Author ID\"])\n",
    "self_loops = set(retweets[retweets['Author ID'] == retweets['Referenced Tweet Author ID']])\n",
    "\n",
    "print(f'Nodos Retweeteados por alguien pero que no Retweetean: {len(nodes_no_receipt):,}')\n",
    "print(f'Nodos que Retweetean a alguien pero no son Retweeteados: {len(nodes_no_send):,}')\n",
    "print(f'Nodos que tienen un self loop: {len(self_loops)}')\n",
    "\n",
    "print(f'primer nodo: {min(users_rts)} último nodo: {max(users_rts):,}')\n",
    "print(f'Total de nodos en conectados: {len(users_rts):,}')\n",
    "print(f'Total de nodos Singletons: {len(singletons):,}')\n",
    "print(f'Total de usuarios que TWITTEARON Durante el paro: {len(singletons) + len(non_singletons):,}')\n",
    "\n",
    "# del nodes_no_receipt, nodes_no_send, self_loops, users_rts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Master Index in Any case\n",
    "master_id = pd.read_csv('/mnt/disk2/Data/3_Day_Graphs/Nodes.csv', sep = ';')\n",
    "index = master_id['ID'].reset_index()\n",
    "# Useful Dicts\n",
    "idx_to_id = master_id['ID'].reset_index().to_dict()['ID']\n",
    "idx_to_pa = master_id['Political Affiliation'].reset_index().to_dict()['Political Affiliation']\n",
    "idx_to_label = master_id['Label'].reset_index().to_dict()['Label']\n",
    "\n",
    "# Dict for lookup in Graph\n",
    "id_to_idx = {id:idx for idx, id in idx_to_id.items()}\n",
    "\n",
    "# dict for color\n",
    "color = {\n",
    "    'Izquierda': (0,0,1,0.7),\n",
    "    'Derecha': (1,0,0,0.7),\n",
    "    'Centro': (0,1,0,0.7),\n",
    "    'No Retweets': (0,0,0,0.7)\n",
    "}\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date_start = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "del v1_end, v1_start\n",
    "\n",
    "v2_start = '2021-05-01 23:59:59'\n",
    "v2_end = '2021-06-30 23:59:59'\n",
    "date_end = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "del v2_start, v2_end\n",
    "\n",
    "# Runtime 5 minutes\n",
    "for d_s, d_e in tqdm(zip(date_start, date_end)):\n",
    "    # Get 3 days Retweets\n",
    "    window = retweets[(retweets['Date'] >= d_s.date()) & (retweets['Date'] < d_e.date())] \n",
    "\n",
    "    # Get total of Tweets during that period\n",
    "    rts_per_user= window.groupby('Author ID').size().reset_index(name = 'total')\n",
    "\n",
    "    # Create Normalize Weight\n",
    "    temp = window.groupby([\"Author ID\", \"Referenced Tweet Author ID\"]).size().reset_index(name = \"number of rts\")\n",
    "    temp = temp.merge(rts_per_user, how = 'right', on='Author ID')\n",
    "    temp['normal weight'] = temp['number of rts']/temp['total']\n",
    "    temp['normal weight'] = temp['normal weight'].round(3)\n",
    "    temp.drop(columns='total', inplace=True)\n",
    "    temp.columns = [\"Source ID\", \"Target ID\", \"Number of rts\", \"Normal weight\"]\n",
    "\n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"Source ID\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"Target ID\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp.dropna(subset=['target_political_afilliation', 'source_political_afilliation'], inplace=True)\n",
    "    \n",
    "    # Assign Label\n",
    "    temp['source_label'] = temp['Source ID'].apply(lambda x: id_to_label[x])\n",
    "    temp['target_label'] = temp['Target ID'].apply(lambda x: id_to_label[x])\n",
    "\n",
    "    # Add ending date\n",
    "    temp['Ending date'] = d_e.date()\n",
    "    temp['Starting date'] = d_s.date()\n",
    "    \n",
    "    # Replace Source IDs for Indexes\n",
    "    temp = temp.merge(index, how = 'left', left_on='Source ID', right_on = 'ID')\n",
    "    temp = temp.rename(columns = {'index': 'Source Index'}).drop(columns=['ID'])\n",
    "    \n",
    "    # Replace Target IDs for Indexes\n",
    "    temp = temp.merge(index, how = 'left', left_on='Target ID', right_on = 'ID')\n",
    "    temp = temp.rename(columns = {'index': 'Target Index'}).drop(columns=['ID'])\n",
    "\n",
    "    #Adding dtypes\n",
    "    temp = temp.astype({\n",
    "        'Source ID': int,\n",
    "        'Target ID': int,\n",
    "        'Number of rts': int,\n",
    "        'Normal weight': float,\n",
    "        'Source Index': int,\n",
    "        'Target Index': int\n",
    "    })\n",
    "    temp = temp[['Source Index', 'Target Index', 'Number of rts', 'Normal weight', 'Ending date', 'Starting date']] \n",
    "    \n",
    "    non_singletons_temp = set(temp['Source Index']).union(set(temp['Target Index']))\n",
    "    if len(non_singletons_temp) > 36964:\n",
    "        print(d_e)\n",
    "        break\n",
    "    elif len(non_singletons_temp) == 36964:\n",
    "        print(f\"Entre {d_s} y {d_e} Todos los nodos no singletons Retwittearon\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source_Target\", 'starting_' + str(d_s.date()) + \".csv\"), index = False, sep = \";\")\n",
    "\n",
    "del d_s, d_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of our lists\n",
    "ej_csv = pd.read_csv(save_path + '/Source_Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source Index'].unique()).union(set(ej_csv['Target Index'].unique())))\n",
    "print(f\" Numero de Arcos: {ej_csv.shape[0]:,}. Nodos Source: {len(set(ej_csv['Source Index'])):,}. Nodos Target {len(set(ej_csv['Target Index'])):,}. Total de Nodos {len(nodes):,}\")\n",
    "ej_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Dicts\n",
    "idx_to_id = master_id['ID'].reset_index().to_dict()['ID']\n",
    "idx_to_pa = master_id['Political Affiliation'].reset_index().to_dict()['Political Affiliation']\n",
    "idx_to_label = master_id['Label'].reset_index().to_dict()['Label']\n",
    "\n",
    "# Dict for lookup in Graph\n",
    "id_to_idx = {id:idx for idx, id in idx_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Graph Runtime 5 minutes\n",
    "files = glob('../../../Data/3_Day_Graphs/Source_Target/starting_*.csv')\n",
    "\n",
    "for file in tqdm(files):\n",
    "    starting_date_str = file.split('.')[-2].split('/')[-1].split('_')[-1]\n",
    "    starting_date = datetime.strptime(starting_date_str, '%Y-%m-%d')\n",
    "    ending_date = starting_date + timedelta(days=3)\n",
    "    ending_date_str = ending_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Initialice Directed Graph\n",
    "    g = gt.load_graph_from_csv(file,\n",
    "                               directed=True,\n",
    "                               eprop_types=['int',\"float\"],\n",
    "                               eprop_names=['Number of rts', 'Normal Weights'],\n",
    "                               skip_first=True,\n",
    "                               hashed=True,\n",
    "                               hash_type='int',\n",
    "                               csv_options={'delimiter': ';'})\n",
    "\n",
    "    # Create a Vertex property map for labels\n",
    "    vertex_PA_map = g.new_vertex_property('string')\n",
    "    vertex_ID_map = g.new_vertex_property('int64_t')\n",
    "    vertex_label_map = g.new_vertex_property('string')\n",
    "    vertex_color_map = g.new_vertex_property('vector<double>')\n",
    "    vertex_isolate_map = g.new_vertex_property('bool')\n",
    "    \n",
    "    # Get Different categories\n",
    "    categories = [cat for cat in set(idx_to_pa.values())]\n",
    "    for cat in categories:\n",
    "        # Create a dummy property map\n",
    "        vertex_dummy_map = g.new_vertex_property('bool')\n",
    "        globals()['map_'+cat] = vertex_dummy_map\n",
    "\n",
    "    # Assign Labels to vertices using loop (Create one VertexPropertyMap for every Political Label)\n",
    "    for v in g.vertices():\n",
    "        vertex_PA_map[v] = idx_to_pa[v]\n",
    "        vertex_ID_map[v] = idx_to_id[v]\n",
    "        vertex_label_map[v] = idx_to_label[v]\n",
    "        vertex_color_map[v] = color[idx_to_pa[v]]\n",
    "        for cat in categories:\n",
    "            if idx_to_pa[v] == cat:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = True\n",
    "                globals()['map_'+cat] = map\n",
    "            else:\n",
    "                map = globals()['map_'+cat]\n",
    "                map[v] = False\n",
    "                globals()['map_'+cat] = map\n",
    "        if v.out_degree() == 0 and v.in_degree() == 0:\n",
    "            vertex_isolate_map[v] = True\n",
    "        else: \n",
    "            vertex_isolate_map[v] = False\n",
    "\n",
    "    # Add properties\n",
    "    g.vp['Political Label'] = vertex_PA_map\n",
    "    g.vp['User ID'] = vertex_ID_map\n",
    "    g.vp['Label'] = vertex_label_map\n",
    "    g.vp['Color'] = vertex_color_map\n",
    "    g.vp['Isolate'] = vertex_isolate_map\n",
    "    \n",
    "    # Add dummy maps\n",
    "    for cat in categories:\n",
    "        map = globals()['map_'+cat]\n",
    "        g.vp[cat] = map\n",
    "    \n",
    "    # Add graph properties\n",
    "    graph_starting_date = g.new_graph_property('string')\n",
    "    graph_ending_date = g.new_graph_property('string')\n",
    "    graph_starting_date[g] = starting_date_str\n",
    "    graph_ending_date[g] = ending_date_str\n",
    "    g.gp['Starting Date'] = graph_starting_date\n",
    "    g.gp['Ending Date'] = graph_ending_date\n",
    "\n",
    "    # Save Graphs\n",
    "    filename = os.path.join(save_path, 'starting_' + starting_date_str + \".graphml\")\n",
    "    g.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_csv = pd.read_csv(save_path + f'/Source_Target/starting_2021-05-04.csv', sep = ';')\n",
    "nodes = set(set(ej_csv['Source Index'].unique()).union(set(ej_csv['Target Index'].unique())))\n",
    "print(f\"{len(nodes):,} Vertices and {len(ej_csv):,} edges\")\n",
    "\n",
    "# Example of our graphs\n",
    "ej_g = gt.load_graph(save_path + f'/starting_2021-05-04.graphml')\n",
    "ej_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id = 1920140406\n",
    "test_idx = id_to_idx[test_id]\n",
    "print(f'Idx in Graph: {test_idx}')\n",
    "print(ej_g.vp['User ID'][test_idx])\n",
    "print(ej_g.vp['Label'][test_idx])\n",
    "print(ej_g.vp['Political Label'][test_idx])\n",
    "print(ej_g.vp['Color'][test_idx])\n",
    "print('---------Checking on Master Index----------')\n",
    "master_id.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking properties of Vertex\n",
    "test_id_source = 12545442\n",
    "test_id_target = 1920140406\n",
    "\n",
    "source_idx = id_to_idx[test_id_source]\n",
    "target_idx = id_to_idx[test_id_target]\n",
    "\n",
    "source_idx_graph = look_up_graph(ej_g, source_idx)\n",
    "target_idx_graph = look_up_graph(ej_g, target_idx)\n",
    "\n",
    "test_edge_idx = (source_idx, target_idx)\n",
    "test_edge_graph = (source_idx_graph, target_idx_graph)\n",
    "\n",
    "edge_index = ej_g.edge_index[test_edge_graph]\n",
    "print(f'Edge: {test_edge_idx}')\n",
    "print(f'Edge In graph: {test_edge_graph}')\n",
    "print(f\"Normal Weights {ej_g.ep['Normal Weights'][test_edge_graph]}\")\n",
    "print(f\"Number of rts {ej_g.ep['Number of rts'][test_edge_graph]}\")\n",
    "print(f\"Ending Date {ej_g.ep['Ending date'][test_edge_graph]}\")\n",
    "print('--------Value in Edge List---------')\n",
    "ej_csv.loc[(ej_csv['Source Index'] == source_idx) & (ej_csv['Target Index'] == target_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_4.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_5.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_3.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_2.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_1.gzip']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_paro = glob('/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_*')\n",
    "tweets_paro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:45<00:00, 45.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30918011, 24)\n"
     ]
    }
   ],
   "source": [
    "# Import the tweets from Paro but select only the retweets\n",
    "retweets = pd.DataFrame()\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets = pd.read_pickle(file, compression = \"gzip\")\n",
    "\n",
    "    # Select only retweets\n",
    "    rts = tweets.loc[tweets[\"Reference Type\"] == \"retweeted\",:].reset_index(drop = True)\n",
    "    rts = rts.drop(columns = 'Reference Type')\n",
    "    retweets = pd.concat([retweets, rts], axis = 0)\n",
    "retweets = retweets.reset_index(drop = True)\n",
    "del rts, tweets \n",
    "print('Shape:', retweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos: 30,918,011 Retweets y 624,358 Usario con Rts o Retwiteados\n"
     ]
    }
   ],
   "source": [
    "users = set(retweets['Author ID']).union(set(retweets['Referenced Tweet Author ID']))\n",
    "print(f'Tenemos: {retweets.shape[0]:,} Retweets y {len(users):,} Usario con Rts o Retwiteados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types\n",
    "retweets[\"ID\"] = retweets[\"ID\"].astype(int)\n",
    "retweets[\"Author ID\"] = retweets[\"Author ID\"].astype(int)\n",
    "retweets['Referenced Tweet Author ID'] = retweets['Referenced Tweet Author ID'].astype(int)\n",
    "retweets['Referenced Tweet'] = retweets['Referenced Tweet'].astype(int)\n",
    "\n",
    "# Remove time from retweets date\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have retweets from 2021-04-28 to 2021-06-29\n"
     ]
    }
   ],
   "source": [
    "fecha_min = retweets[\"Date\"].min()\n",
    "fecha_max = retweets[\"Date\"].max()\n",
    "print(f\"We have retweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = pd.read_pickle(\"../../../Data/Tweets_DataFrames/users_information.gzip\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Referenced Tweet Author\n",
    "retweets = users_information.reset_index()[[\"Author ID\", \"Author Name\"]] \\\n",
    "    .rename(columns = {\"Author ID\": \"Referenced Tweet Author ID\", \n",
    "                       \"Author Name\": \"Referenced Tweet Author Name\"}) \\\n",
    "                       .merge(retweets, how = \"right\", on = \"Referenced Tweet Author ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Referenced Tweet Author ID           0\n",
       "Referenced Tweet Author Name    587246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users without name\n",
    "retweets.iloc[:, 0:2].drop_duplicates().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in tqdm(daily_grid):\n",
    "    # Select the retweets from the desired date\n",
    "    temp = retweets[retweets['Date'] == d.date()]\n",
    "    temp = temp.groupby([\"Author ID\", \"Author Name\", \"Date\", \"Referenced Tweet Author ID\", \"Referenced Tweet Author Name\"]).size().reset_index(name = \"w\")\n",
    "    temp.columns = [\"source\", \"source_label\", \"date\", \"target\", \"target_label\", \"w\"]\n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target\"].apply(lambda x: user_to_party_paro[x])\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source-Target\", str(d.date()) + \".csv\"), index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Node list\n",
    "nodes_id = list(set(retweets[\"Author ID\"]).union(set(retweets[\"Referenced Tweet Author ID\"])))\n",
    "len(nodes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37344, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = users_information.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"../../../Data/Pickle/user_to_party_paro.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624358/624358 [00:00<00:00, 1256998.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert users_information DataFrame to a dictionary for fast lookup\n",
    "users_info_dict = users_information.set_index('Author ID')['Author Name'].to_dict()\n",
    "\n",
    "nodes_label = []\n",
    "nodes_political_affilitation = []\n",
    "for i in tqdm(nodes_id):\n",
    "    # Assign label\n",
    "    label = users_info_dict.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_label.append(label)\n",
    "\n",
    "    # Assign Political Affiliation\n",
    "    pa = user_to_party_paro.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_political_affilitation.append(pa)\n",
    "\n",
    "num_nodes = len(nodes_id)\n",
    "nodes_idx = [i for i in range(num_nodes)]\n",
    "\n",
    "# Create dictionary\n",
    "nodes_dict = {\n",
    "    'id': nodes_id,\n",
    "    'idx': nodes_idx,\n",
    "    'label': nodes_label,\n",
    "    'pa': nodes_political_affilitation\n",
    "}\n",
    "\n",
    "# Save as pickle\n",
    "with open(\"../../../Data/Daily_graphs/nodes_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nodes_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624358"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_dict[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify indices where \"pa\" is not nan\n",
    "indices_to_keep = [i for i, pa_value in enumerate(nodes_dict[\"pa\"]) if str(pa_value) != \"nan\"]\n",
    "\n",
    "# Create a new dictionary with filtered values\n",
    "nodes_dict_filtered = {key: [value[i] for i in indices_to_keep] for key, value in nodes_dict.items()}\n",
    "\n",
    "# Fix idx\n",
    "nodes_dict_filtered[\"idx\"] = [i for i in range(num_nodes)]\n",
    "# Fix id\n",
    "nodes_dict_filtered[\"id\"] = [int(i) for i in nodes_dict_filtered[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37112"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = len(nodes_dict_filtered[\"id\"])\n",
    "num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37112"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes_dict_filtered[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets['Author ID'] = retweets['Author ID'].astype(int)\n",
    "retweets['Referenced Tweet Author ID'] = retweets['Referenced Tweet Author ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_dict_filtered[\"id\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_filtered = retweets.copy()\n",
    "retweets_filtered = retweets_filtered.loc[retweets['Author ID'].isin(nodes_dict_filtered[\"id\"]),:]\n",
    "retweets_filtered = retweets_filtered.loc[retweets['Referenced Tweet Author ID'].isin(nodes_dict_filtered[\"id\"]),:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/63 [00:07<03:56,  3.88s/it]"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for O(1) lookup time of indices\n",
    "id_to_idx = {node_id: idx for idx, node_id in enumerate(nodes_dict_filtered['id'])}\n",
    "\n",
    "for d in tqdm(daily_grid):\n",
    "    # Filter retweets first\n",
    "    retweets_filtered2 = retweets_filtered[retweets_filtered['Date'] == d.date()]\n",
    "    \n",
    "    # Create weights\n",
    "    test = retweets_filtered2.groupby(['Author ID', 'Referenced Tweet Author ID']).size().reset_index(name=\"w\")\n",
    "    \n",
    "    # Use dictionary lookups for index mappings\n",
    "    test['idx_s'] = [id_to_idx.get(x, np.nan) for x in test['Author ID']]\n",
    "    test['idx_t'] = [id_to_idx.get(x, np.nan) for x in test['Referenced Tweet Author ID']]\n",
    "    \n",
    "    # The edge list should be based on the idx of the nodes and include weights\n",
    "    edges_list_with_weights = list(zip(test['idx_s'].dropna().astype(int), test['idx_t'].dropna().astype(int), test['w']))\n",
    "    \n",
    "    # Create graph\n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(num_nodes)\n",
    "    \n",
    "    # Node attributes\n",
    "    node_id = g.new_vertex_property(\"string\", vals=nodes_dict_filtered['id'])\n",
    "    node_label = g.new_vertex_property(\"string\", vals=nodes_dict_filtered['label'])\n",
    "    node_affiliation = g.new_vertex_property(\"string\", vals=nodes_dict_filtered['pa'])\n",
    "    \n",
    "    # Assign attributes to graph\n",
    "    g.vertex_properties[\"ID\"] = node_id\n",
    "    g.vertex_properties[\"Label\"] = node_label\n",
    "    g.vertex_properties[\"Political Affiliation\"] = node_affiliation\n",
    "    \n",
    "    # Edge weight attribute\n",
    "    edge_weights = g.new_edge_property(\"int\")\n",
    "    \n",
    "    # Add edges and assign weights\n",
    "    for source, target, weight in edges_list_with_weights:\n",
    "        e = g.add_edge(source, target)\n",
    "        edge_weights[e] = weight\n",
    "\n",
    "    g.edge_properties[\"weight\"] = edge_weights\n",
    "    \n",
    "    g.save(os.path.join(\"../../../Data/Daily_graphs/Full network\", str(d.date()) + \".graphml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g)\n",
    "print(g.vp[\"ID\"][624353])\n",
    "print(g.vp[\"Label\"][624353])\n",
    "print(g.vp[\"Political Affiliation\"][624353])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
