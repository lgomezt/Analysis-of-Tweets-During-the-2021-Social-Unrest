{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we create a daily retweet network. First, we transform our dataset into a Source-Target DataFrame. Afterward, we construct a `graph-tool` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import find\n",
    "import scipy.sparse\n",
    "import graph_tool.all as gt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45330718, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:37:59</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.419439e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:37:16</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>8.628063e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:31:36</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.402301e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:30:41</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>3.824198e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.180596e+17</td>\n",
       "      <td>2021/06/29 23:29:39</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1.483430e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author ID                 Date Reference Type  \\\n",
       "0  9.180596e+17  2021/06/29 23:37:59      retweeted   \n",
       "1  9.180596e+17  2021/06/29 23:37:16      retweeted   \n",
       "2  9.180596e+17  2021/06/29 23:31:36      retweeted   \n",
       "3  9.180596e+17  2021/06/29 23:30:41      retweeted   \n",
       "4  9.180596e+17  2021/06/29 23:29:39      retweeted   \n",
       "\n",
       "   Referenced Tweet Author ID  \n",
       "0                1.419439e+08  \n",
       "1                8.628063e+17  \n",
       "2                1.402301e+18  \n",
       "3                3.824198e+08  \n",
       "4                1.483430e+07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/tweets_lite.gzip', compression='gzip')\n",
    "print('Shape:', tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function which returns a Boolean specifying if matrix is Non Zero\n",
    "def is_matrix_nonzero(matrix):\n",
    "    return len(matrix.nonzero()[0]) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Dictionary with all the Author IDs and their indexes in the Dataframe. This will help us query the Dataframe for the Tweets and ReTweets of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are some nan's values. Proof: nan at -1\n"
     ]
    }
   ],
   "source": [
    "tweets['Date'] = pd.to_datetime(tweets['Date'], errors = 'coerce')\n",
    "\n",
    "# List of Twitter users\n",
    "users = np.unique(tweets[['Author ID']].values)\n",
    "print(f\"there are some nan's values. Proof: {users[-1]} at -1\" )\n",
    "users = users[:-1]\n",
    "users = [ int(x) for x in users ]\n",
    "\n",
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date1 = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "v2_start = '2021-04-30 23:59:59'\n",
    "v2_end = '2021-06-29 23:59:59'\n",
    "date2 = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "user_indices = {user: idx for idx, user in enumerate(users)}\n",
    "datestr = list(date2.strftime(\"%d-%m-%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save this file for further usage\n",
    "with open('../../../Data/Pickle/user_indices.pkl', 'wb') as file:\n",
    "    pickle.dump(user_indices, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../Data/Pickle/user_to_party_paro.pkl', 'rb') as file:\n",
    "    user_to_party_paro = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each matrix contains the Retweet Network in windows of 3 days between April 28 and June 27 of 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this _for loop_ we create the adjacency matrix for constructing the graph.\n",
    "\n",
    "Each cell _RT<sub>i,j</sub>_ is the amount of Tweets the _i_ user Retweeted from the _j_ user.\n",
    "\n",
    "This process is done for all the tweets done in intervals of 3 days during the Paro Nacional.\n",
    "\n",
    "The Adjacency Matrix will be stored in the Matrices folder of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "os.chdir('../../../Data/Matrices/')\n",
    "for start_date, end_date in tqdm(zip(date1, date2)):\n",
    "    # get tweets by current day between start_date and end_date\n",
    "    test = tweets[(tweets['Date'] >= start_date) & (tweets['Date'] <= end_date)]\n",
    "\n",
    "    # 'rts' dataframe contains the Author ID and the Referenced Author ID in the \n",
    "    # timeframe we are interested.\n",
    "    rts = test.loc[(test[\"Reference Type\"] == \"retweeted\") & (test[\"Referenced Tweet Author ID\"].isin(users)),\n",
    "                                                    [\"Author ID\", \"Referenced Tweet Author ID\"]]\n",
    "\n",
    "    # We rename the 'rts' dataframe columns for code easyness now.\n",
    "    new_column_names = {'Author ID':'user1', 'Referenced Tweet Author ID':'user2'}\n",
    "    rts = rts.rename(columns = new_column_names)\n",
    "    \n",
    "    # Because of the data structure, we use a sparse matrix.\n",
    "    A = sp.csr_matrix((len(users), len(users)), dtype = int)\n",
    "    lil = lil_matrix(A.shape)\n",
    "\n",
    "    for row in rts.itertuples(index = False):\n",
    "        user1, user2 = row.user1, row.user2\n",
    "    \n",
    "        idx_user1 = user_indices[user1]\n",
    "        idx_user2 = user_indices[user2]\n",
    "\n",
    "        lil[idx_user1, idx_user2] += 1\n",
    "        lil[idx_user2, idx_user1] += 1\n",
    "\n",
    "    if is_matrix_nonzero(lil):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Matrix is zero\")\n",
    "    \n",
    "    # This matrices are sparse. Therefore, we save it as such.\n",
    "    A = lil.tocsr()\n",
    "    filename = f'adj_end_of_{datestr[k]}.csr'\n",
    "    sp.save_npz(filename, A, compressed = False)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_4.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_5.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_3.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_2.gzip',\n",
       " '/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_1.gzip']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_paro = glob.glob('/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_*')\n",
    "tweets_paro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:44<00:00, 32.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30918011, 14)\n"
     ]
    }
   ],
   "source": [
    "# Import the tweets from Paro but select only the retweets\n",
    "retweets = pd.DataFrame()\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets = pd.read_pickle(file, compression = \"gzip\")\n",
    "    # Select only retweets\n",
    "    rts = tweets.loc[tweets[\"Reference Type\"] == \"retweeted\",:].reset_index(drop = True)\n",
    "    rts = rts.drop(columns = 'Reference Type')\n",
    "    retweets = pd.concat([retweets, rts], axis = 0)\n",
    "retweets = retweets.reset_index(drop = True)\n",
    "del rts, tweets \n",
    "print('Shape:', retweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>is Retweet?</th>\n",
       "      <th>Reply To User Name</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.409944e+18</td>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/29 13:38:42</td>\n",
       "      <td>RT @udsnoexisten: Feliz almuerzo para todos ht...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>udsnoexisten</td>\n",
       "      <td>1.409943e+18</td>\n",
       "      <td>2.195296e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.409726e+18</td>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/28 23:09:28</td>\n",
       "      <td>RT @charlasamenas63: El Profesionalismo de jug...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>charlasamenas63</td>\n",
       "      <td>1.409726e+18</td>\n",
       "      <td>9.273397e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.409498e+18</td>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/28 08:05:01</td>\n",
       "      <td>RT @elyrxc: What's up bro... üôä üòçü§£ https://t.co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>elyrxc</td>\n",
       "      <td>1.409352e+18</td>\n",
       "      <td>1.402825e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.409266e+18</td>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/27 16:41:47</td>\n",
       "      <td>RT @Lidio_Dominante: Aqu√≠ la derecha debe ente...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lidio_Dominante</td>\n",
       "      <td>1.409202e+18</td>\n",
       "      <td>1.391738e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.408904e+18</td>\n",
       "      <td>325932532.0</td>\n",
       "      <td>wilman_86</td>\n",
       "      <td>2021/06/26 16:46:05</td>\n",
       "      <td>RT @Lidio_Dominante: No hay m√©rito en que teng...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lidio_Dominante</td>\n",
       "      <td>1.408853e+18</td>\n",
       "      <td>1.391738e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID    Author ID Author Name                 Date  \\\n",
       "0  1.409944e+18  325932532.0   wilman_86  2021/06/29 13:38:42   \n",
       "1  1.409726e+18  325932532.0   wilman_86  2021/06/28 23:09:28   \n",
       "2  1.409498e+18  325932532.0   wilman_86  2021/06/28 08:05:01   \n",
       "3  1.409266e+18  325932532.0   wilman_86  2021/06/27 16:41:47   \n",
       "4  1.408904e+18  325932532.0   wilman_86  2021/06/26 16:46:05   \n",
       "\n",
       "                                                Text  Replies  Retweets  \\\n",
       "0  RT @udsnoexisten: Feliz almuerzo para todos ht...      0.0     131.0   \n",
       "1  RT @charlasamenas63: El Profesionalismo de jug...      0.0       1.0   \n",
       "2  RT @elyrxc: What's up bro... üôä üòçü§£ https://t.co...      0.0       1.0   \n",
       "3  RT @Lidio_Dominante: Aqu√≠ la derecha debe ente...      0.0      84.0   \n",
       "4  RT @Lidio_Dominante: No hay m√©rito en que teng...      0.0      17.0   \n",
       "\n",
       "   Favorites  Quotes is Retweet? Reply To User Name          Mentions  \\\n",
       "0        0.0     0.0        True                NaN      udsnoexisten   \n",
       "1        0.0     0.0        True                NaN   charlasamenas63   \n",
       "2        0.0     0.0        True                NaN            elyrxc   \n",
       "3        0.0     0.0        True                NaN   Lidio_Dominante   \n",
       "4        0.0     0.0        True                NaN   Lidio_Dominante   \n",
       "\n",
       "   Referenced Tweet  Referenced Tweet Author ID  \n",
       "0      1.409943e+18                2.195296e+07  \n",
       "1      1.409726e+18                9.273397e+17  \n",
       "2      1.409352e+18                1.402825e+18  \n",
       "3      1.409202e+18                1.391738e+18  \n",
       "4      1.408853e+18                1.391738e+18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types\n",
    "retweets[\"ID\"] = retweets[\"ID\"].astype(int)\n",
    "retweets[\"Author ID\"] = retweets[\"Author ID\"].astype(int)\n",
    "retweets['Referenced Tweet Author ID'] = retweets['Referenced Tweet Author ID'].astype(int)\n",
    "retweets['Referenced Tweet'] = retweets['Referenced Tweet'].astype(int)\n",
    "# Remove time from retweets date\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faltan clasificar 598057 usuarios\n"
     ]
    }
   ],
   "source": [
    "# Import political labelling dictionary\n",
    "user_to_party_paro = pd.read_pickle(\"/mnt/disk2/Data/Pickle/user_to_party_paro.pkl\")\n",
    "\n",
    "ids_faltantes1 = set(retweets[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(retweets[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(ids_faltantes)} usuarios\")\n",
    "\n",
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Source-Target DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have retweets from 2021-04-28 to 2021-06-29\n"
     ]
    }
   ],
   "source": [
    "fecha_min = retweets[\"Date\"].min()\n",
    "fecha_max = retweets[\"Date\"].max()\n",
    "print(f\"We have retweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = pd.read_pickle(\"../../../Data/Tweets_DataFrames/users_information.gzip\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Referenced Tweet Author\n",
    "retweets = users_information.reset_index()[[\"Author ID\", \"Author Name\"]] \\\n",
    "    .rename(columns = {\"Author ID\": \"Referenced Tweet Author ID\", \n",
    "                       \"Author Name\": \"Referenced Tweet Author Name\"}) \\\n",
    "                       .merge(retweets, how = \"right\", on = \"Referenced Tweet Author ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Referenced Tweet Author ID           0\n",
       "Referenced Tweet Author Name    587246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users without name\n",
    "retweets.iloc[:, 0:2].drop_duplicates().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [03:11<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(daily_grid):\n",
    "    # Select the retweets from the desired date\n",
    "    temp = retweets[retweets['Date'] == d.date()]\n",
    "    temp = temp.groupby([\"Author ID\", \"Author Name\", \"Date\", \"Referenced Tweet Author ID\", \"Referenced Tweet Author Name\"]).size().reset_index(name = \"w\")\n",
    "    temp.columns = [\"source\", \"source_label\", \"date\", \"target\", \"target_label\", \"w\"]\n",
    "    # Assign political affiliation\n",
    "    temp[\"source_political_afilliation\"] = temp[\"source\"].apply(lambda x: user_to_party_paro[x])\n",
    "    temp[\"target_political_afilliation\"] = temp[\"target\"].apply(lambda x: user_to_party_paro[x])\n",
    "    # Save results as csv\n",
    "    temp.to_csv(os.path.join(save_path, \"Source-Target\", str(d.date()) + \".csv\"), index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node list\n",
    "nodes_id = list(set(retweets[\"Author ID\"]).union(set(retweets[\"Referenced Tweet Author ID\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_information = users_information.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/624358 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 624358/624358 [00:01<00:00, 429591.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert users_information DataFrame to a dictionary for fast lookup\n",
    "users_info_dict = users_information.set_index('Author ID')['Author Name'].to_dict()\n",
    "\n",
    "nodes_label = []\n",
    "nodes_political_affilitation = []\n",
    "for i in tqdm(nodes_id):\n",
    "    # Assign label\n",
    "    label = users_info_dict.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_label.append(label)\n",
    "\n",
    "    # Assign Political Affiliation\n",
    "    pa = user_to_party_paro.get(i, np.nan) # using .get() for safe dictionary lookup\n",
    "    nodes_political_affilitation.append(pa)\n",
    "\n",
    "num_nodes = len(nodes_id)\n",
    "nodes_idx = [i for i in range(num_nodes)]\n",
    "\n",
    "# Create dictionary\n",
    "nodes_dict = {\n",
    "    'id': nodes_id,\n",
    "    'idx': nodes_idx,\n",
    "    'label': nodes_label,\n",
    "    'pa': nodes_political_affilitation\n",
    "}\n",
    "\n",
    "# Save as pickle\n",
    "with open(\"../../../Data/Daily_graphs/nodes_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nodes_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 21/63 [19:38<36:55, 52.75s/it]"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for O(1) lookup time of indices\n",
    "id_to_idx = {node_id: idx for idx, node_id in enumerate(nodes_dict['id'])}\n",
    "\n",
    "for d in tqdm(daily_grid):\n",
    "    # Filter retweets first\n",
    "    filtered_retweets = retweets[retweets['Date'] == d.date()]\n",
    "    \n",
    "    # Create weights\n",
    "    test = filtered_retweets.groupby(['Author ID', 'Referenced Tweet Author ID']).size().reset_index(name=\"w\")\n",
    "    \n",
    "    # Use dictionary lookups for index mappings\n",
    "    test['idx_s'] = [id_to_idx.get(x, np.nan) for x in test['Author ID']]\n",
    "    test['idx_t'] = [id_to_idx.get(x, np.nan) for x in test['Referenced Tweet Author ID']]\n",
    "    \n",
    "    # The edge list should be based on the idx of the nodes and include weights\n",
    "    edges_list_with_weights = list(zip(test['idx_s'].dropna().astype(int), test['idx_t'].dropna().astype(int), test['w']))\n",
    "    \n",
    "    # Create graph\n",
    "    g = gt.Graph(directed=True)\n",
    "    g.add_vertex(num_nodes)\n",
    "    \n",
    "    # Node attributes\n",
    "    node_id = g.new_vertex_property(\"string\", vals=nodes_dict['id'])\n",
    "    node_label = g.new_vertex_property(\"string\", vals=nodes_dict['label'])\n",
    "    node_affiliation = g.new_vertex_property(\"string\", vals=nodes_dict['pa'])\n",
    "    \n",
    "    # Assign attributes to graph\n",
    "    g.vertex_properties[\"ID\"] = node_id\n",
    "    g.vertex_properties[\"Label\"] = node_label\n",
    "    g.vertex_properties[\"Political Affiliation\"] = node_affiliation\n",
    "    \n",
    "    # Edge weight attribute\n",
    "    edge_weights = g.new_edge_property(\"int\")\n",
    "    \n",
    "    # Add edges and assign weights\n",
    "    for source, target, weight in edges_list_with_weights:\n",
    "        e = g.add_edge(source, target)\n",
    "        edge_weights[e] = weight\n",
    "\n",
    "    g.edge_properties[\"weight\"] = edge_weights\n",
    "    \n",
    "    g.save(os.path.join(save_path, str(d.date()) + \".graphml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Graph object, directed, with 624358 vertices and 460845 edges, 3 internal vertex properties, at 0x7f08b17f8150>\n",
      "113246190\n",
      "renlopezs\n",
      "Retweets Centro\n"
     ]
    }
   ],
   "source": [
    "print(g)\n",
    "print(g.vp[\"ID\"][624353])\n",
    "print(g.vp[\"Label\"][624353])\n",
    "print(g.vp[\"Political Affiliation\"][624353])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
