{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we create the adjacency matrices for the creation of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import find\n",
    "import scipy.sparse\n",
    "import graph_tool.all as gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here We import the necessary data and then look it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle('/mnt/disk2/Data/Tweets_DataFrames/tweets_lite.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45330426, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000014e+18</td>\n",
       "      <td>2021/06/28 08:17:49</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>352373166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000014e+18</td>\n",
       "      <td>2021/06/25 12:00:06</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>14834302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000014e+18</td>\n",
       "      <td>2021/06/25 11:52:30</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>528290945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000014e+18</td>\n",
       "      <td>2021/06/24 17:49:16</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>753376280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000014e+18</td>\n",
       "      <td>2021/06/24 15:21:04</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>132102878.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author ID                 Date Reference Type  \\\n",
       "0  1.000014e+18  2021/06/28 08:17:49      retweeted   \n",
       "1  1.000014e+18  2021/06/25 12:00:06      retweeted   \n",
       "2  1.000014e+18  2021/06/25 11:52:30      retweeted   \n",
       "3  1.000014e+18  2021/06/24 17:49:16      retweeted   \n",
       "4  1.000014e+18  2021/06/24 15:21:04      retweeted   \n",
       "\n",
       "   Referenced Tweet Author ID  \n",
       "0                 352373166.0  \n",
       "1                  14834302.0  \n",
       "2                 528290945.0  \n",
       "3                 753376280.0  \n",
       "4                 132102878.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape:', tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet network with a 3-day rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function which returns a Boolean specifying if matrix is Non Zero\n",
    "def is_matrix_nonzero(matrix):\n",
    "    return len(matrix.nonzero()[0]) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a Dictionary with all the Author IDs and their indexes in the Dataframe. This will help us query the Dataframe for the Tweets and ReTweets of each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Date'] = pd.to_datetime(tweets['Date'], errors = 'coerce')\n",
    "\n",
    "# List of Twitter users\n",
    "users = np.unique(tweets[['Author ID']].values)\n",
    "users = [ int(x) for x in users ]\n",
    "\n",
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date1 = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "v2_start = '2021-04-30 23:59:59'\n",
    "v2_end = '2021-06-29 23:59:59'\n",
    "date2 = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "\n",
    "user_indices = {user: idx for idx, user in enumerate(users)}\n",
    "datestr = list(date2.strftime(\"%d-%m-%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save this file for further usage\n",
    "with open('../fcastrillon/Data/user_indices.pkl', 'wb') as file:\n",
    "    pickle.dump(user_indices, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each matrix contains the Retweet Network in windows of 3 days between April 28 and June 27 of 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this _for loop_ we create the adjacency matrix for constructing the graph.\n",
    "\n",
    "Each cell _RT<sub>i,j</sub>_ is the amount of Tweets the _i_ user Retweeted from the _j_ user.\n",
    "\n",
    "This process is done for all the tweets done in intervals of 3 days during the Paro Nacional.\n",
    "\n",
    "The Adjacency Matrix will be stored in the Matrices folder of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "os.chdir('../Matrices/')\n",
    "for start_date, end_date in tqdm(zip(date1, date2)):\n",
    "    # get tweets by current day between start_date and end_date\n",
    "    test = tweets[(tweets['Date'] >= start_date) & (tweets['Date'] <= end_date)]\n",
    "\n",
    "    # 'rts' dataframe contains the Author ID and the Referenced Author ID in the \n",
    "    # timeframe we are interested.\n",
    "    rts = test.loc[(test[\"Reference Type\"] == \"retweeted\") & (test[\"Referenced Tweet Author ID\"].isin(users)),\n",
    "                                                    [\"Author ID\", \"Referenced Tweet Author ID\"]]\n",
    "\n",
    "    # We rename the 'rts' dataframe columns for code easyness now.\n",
    "    new_column_names = {'Author ID':'user1', 'Referenced Tweet Author ID':'user2'}\n",
    "    rts = rts.rename(columns = new_column_names)\n",
    "    \n",
    "    # Because of the data structure, we use a sparse matrix.\n",
    "    A = sp.csr_matrix((len(users), len(users)), dtype = int)\n",
    "    lil = lil_matrix(A.shape)\n",
    "\n",
    "    for row in rts.itertuples(index = False):\n",
    "        user1, user2 = row.user1, row.user2\n",
    "    \n",
    "        idx_user1 = user_indices[user1]\n",
    "        idx_user2 = user_indices[user2]\n",
    "\n",
    "        lil[idx_user1, idx_user2] += 1\n",
    "        lil[idx_user2, idx_user1] += 1\n",
    "\n",
    "    if is_matrix_nonzero(lil):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Matrix is zero\")\n",
    "    \n",
    "    # This matrices are sparse. Therefore, we save it as such.\n",
    "    A = lil.tocsr()\n",
    "    filename = f'adj_end_of_{datestr[k]}.csr'\n",
    "    sp.save_npz(filename, A, compressed = False)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily retweet network (with no rolling window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_to_party_jan_oct.pkl',\n",
       " 'mapa.pkl',\n",
       " 'user_to_party.pkl',\n",
       " 'rts_usuario.pkl',\n",
       " 'users_to_date.pkl',\n",
       " 'rts_usuario_paro.pkl',\n",
       " 'user_to_party_paro.pkl',\n",
       " 'rts_usuario_jan_oct.pkl',\n",
       " 'user_indices.pkl',\n",
       " 'tweets_jan21.gzip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/mnt/disk2/Data/Pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (30918011, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import tweets from Paro\n",
    "# tweets = pd.read_pickle(r'/mnt/disk2/Data/Tweets_DataFrames/tweets_Usuarios_V1.gzip')\n",
    "user_to_party_paro = pd.read_pickle(\"/mnt/disk2/Data/Pickle/user_to_party_paro.pkl\")\n",
    "# Select only retweets\n",
    "rtweets = tweets.loc[tweets[\"Reference Type\"] == \"retweeted\",:].reset_index(drop = True)\n",
    "rtweets = rtweets.drop(columns = 'Reference Type')\n",
    "rtweets = rtweets.reset_index(drop = True)\n",
    "print('Shape:', rtweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types\n",
    "rtweets[\"Author ID\"] = rtweets[\"Author ID\"].astype(int)\n",
    "rtweets['Referenced Tweet Author ID'] = rtweets['Referenced Tweet Author ID'].astype(int)\n",
    "# Remove time from rtweets date\n",
    "rtweets[\"Date\"] = pd.to_datetime(rtweets[\"Date\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000013974610567168</td>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>352373166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000013974610567168</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>14834302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000013974610567168</td>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>528290945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000013974610567168</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>753376280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000013974610567168</td>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>132102878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author ID        Date  Referenced Tweet Author ID\n",
       "0  1000013974610567168  2021-06-28                   352373166\n",
       "1  1000013974610567168  2021-06-25                    14834302\n",
       "2  1000013974610567168  2021-06-25                   528290945\n",
       "3  1000013974610567168  2021-06-24                   753376280\n",
       "4  1000013974610567168  2021-06-24                   132102878"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faltan clasificar 598057 usuarios\n"
     ]
    }
   ],
   "source": [
    "ids_faltantes1 = set(rtweets[\"Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes2 = set(rtweets[\"Referenced Tweet Author ID\"]) - set(user_to_party_paro.keys())\n",
    "ids_faltantes = np.concatenate((list(ids_faltantes1), list(ids_faltantes2)))\n",
    "print(f\"Faltan clasificar {len(ids_faltantes)} usuarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los dejamos como inclasificados \n",
    "for usuario in ids_faltantes:\n",
    "    user_to_party_paro[usuario] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have rtweets from 2021-04-28 to 2021-06-29\n"
     ]
    }
   ],
   "source": [
    "fecha_min = rtweets[\"Date\"].min()\n",
    "fecha_max = rtweets[\"Date\"].max()\n",
    "print(f\"We have rtweets from {fecha_min.strftime('%Y-%m-%d')} to {fecha_max.strftime('%Y-%m-%d')}\")\n",
    "daily_grid = pd.date_range(start = fecha_min, end = fecha_max, freq = 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../../Data/Daily_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-04-28.gt', '2021-04-29.gt']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [26:48<00:00, 25.53s/it]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm(daily_grid):\n",
    "    # Select the retweets from the desired date\n",
    "    test = rtweets[rtweets['Date'] == d.date()]\n",
    "\n",
    "    nodes_ids = np.unique(np.concatenate((test[\"Author ID\"].unique(), test['Referenced Tweet Author ID'].unique())))\n",
    "    num_nodes = len(nodes_ids)\n",
    "    nodes_idx = [i for i in range(num_nodes)]\n",
    "    nodes_dict = dict(zip(nodes_ids, nodes_idx))\n",
    "    political_affiliations = [user_to_party_paro[i] for i in nodes_ids]\n",
    "    # The edge list should be based on the idx of the nodes, nor in their ids\n",
    "    edges_list = [(nodes_dict[row['Author ID']], nodes_dict[row['Referenced Tweet Author ID']]) for index, row in test.iterrows()]\n",
    "\n",
    "    g = gt.Graph(directed=False)\n",
    "\n",
    "    # Add nodes\n",
    "    g.add_vertex(num_nodes)\n",
    "\n",
    "    # Create attributes\n",
    "    node_id = g.new_vertex_property(\"string\")\n",
    "    node_affiliation = g.new_vertex_property(\"string\")\n",
    "\n",
    "    # Assign attributes to graph\n",
    "    g.vertex_properties[\"ID\"] = node_id\n",
    "    g.vertex_properties[\"Political Affiliation\"] = node_affiliation\n",
    "\n",
    "    # Assign attributes to each node\n",
    "    for i, z in enumerate(zip(nodes_ids, political_affiliations)):\n",
    "        node_id[g.vertex(i)] = z[0]\n",
    "        node_affiliation[g.vertex(i)] = z[1]\n",
    "\n",
    "    g.add_edge_list(edges_list)\n",
    "\n",
    "    g.save(os.path.join(save_path, str(d.date()) + \".gt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
