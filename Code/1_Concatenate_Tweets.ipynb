{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate tweets\n",
    "\n",
    "In this notebook, we will consolidate all the tweet files into a single compressed pickle file for further analysis. We have three main sets of data that we need to store: \n",
    "\n",
    "1. Data from January 2021.\n",
    "2. Data from October 2021.\n",
    "3. Data from April 28 to June 30.\n",
    "\n",
    "Each of these samples corresponds to a specific moment relevant for our analysis. The October data is used for analyzing our community during election periods, specifically the regional elections in Colombia that took place in October 2019. The data from January 2021 represents the period three months before the \"Paro Nacional,\" allowing us to track our community before the social outbreak. Finally, we have the data from the time of the \"Paro Nacional,\" which will be the focal point of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from time import perf_counter\n",
    "import warnings\n",
    "\n",
    "path = r\"/mnt/disk2/Data\"\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enero y Octubre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file, dtype={'Author ID': str, 'Referenced Tweet Author ID': str})\n",
    "        if df.empty:\n",
    "            return None, file\n",
    "        return df, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {str(e)}\")\n",
    "        return None, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regional elections: October 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25125/25125 [00:18<00:00, 1343.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished concatenating in 0 minutes with 13.585816778242588 seconds\n",
      "Finished sorting in 0 minutes with 18.066083257086575 seconds\n",
      "Finished saving in 8 minutes with 29.61275841947645 seconds\n",
      "Processed 25,125 files.\n",
      "Found 11 empty files.\n",
      "Total tweets: 5,424,132\n",
      "****************************************************************************************************\n",
      "Before Paro Nacional: January 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34048/34048 [00:25<00:00, 1354.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished concatenating in 0 minutes with 18.782765831798315 seconds\n",
      "Finished sorting in 0 minutes with 21.50655343849212 seconds\n",
      "Finished saving in 9 minutes with 12.74394468497485 seconds\n",
      "Processed 34,048 files.\n",
      "Found 5 empty files.\n",
      "Total tweets: 5,893,802\n"
     ]
    }
   ],
   "source": [
    "def main(files,savefile):\n",
    "    tweets_aux = []\n",
    "    empties = []\n",
    "\n",
    "    # Use ProcessPoolExecutor for I/O bound operations\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        # Submit all file processing tasks\n",
    "        futures = [executor.submit(process_file, file) for file in files]\n",
    "\n",
    "        # Process results as they complete\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(files)):\n",
    "            df, empty_file = future.result()\n",
    "            if df is not None:\n",
    "                tweets_aux.append(df)\n",
    "            if empty_file:\n",
    "                empties.append(empty_file)\n",
    "\n",
    "    tic = perf_counter()\n",
    "    # Concatenate all dataframes\n",
    "    tweets = pd.concat(tweets_aux, ignore_index=True)\n",
    "    del tweets_aux\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished concatenating in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "\n",
    "    # Sort and reset index\n",
    "    tic = perf_counter()\n",
    "    tweets = tweets.sort_values('ID').reset_index(drop=True)\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished sorting in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "    \n",
    "    # Store results\n",
    "    tic = perf_counter()\n",
    "    tweets.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{savefile}.gzip\"), compression=\"gzip\")\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished saving in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "    print(\"\")\n",
    "    print(f\"Processed {len(files):,} files.\")\n",
    "    print(f\"Found {len(empties):,} empty files.\")\n",
    "    print(f\"Total tweets: {len(tweets):,}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Regional elections: October 2019\")\n",
    "    files_oct = glob(os.path.join(path, 'RawData', 'users_oct_19/*.csv'))\n",
    "    main(files_oct,\"tweets_oct19\")\n",
    "    print(\"*\"*100)\n",
    "    print(\"Before Paro Nacional: January 2021\")\n",
    "    files_jan = glob(os.path.join(path, \"RawData\", \"users_jan/*.csv\"))\n",
    "    main(files_jan,\"tweets_jan21\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paro Nacional: April 28 - June 30 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_to_string(x):\n",
    "    unique_values = x.unique()\n",
    "    return ', '.join(map(str, unique_values))\n",
    "\n",
    "def process_file(file):\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            # Ignore nanmean error\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            \n",
    "            # Ignore Dtype errors, check in any case\n",
    "            warnings.simplefilter(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "            \n",
    "            df = pd.read_csv(file,low_memory=False, dtype={'Author ID': str, 'Referenced Tweet Author ID': str})\n",
    "            if df.empty:\n",
    "                return None, file, None\n",
    "            \n",
    "            # Fix some datatypes\n",
    "            df[['Author Followers', 'Author Following', 'Author Tweets']] = df[['Author Followers', 'Author Following', 'Author Tweets']].map(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "            \n",
    "            # Save user information\n",
    "            user_information = df.groupby(['Author ID', 'Author Name']).agg({\n",
    "                'Author Location': unique_to_string,\n",
    "                'Author Description': unique_to_string,\n",
    "                'Author Followers': lambda x: np.nanmean(x),\n",
    "                'Author Following': lambda x: np.nanmean(x),\n",
    "                'Author Tweets': lambda x: np.nanmax(x),\n",
    "                'Author Verified': unique_to_string})\n",
    "            \n",
    "            return df, None, user_information\n",
    "    except (ValueError, KeyError) as e:\n",
    "        return None, None, file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 5792/37324 [07:14<38:18:14,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 1 in 7 minutes with 15.519305424764752 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 11509/37324 [13:41<50:30,  8.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 2 in 6 minutes with 27.193555446341634 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 17392/37324 [20:06<28:47, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 3 in 6 minutes with 25.350479869171977 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 23019/37324 [26:33<18:45, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 4 in 6 minutes with 27.075258273631334 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 28816/37324 [32:57<10:27, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 5 in 6 minutes with 23.962212254293263 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37324/37324 [39:27<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 6 in 6 minutes with 29.920094214379787 seconds\n",
      "Processing remaining data\n",
      "Finished chunk 7 in 3 minutes with 5.160846663638949 seconds\n",
      "Finished processing Tweets. Now process users info\n",
      "Finished saving users_information in 21 minutes with 20.4131678044796 seconds\n",
      "\n",
      "Processed 37324 files.\n",
      "Found 17 empty files.\n",
      "Encountered problems with 0 files.\n",
      "Created 7 tweet files.\n",
      "Total users processed: 37307\n"
     ]
    }
   ],
   "source": [
    "def main(files):\n",
    "    df_list = []\n",
    "    users_information = []\n",
    "    empties = []\n",
    "    problems = []\n",
    "\n",
    "    count = 0  # Amount of Tweets\n",
    "    n = 0  # Number of Checkpoint\n",
    "    tic = perf_counter()\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        future_to_file = {executor.submit(process_file, file):file for file in files}\n",
    "        \n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_file), total=len(files)):\n",
    "            \n",
    "            # Process the future task\n",
    "            file = future_to_file[future]\n",
    "            df, empty, user_info = future.result()\n",
    "            \n",
    "            # SAve info of empty, corrputed and correct files\n",
    "            if df is not None:\n",
    "                df_list.append(df)\n",
    "                count += len(df)\n",
    "                users_information.append(user_info)\n",
    "            elif empty:\n",
    "                empties.append(empty)\n",
    "            else:\n",
    "                problems.append(file)\n",
    "            \n",
    "            # If we reach or exceed 7 million rows, save the file and reset\n",
    "            if count >= 7_000_000:\n",
    "                n += 1\n",
    "                concat_df = pd.concat(df_list)\n",
    "                output_filename = f\"tweets_paro_{n}.gzip\"\n",
    "                concat_df.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{output_filename}\"), compression='gzip')\n",
    "                toc = perf_counter()\n",
    "                tqdm.write(f\"Finished chunk {n} in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "                # Reset counter,list and tic for performance\n",
    "                count = 0\n",
    "                df_list = []\n",
    "                tic = perf_counter()\n",
    "\n",
    "    # Process any remaining data\n",
    "    if len(df_list)>0:\n",
    "        print(f\"Processing remaining data\")\n",
    "        n += 1\n",
    "        concat_df = pd.concat(df_list)\n",
    "        output_filename = f\"tweets_paro_{n}.gzip\"\n",
    "        concat_df.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{output_filename}\"), compression='gzip')\n",
    "        toc = perf_counter()\n",
    "        print(f\"Finished chunk {n} in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "        \n",
    "    del df_list\n",
    "    print(\"Finished processing Tweets. Now process users info\")\n",
    "    # Combine all user information\n",
    "    tic = perf_counter()\n",
    "    all_users_info = pd.concat(users_information)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        # Ignore nanmean error\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        all_users_info = (\n",
    "            all_users_info.groupby(['Author ID', 'Author Name'])\n",
    "            .agg({'Author Location': unique_to_string,\n",
    "                'Author Description': unique_to_string,\n",
    "                'Author Followers': lambda x: np.nanmean(x),\n",
    "                'Author Following': lambda x: np.nanmean(x),\n",
    "                'Author Tweets': lambda x: np.nanmax(x),\n",
    "                'Author Verified': unique_to_string})\n",
    "            .to_pickle(os.path.join(path, \"Tweets_DataFrames/users_information.gzip\"), \n",
    "                                    compression = 'gzip')\n",
    "        )\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished saving users_information in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "    print(\"\")\n",
    "    print(f\"Processed {len(files)} files.\")\n",
    "    print(f\"Found {len(empties)} empty files.\")\n",
    "    print(f\"Encountered problems with {len(problems)} files.\")\n",
    "    print(f\"Created {n} tweet files.\")\n",
    "    print(f\"Total users processed: {len(users_information)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    files_v1 = glob(os.path.join(path, 'RawData/Usuarios_V1/*.csv'))\n",
    "    main(files_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: Cargar DataFrame gigante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:40<00:00, 31.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Author Location</th>\n",
       "      <th>Author Description</th>\n",
       "      <th>Author Followers</th>\n",
       "      <th>Author Following</th>\n",
       "      <th>Author Tweets</th>\n",
       "      <th>Author Profile Image</th>\n",
       "      <th>Author Verified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>is Retweet?</th>\n",
       "      <th>Reply To User Name</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Media URLs</th>\n",
       "      <th>Media Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1409618955283668992</td>\n",
       "      <td>/hmauriciojg/status/1409618955283668996</td>\n",
       "      <td>138377765</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/28 16:05:23</td>\n",
       "      <td>@DanielSamperO A vida hp!!. @IvanDuque fue y s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>DanielSamperO IvanDuque petrogustavo</td>\n",
       "      <td>1.409586e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>134855279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1409574993596452864</td>\n",
       "      <td>/hmauriciojg/status/1409574993596452867</td>\n",
       "      <td>138377765</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/28 13:10:41</td>\n",
       "      <td>@alejarojas_g A bueno de pronto si @petrogusta...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>alejarojas_g</td>\n",
       "      <td>alejarojas_g petrogustavo</td>\n",
       "      <td>1.409192e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1131820958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1409302180847292416</td>\n",
       "      <td>/hmauriciojg/status/1409302180847292417</td>\n",
       "      <td>138377765</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/27 19:06:38</td>\n",
       "      <td>@gabodelascasas Ahí la tiene https://t.co/2WJZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>gabodelascasas</td>\n",
       "      <td>gabodelascasas</td>\n",
       "      <td>1.409298e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>62337495</td>\n",
       "      <td>https://pbs.twimg.com/media/E47Y3H4XMAMtHHu.jpg</td>\n",
       "      <td>3_1409302174933397507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1407446306113691648</td>\n",
       "      <td>/hmauriciojg/status/1407446306113691662</td>\n",
       "      <td>138377765</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/22 16:12:03</td>\n",
       "      <td>@JOHANVE_LAND Deberías hacerle esa pregunta ta...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>JOHANVE_LAND</td>\n",
       "      <td>JOHANVE_LAND petrogustavo</td>\n",
       "      <td>1.407171e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>576647412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1407176029635067904</td>\n",
       "      <td>/hmauriciojg/status/1407176029635067904</td>\n",
       "      <td>138377765</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/21 22:18:04</td>\n",
       "      <td>@ClaraLopezObre @petrogustavo Que susto tan hp...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>ClaraLopezObre</td>\n",
       "      <td>ClaraLopezObre petrogustavo</td>\n",
       "      <td>1.406750e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>126832572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                Permalink  Author ID  \\\n",
       "0  1409618955283668992  /hmauriciojg/status/1409618955283668996  138377765   \n",
       "1  1409574993596452864  /hmauriciojg/status/1409574993596452867  138377765   \n",
       "2  1409302180847292416  /hmauriciojg/status/1409302180847292417  138377765   \n",
       "3  1407446306113691648  /hmauriciojg/status/1407446306113691662  138377765   \n",
       "4  1407176029635067904  /hmauriciojg/status/1407176029635067904  138377765   \n",
       "\n",
       "   Author Name        Author Location Author Description  Author Followers  \\\n",
       "0  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "1  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "2  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "3  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "4  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "\n",
       "   Author Following  Author Tweets  \\\n",
       "0             558.0          873.0   \n",
       "1             558.0          873.0   \n",
       "2             558.0          873.0   \n",
       "3             558.0          873.0   \n",
       "4             558.0          873.0   \n",
       "\n",
       "                                Author Profile Image Author Verified  \\\n",
       "0  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "1  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "2  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "3  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "4  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "\n",
       "                  Date                                               Text  \\\n",
       "0  2021/06/28 16:05:23  @DanielSamperO A vida hp!!. @IvanDuque fue y s...   \n",
       "1  2021/06/28 13:10:41  @alejarojas_g A bueno de pronto si @petrogusta...   \n",
       "2  2021/06/27 19:06:38  @gabodelascasas Ahí la tiene https://t.co/2WJZ...   \n",
       "3  2021/06/22 16:12:03  @JOHANVE_LAND Deberías hacerle esa pregunta ta...   \n",
       "4  2021/06/21 22:18:04  @ClaraLopezObre @petrogustavo Que susto tan hp...   \n",
       "\n",
       "   Replies  Retweets  Favorites  Quotes is Retweet? Reply To User Name  \\\n",
       "0      0.0       0.0        0.0     0.0       False      DanielSamperO   \n",
       "1      0.0       0.0        0.0     0.0       False       alejarojas_g   \n",
       "2      0.0       0.0        0.0     0.0       False     gabodelascasas   \n",
       "3      0.0       0.0        0.0     0.0       False       JOHANVE_LAND   \n",
       "4      0.0       0.0        0.0     0.0       False     ClaraLopezObre   \n",
       "\n",
       "                                Mentions  Referenced Tweet Reference Type  \\\n",
       "0   DanielSamperO IvanDuque petrogustavo      1.409586e+18     replied_to   \n",
       "1              alejarojas_g petrogustavo      1.409192e+18     replied_to   \n",
       "2                         gabodelascasas      1.409298e+18     replied_to   \n",
       "3              JOHANVE_LAND petrogustavo      1.407171e+18     replied_to   \n",
       "4            ClaraLopezObre petrogustavo      1.406750e+18     replied_to   \n",
       "\n",
       "   Referenced Tweet Author ID  \\\n",
       "0                   134855279   \n",
       "1                  1131820958   \n",
       "2                    62337495   \n",
       "3                   576647412   \n",
       "4                   126832572   \n",
       "\n",
       "                                        Media URLs             Media Keys  \n",
       "0                                              NaN                    NaN  \n",
       "1                                              NaN                    NaN  \n",
       "2  https://pbs.twimg.com/media/E47Y3H4XMAMtHHu.jpg  3_1409302174933397507  \n",
       "3                                              NaN                    NaN  \n",
       "4                                              NaN                    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_paro = glob('/mnt/disk2/Data/Tweets_DataFrames/Tweets_Paro_Total/tweets_paro_*')\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets_df = pd.read_pickle(file, compression = \"gzip\").astype({'Author ID': 'Int64', 'Referenced Tweet Author ID': 'Int64','ID':'Int64'})\n",
    "    tweets = pd.concat([tweets, tweets_df], axis = 0)\n",
    "    del tweets_df\n",
    "    \n",
    "# Fill tweets that doesn't reference anyone as original tweet\n",
    "tweets[\"Reference Type\"] = tweets[\"Reference Type\"].fillna(\"original tweet\")\n",
    "\n",
    "# Drop Values we don't know anything about\n",
    "tweets.dropna(subset='Author ID', inplace=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Author Location</th>\n",
       "      <th>Author Description</th>\n",
       "      <th>Author Followers</th>\n",
       "      <th>Author Following</th>\n",
       "      <th>Author Tweets</th>\n",
       "      <th>Author Profile Image</th>\n",
       "      <th>Author Verified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>is Retweet?</th>\n",
       "      <th>Reply To User Name</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Media URLs</th>\n",
       "      <th>Media Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>1391113172245831680</td>\n",
       "      <td>/radio1040am/status/1391113172245831691</td>\n",
       "      <td>2434157119</td>\n",
       "      <td>radio1040am</td>\n",
       "      <td>Popayán Colombia</td>\n",
       "      <td>Emisora de Red Sonora Radio. Pasión por el Cau...</td>\n",
       "      <td>6054.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>24269.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/821124947...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/05/08 14:30:00</td>\n",
       "      <td>#Noticias1040 \\nEl Fiscal General y el Defenso...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original tweet</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1391113172245831680</td>\n",
       "      <td>/nuevodiaibague/status/1391113172245831692</td>\n",
       "      <td>61925350</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>Ibague - Colombia</td>\n",
       "      <td>El periódico de los tolimenses.\\n#Tolima #Ibagué</td>\n",
       "      <td>53192.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>234956.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/144258337...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/05/08 14:30:00</td>\n",
       "      <td>👉 El emprendimiento se convirtió en una altern...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original tweet</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                                   Permalink  \\\n",
       "2448  1391113172245831680     /radio1040am/status/1391113172245831691   \n",
       "1184  1391113172245831680  /nuevodiaibague/status/1391113172245831692   \n",
       "\n",
       "       Author ID     Author Name    Author Location  \\\n",
       "2448  2434157119     radio1040am   Popayán Colombia   \n",
       "1184    61925350  nuevodiaibague  Ibague - Colombia   \n",
       "\n",
       "                                     Author Description  Author Followers  \\\n",
       "2448  Emisora de Red Sonora Radio. Pasión por el Cau...            6054.0   \n",
       "1184   El periódico de los tolimenses.\\n#Tolima #Ibagué           53192.0   \n",
       "\n",
       "      Author Following  Author Tweets  \\\n",
       "2448             239.0        24269.0   \n",
       "1184            1829.0       234956.0   \n",
       "\n",
       "                                   Author Profile Image Author Verified  \\\n",
       "2448  https://pbs.twimg.com/profile_images/821124947...           False   \n",
       "1184  https://pbs.twimg.com/profile_images/144258337...           False   \n",
       "\n",
       "                     Date                                               Text  \\\n",
       "2448  2021/05/08 14:30:00  #Noticias1040 \\nEl Fiscal General y el Defenso...   \n",
       "1184  2021/05/08 14:30:00  👉 El emprendimiento se convirtió en una altern...   \n",
       "\n",
       "      Replies  Retweets  Favorites  Quotes is Retweet? Reply To User Name  \\\n",
       "2448      0.0       0.0        0.0     0.0       False                NaN   \n",
       "1184      0.0       0.0        0.0     0.0       False                NaN   \n",
       "\n",
       "     Mentions  Referenced Tweet  Reference Type  Referenced Tweet Author ID  \\\n",
       "2448      NaN               NaN  original tweet                        <NA>   \n",
       "1184      NaN               NaN  original tweet                        <NA>   \n",
       "\n",
       "     Media URLs Media Keys  \n",
       "2448        NaN        NaN  \n",
       "1184        NaN        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['ID'] == 1391113172245831680]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Lite\n",
    "We create a reduced version of the Paro data frame. This will have the same amount of rows but we will only store four columns: 'Author ID', 'Date', 'Reference Type', 'Referenced Tweet Author ID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Referenced Tweet Author ID',\n",
    "    'Date',\n",
    "    'Reference Type',\n",
    "    'Referenced Tweet'\n",
    "]\n",
    "\n",
    "tweets_lite = tweets[cols].reset_index(drop = True)\n",
    "tweets_lite.rename(columns={'ID': 'Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "tweets_lite.to_pickle(os.path.join(path, \"Tweets_DataFrames/tweets_lite.gzip\"), compression = \"gzip\")\n",
    "del tweets_lite\n",
    "toc = perf_counter()\n",
    "\n",
    "print(f\"Finished saving tweets_lite in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving tweets_lite in 9 minutes with 37.178022634238005 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "def get_reference_author_name(x):\n",
    "    try:\n",
    "        return x.split(': ')[0].split('@')[1]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Extraer Retweets\n",
    "retweets = tweets[tweets['Reference Type'] == 'retweeted'].drop(columns='Reference Type')\n",
    "\n",
    "# Extraer nombre del Usuario Retwiteado\n",
    "retweets['Referenced Tweet Author Name'] = retweets['Text'].apply(get_reference_author_name)\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Referenced Tweet Author ID',\n",
    "    'Referenced Tweet Author Name',\n",
    "    'Date',\n",
    "    'Referenced Tweet'\n",
    "]\n",
    "\n",
    "retweets = retweets[cols].reset_index(drop = True)\n",
    "retweets.rename(columns={'ID': 'Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "retweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/retweets.gzip\"), compression = \"gzip\")\n",
    "del retweets\n",
    "toc = perf_counter()\n",
    "\n",
    "print(f\"Finished saving retweets in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving original_tweets in 1 minutes with 48.37488846387714 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "# Extraer tweets originales\n",
    "original_tweets = tweets[tweets['Reference Type'] == 'original tweet'].drop(columns='Reference Type')\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Date',\n",
    "]\n",
    "\n",
    "original_tweets = original_tweets[cols].reset_index(drop = True)\n",
    "original_tweets.rename(columns={'ID': 'Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "original_tweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/original_tweets.gzip\"), compression = \"gzip\")\n",
    "del original_tweets\n",
    "toc = perf_counter()\n",
    "\n",
    "print(f\"Finished saving original_tweets in {(toc-tic)//60:,.0f} minutes with {(toc-tic)%60} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: Cargar Tweets Originales y Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Retweets\n",
    "retweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames/retweets.gzip\"), compression='gzip')\n",
    "\n",
    "retweets = retweets.astype({\n",
    "    'Author ID': float,\n",
    "    'Referenced Tweet Author ID': float\n",
    "})\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"], errors='coerce')\n",
    "\n",
    "# Load Original tweets\n",
    "original_tweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames/original_tweets.gzip\"), compression='gzip')\n",
    "\n",
    "original_tweets = original_tweets.astype({\n",
    "    'Author ID': float\n",
    "})\n",
    "original_tweets[\"Date\"] = pd.to_datetime(original_tweets[\"Date\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941999</th>\n",
       "      <td>11611502.0</td>\n",
       "      <td>KRLS</td>\n",
       "      <td>9.486508e+08</td>\n",
       "      <td>2021-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19122990</th>\n",
       "      <td>20322929.0</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>1.222422e+09</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047346</th>\n",
       "      <td>18369876.0</td>\n",
       "      <td>manibeto</td>\n",
       "      <td>1.307903e+09</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870085</th>\n",
       "      <td>14497313.0</td>\n",
       "      <td>SonyPictures</td>\n",
       "      <td>1.316942e+09</td>\n",
       "      <td>2021-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20694672</th>\n",
       "      <td>31927467.0</td>\n",
       "      <td>pitbull</td>\n",
       "      <td>1.756103e+09</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author ID   Author Name      Tweet ID        Date\n",
       "5941999   11611502.0          KRLS  9.486508e+08  2021-05-26\n",
       "19122990  20322929.0    wizkhalifa  1.222422e+09  2021-04-30\n",
       "9047346   18369876.0      manibeto  1.307903e+09  2021-05-11\n",
       "8870085   14497313.0  SonyPictures  1.316942e+09  2021-05-08\n",
       "20694672  31927467.0       pitbull  1.756103e+09  2021-05-09"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a buscar la primera instancia de cada retweet. Esto nos llevará al tweet original que tenemos que encontrar\n",
    "cols = ['Referenced Tweet Author ID','Referenced Tweet Author Name','Referenced Tweet', 'Date']\n",
    "original_retweets = retweets[cols].sort_values(by=['Referenced Tweet', 'Date'])\n",
    "original_retweets['row_number'] = original_retweets.groupby('Referenced Tweet').cumcount()\n",
    "\n",
    "# Seleccionamos la primera instancia de cada Retweet\n",
    "original_retweets = original_retweets[original_retweets['row_number'] == 0]\n",
    "\n",
    "# Nombrar columnas\n",
    "original_retweets = original_retweets.rename(columns = {\n",
    "    'Referenced Tweet': 'Tweet ID',\n",
    "    'Referenced Tweet Author ID': 'Author ID',\n",
    "    'Referenced Tweet Author Name': 'Author Name',\n",
    "})\n",
    "\n",
    "# Eliminar fila de rank\n",
    "original_retweets = original_retweets.drop(columns = 'row_number')\n",
    "original_retweets['Date'] = original_retweets['Date'].dt.date\n",
    "original_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Author ID, Author Name, Tweet ID, Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos que no hayan tweets duplicados para coger el número exacto de tweets originales que sabemos fueron retweeteados\n",
    "original_retweets[original_retweets.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75855</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75862</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75875</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75886</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83589</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531386</th>\n",
       "      <td>1389584245669208064</td>\n",
       "      <td>370873343.0</td>\n",
       "      <td>aleltbd</td>\n",
       "      <td>2021-05-04 09:14:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538223</th>\n",
       "      <td>1403105860990160896</td>\n",
       "      <td>455212894.0</td>\n",
       "      <td>leonacassiani7</td>\n",
       "      <td>2021-06-10 16:44:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541332</th>\n",
       "      <td>1405530671699791872</td>\n",
       "      <td>61925350.0</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>2021-06-17 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541917</th>\n",
       "      <td>1395056656174755840</td>\n",
       "      <td>61925350.0</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>2021-05-19 11:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542175</th>\n",
       "      <td>1391113172245831680</td>\n",
       "      <td>61925350.0</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>2021-05-08 14:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Tweet ID    Author ID     Author Name                Date\n",
       "75855                      0          0.0               0                 NaT\n",
       "75862                      0          0.0               0                 NaT\n",
       "75875                      0          0.0               0                 NaT\n",
       "75886                      0          0.0               0                 NaT\n",
       "83589                      0          0.0               0                 NaT\n",
       "...                      ...          ...             ...                 ...\n",
       "4531386  1389584245669208064  370873343.0         aleltbd 2021-05-04 09:14:36\n",
       "4538223  1403105860990160896  455212894.0  leonacassiani7 2021-06-10 16:44:40\n",
       "4541332  1405530671699791872   61925350.0  nuevodiaibague 2021-06-17 09:20:00\n",
       "4541917  1395056656174755840   61925350.0  nuevodiaibague 2021-05-19 11:40:00\n",
       "4542175  1391113172245831680   61925350.0  nuevodiaibague 2021-05-08 14:30:00\n",
       "\n",
       "[582 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos que hay duplicados. Ya que encontramos duplicados, procedemos a borrarlos\n",
    "original_tweets[original_tweets.duplicated(subset = 'Tweet ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de tweets originales (Retweeteados y no retweeteados) 10,455,352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941999</th>\n",
       "      <td>11611502.0</td>\n",
       "      <td>KRLS</td>\n",
       "      <td>948650802.0</td>\n",
       "      <td>2021-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19122990</th>\n",
       "      <td>20322929.0</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>1222421789.0</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047346</th>\n",
       "      <td>18369876.0</td>\n",
       "      <td>manibeto</td>\n",
       "      <td>1307903040.0</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870085</th>\n",
       "      <td>14497313.0</td>\n",
       "      <td>SonyPictures</td>\n",
       "      <td>1316941803.0</td>\n",
       "      <td>2021-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20694672</th>\n",
       "      <td>31927467.0</td>\n",
       "      <td>pitbull</td>\n",
       "      <td>1756102988.0</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author ID   Author Name      Tweet ID        Date\n",
       "5941999   11611502.0          KRLS   948650802.0  2021-05-26\n",
       "19122990  20322929.0    wizkhalifa  1222421789.0  2021-04-30\n",
       "9047346   18369876.0      manibeto  1307903040.0  2021-05-11\n",
       "8870085   14497313.0  SonyPictures  1316941803.0  2021-05-08\n",
       "20694672  31927467.0       pitbull  1756102988.0  2021-05-09"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tweets.drop_duplicates(subset = 'Tweet ID', inplace=True)\n",
    "original_tweets['Date'] = original_tweets['Date'].dt.date\n",
    "\n",
    "# Obtenemos lo Tweets originales y los tweets originales Retweiteados\n",
    "original = pd.concat([original_retweets, original_tweets])\n",
    "\n",
    "print(f\"Total de tweets originales (Retweeteados y no retweeteados) {len(original):,.0f}\")\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.778842e+07</td>\n",
       "      <td>JavierDMC_</td>\n",
       "      <td>1393036678219145216.0</td>\n",
       "      <td>2021-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>7.778842e+07</td>\n",
       "      <td>JavierDMC_</td>\n",
       "      <td>1388348380884185088.0</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.211572e+08</td>\n",
       "      <td>andresmpn</td>\n",
       "      <td>1395862561149669376.0</td>\n",
       "      <td>2021-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.211572e+08</td>\n",
       "      <td>andresmpn</td>\n",
       "      <td>1391516875734097920.0</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>7.608689e+17</td>\n",
       "      <td>DANILO25031974</td>\n",
       "      <td>1404769952415064064.0</td>\n",
       "      <td>2021-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543182</th>\n",
       "      <td>2.562833e+08</td>\n",
       "      <td>MJVGaray</td>\n",
       "      <td>1401578149364838400.0</td>\n",
       "      <td>2021-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543190</th>\n",
       "      <td>2.562833e+08</td>\n",
       "      <td>MJVGaray</td>\n",
       "      <td>1390106433555996672.0</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543222</th>\n",
       "      <td>1.395573e+09</td>\n",
       "      <td>PerdomoPilar</td>\n",
       "      <td>1398727746000412672.0</td>\n",
       "      <td>2021-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543230</th>\n",
       "      <td>1.395573e+09</td>\n",
       "      <td>PerdomoPilar</td>\n",
       "      <td>1396170622443692032.0</td>\n",
       "      <td>2021-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543239</th>\n",
       "      <td>1.395573e+09</td>\n",
       "      <td>PerdomoPilar</td>\n",
       "      <td>1390037030059511808.0</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811479 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author ID     Author Name               Tweet ID        Date\n",
       "137      7.778842e+07      JavierDMC_  1393036678219145216.0  2021-05-13\n",
       "161      7.778842e+07      JavierDMC_  1388348380884185088.0  2021-04-30\n",
       "168      1.211572e+08       andresmpn  1395862561149669376.0  2021-05-21\n",
       "182      1.211572e+08       andresmpn  1391516875734097920.0  2021-05-09\n",
       "192      7.608689e+17  DANILO25031974  1404769952415064064.0  2021-06-15\n",
       "...               ...             ...                    ...         ...\n",
       "4543182  2.562833e+08        MJVGaray  1401578149364838400.0  2021-06-06\n",
       "4543190  2.562833e+08        MJVGaray  1390106433555996672.0  2021-05-05\n",
       "4543222  1.395573e+09    PerdomoPilar  1398727746000412672.0  2021-05-29\n",
       "4543230  1.395573e+09    PerdomoPilar  1396170622443692032.0  2021-05-22\n",
       "4543239  1.395573e+09    PerdomoPilar  1390037030059511808.0  2021-05-05\n",
       "\n",
       "[811479 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos por tweets duplicados\n",
    "# Esto puede pasar por que en la tabla original_retweets algunos de esos tweets retweeteados estaban en base de datos\n",
    "# Al cominar las tabla original_tweets con original_retweets, estos saldrán duplicados\n",
    "original[original.duplicated(subset = 'Tweet ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 5,912,692 Retweets únicos y 4,542,660 Tweets originales únicos.\n",
      "De los 4,542,660 Tweets originales que tenemos, 811,479 fueron retweeteados y los tenemos en base de datos.\n"
     ]
    }
   ],
   "source": [
    "# Cuantos Tweets originales y retweets tenemos\n",
    "retweets_id = retweets['Referenced Tweet'].unique()\n",
    "original_tweets_id = original_tweets['Tweet ID'].unique()\n",
    "print(f\"Tenemos {len(retweets_id):,} Retweets únicos y {len(original_tweets_id):,} Tweets originales únicos.\")\n",
    "\n",
    "# De los retweets, cuantos de esos tenemos en su versión originales\n",
    "original_tweets_retweeted = set(retweets_id).intersection(set(original_tweets_id))\n",
    "print(f\"De los {len(original_tweets_id):,} Tweets originales que tenemos, {len(original_tweets_retweeted):,} fueron retweeteados y los tenemos en base de datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar DataFrames\n",
    "original.to_pickle(os.path.join(path, \"Tweets_DataFrames/original.gzip\"), compression = \"gzip\")\n",
    "original_retweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/original_retweets.gzip\"), compression = \"gzip\")\n",
    "original_tweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/original_tweets.gzip\"), compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs\n",
    "\n",
    "The output of this Notebook are stored \"/mnt/disk2/Data/Tweets_DataFrames\" and are listed below:\n",
    "\n",
    "- **tweets_jan21.gzip**: Dataframe for the Tweets for our users during January of 2021. 3 Months before the Paro\n",
    "- **tweets_oct19.gzip**: Dataframe for the Tweets for our users during October of 2019. Regional elections Period\n",
    "- **tweets_paro_i.gzip**: 5 dataframes for the tweets of our users between April 28 to June 30 of 2021\n",
    "- **tweets_lite.pkl**: Lite version of **tweets_Usuarios_V1.gzip** that contains just the colmns needed for the graph construction. Which is Author ID, Reference Type, Date and Retweet Author"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
