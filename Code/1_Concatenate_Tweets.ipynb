{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate tweets\n",
    "\n",
    "In this notebook, we will consolidate all the tweet files into a single compressed pickle file for further analysis. We have three main sets of data that we need to store: \n",
    "\n",
    "1. Data from January 2021.\n",
    "2. Data from October 2021.\n",
    "3. Data from April 28 to June 30.\n",
    "\n",
    "Each of these samples corresponds to a specific moment relevant for our analysis. The October data is used for analyzing our community during election periods, specifically the regional elections in Colombia that took place in October 2019. The data from January 2021 represents the period three months before the \"Paro Nacional,\" allowing us to track our community before the social outbreak. Finally, we have the data from the time of the \"Paro Nacional,\" which will be the focal point of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/mnt/disk2/Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional elections: October 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an empty aux list that will store the tweets.\n",
    "tweets_aux = []\n",
    "files_oct = glob(os.path.join(path, 'users_oct_19/*.csv'))\n",
    "\n",
    "for file in tqdm(files_oct):\n",
    "    tweets_aux.append(pd.read_csv(file))\n",
    "\n",
    "# Finally, the tweet dataframe is established and tweets_aux is deleted.  \n",
    "tweets = pd.concat(tweets_aux)\n",
    "del tweets_aux\n",
    "tweets = tweets.sort_values('ID').reset_index(drop = True)\n",
    "\n",
    "# Store results\n",
    "tweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/tweets_oct19.gzip\"), compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Paro Nacional: January 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify two users with their file corrupted: Usuario_82383620 and Usuario_2526574133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an empty aux list that will store the tweets.\n",
    "tweets_aux = []\n",
    "files_jan = glob(os.path.join(path, \"RawData/users_jan/*.csv\"))\n",
    "\n",
    "for file in tqdm(files_jan):\n",
    "    tweets_aux.append(pd.read_csv(file))\n",
    "\n",
    "# Finally, the tweet dataframe is established and tweets_aux is deleted.  \n",
    "tweets_jan = pd.concat(tweets_aux)\n",
    "del tweets_aux\n",
    "tweets_jan = tweets_jan.sort_values('ID').reset_index(drop = True)\n",
    "\n",
    "# We check the DataFrame\n",
    "print('Shape: ',tweets_jan.shape)\n",
    "tweets_jan.head()\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 /mnt/disk2/Data/Tweets_DataFrames in bash if it is needed\n",
    "tweets_jan.to_pickle(os.path.join(path, \"Tweets_DataFrames/tweets_jan21.gzip\"), compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paro Nacional: April 28 - June 30 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37324"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_v1 = glob(os.path.join(path, 'RawData/Usuarios_V1/*.csv'))\n",
    "len(files_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_31172486-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_418406996-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_2564362444-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_721013234-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_286818396-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_186496554-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_799005686-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_3327640233-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_2183412805-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_1286016270517841931-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_820659585770016769-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_180601646-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_1239743072516411394-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_4861663593-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_328178806-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_297706813-Juan’s MacBook Air.csv',\n",
       " '/mnt/disk2/Data/RawData/Usuarios_V1/Usuario_909410714-Juan’s MacBook Air.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "users_information = []\n",
    "\n",
    "# cols = ['ID', 'Author ID', 'Author Name', 'Date', 'Text', 'Replies', 'Retweets', 'Favorites', 'Quotes', 'is Retweet?',\n",
    "#            'Reply To User Name', 'Mentions', 'Referenced Tweet', 'Reference Type', 'Referenced Tweet Author ID']\n",
    "\n",
    "problems = []\n",
    "\n",
    "def unique_to_string(x):\n",
    "    unique_values = x.unique()\n",
    "    return ', '.join(map(str, unique_values))\n",
    "\n",
    "# Counter and variable for keeping track of file names\n",
    "count = 0 # Amount of Tweets\n",
    "n = 0 # Number of Cheackpoint\n",
    "\n",
    "# Runtime 1 Hour!!!!!\n",
    "for file in tqdm(files_v1):\n",
    "    try:\n",
    "        # df = pd.read_csv(file, usecols = cols)\n",
    "        df = pd.read_csv(file)\n",
    "        # Fix some datatypes\n",
    "        df[['Author Followers', 'Author Following', 'Author Tweets']] = df[['Author Followers', 'Author Following', 'Author Tweets']].map(lambda x: pd.to_numeric(x, errors = 'coerce'))\n",
    "        df_list.append(df)\n",
    "        count += len(df)\n",
    "\n",
    "        # Save user information\n",
    "        user_information = df.groupby(['Author ID', 'Author Name']).agg({\n",
    "                'Author Location': unique_to_string,\n",
    "                'Author Description': unique_to_string,\n",
    "                'Author Followers': lambda x: np.nanmean(x),\n",
    "                'Author Following': lambda x: np.nanmean(x),\n",
    "                'Author Tweets': lambda x: np.nanmax(x),\n",
    "                'Author Verified': unique_to_string})\n",
    "        \n",
    "        users_information.append(user_information)\n",
    "        \n",
    "        # If we reach or exceed 10 million rows, save the file and reset\n",
    "        if count >= 10_000_000:\n",
    "            n += 1\n",
    "            concat_df = pd.concat(df_list)\n",
    "            output_filename = f\"tweets_paro_{n}.gzip\"\n",
    "            concat_df.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{output_filename}\"), compression='gzip')\n",
    "            \n",
    "            # Reset counter and list\n",
    "            count = 0\n",
    "            df_list = []\n",
    "            \n",
    "    except (ValueError, KeyError) as e:\n",
    "        problems.append(file)\n",
    "\n",
    "problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save any remaining data after the loop\n",
    "# Runtime 5 minutes\n",
    "if df_list:\n",
    "    n += 1\n",
    "    concat_df = pd.concat(df_list)\n",
    "    output_filename = f\"tweets_paro_{n}.gzip\"\n",
    "    # If necessary, run \"sudo chmod 777 Data/Tweets_DataFrames\" in bash\n",
    "    concat_df.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{output_filename}\"), compression = 'gzip')\n",
    "\n",
    "del df_list, concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1710478/1078093390.py:5: RuntimeWarning: Mean of empty slice\n",
      "  'Author Followers': lambda x: np.nanmean(x),\n",
      "/tmp/ipykernel_1710478/1078093390.py:6: RuntimeWarning: Mean of empty slice\n",
      "  'Author Following': lambda x: np.nanmean(x),\n",
      "/tmp/ipykernel_1710478/1078093390.py:7: RuntimeWarning: All-NaN axis encountered\n",
      "  'Author Tweets': lambda x: np.nanmax(x),\n"
     ]
    }
   ],
   "source": [
    "# runtime 22 minutes\n",
    "concat_users_information = pd.concat(users_information)\n",
    "concat_users_information = concat_users_information.groupby(['Author ID', 'Author Name']) \\\n",
    "    .agg({'Author Location': unique_to_string,\n",
    "            'Author Description': unique_to_string,\n",
    "            'Author Followers': lambda x: np.nanmean(x),\n",
    "            'Author Following': lambda x: np.nanmean(x),\n",
    "            'Author Tweets': lambda x: np.nanmax(x),\n",
    "            'Author Verified': unique_to_string})\n",
    "concat_users_information.to_pickle(os.path.join(path, \"Tweets_DataFrames/users_information.gzip\"), \n",
    "                                   compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Author Location</th>\n",
       "      <th>Author Description</th>\n",
       "      <th>Author Followers</th>\n",
       "      <th>Author Following</th>\n",
       "      <th>Author Tweets</th>\n",
       "      <th>Author Verified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000e+00</th>\n",
       "      <th>0</th>\n",
       "      <td>True, False, True, False</td>\n",
       "      <td>nan, equidad_mujer, mariumega, PattyRosi24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.384355e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan, https://pbs.twimg.com/media/E2C38-kXEAIkE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000e+00</th>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>nan, equidad_mujer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.398276e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan, https://pbs.twimg.com/media/E19UAtWXsAYjz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000000e+00</th>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>nan, estoacaquees, thearchipielago, equidad_mu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.396578e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/ext_tw_video_thumb/14011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3.000000e+00</th>\n",
       "      <th>0</th>\n",
       "      <td>False, True</td>\n",
       "      <td>MinTransporteCo, nan, Supertransporte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.396701e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/E0ysfTuWUAUo8by.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://pbs.twimg.com/media/E1dlhtaXEAYTwol.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.389722e+18</th>\n",
       "      <th>Neoplasticista</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Arquitecto. Contra Corriente.</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.980000e+02</td>\n",
       "      <td>3534.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.389737e+18</th>\n",
       "      <th>JC13177979</th>\n",
       "      <td>Bogotá, D.C., Colombia</td>\n",
       "      <td>Aunque nadie ha podido regresar y hacer un nue...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>7083.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.389741e+18</th>\n",
       "      <th>JhonatanVRojo</th>\n",
       "      <td>Medellín, Colombia</td>\n",
       "      <td>El mundo es más que blanco &amp; negro.</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.270000e+02</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.389769e+18</th>\n",
       "      <th>VaneLen18</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.389784e+18</th>\n",
       "      <th>kars0518</th>\n",
       "      <td>COL.</td>\n",
       "      <td>nan</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.700000e+01</td>\n",
       "      <td>768.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37344 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Author Location  \\\n",
       "Author ID    Author Name                                \n",
       "0.000000e+00 0               True, False, True, False   \n",
       "1.000000e+00 0                                  False   \n",
       "2.000000e+00 0                                  False   \n",
       "3.000000e+00 0                            False, True   \n",
       "             1                                  False   \n",
       "...                                               ...   \n",
       "1.389722e+18 Neoplasticista                  Colombia   \n",
       "1.389737e+18 JC13177979        Bogotá, D.C., Colombia   \n",
       "1.389741e+18 JhonatanVRojo         Medellín, Colombia   \n",
       "1.389769e+18 VaneLen18                       Colombia   \n",
       "1.389784e+18 kars0518                            COL.   \n",
       "\n",
       "                                                            Author Description  \\\n",
       "Author ID    Author Name                                                         \n",
       "0.000000e+00 0                      nan, equidad_mujer, mariumega, PattyRosi24   \n",
       "1.000000e+00 0                                              nan, equidad_mujer   \n",
       "2.000000e+00 0               nan, estoacaquees, thearchipielago, equidad_mu...   \n",
       "3.000000e+00 0                           MinTransporteCo, nan, Supertransporte   \n",
       "             1                                                             nan   \n",
       "...                                                                        ...   \n",
       "1.389722e+18 Neoplasticista                      Arquitecto. Contra Corriente.   \n",
       "1.389737e+18 JC13177979      Aunque nadie ha podido regresar y hacer un nue...   \n",
       "1.389741e+18 JhonatanVRojo                 El mundo es más que blanco & negro.   \n",
       "1.389769e+18 VaneLen18                                                     nan   \n",
       "1.389784e+18 kars0518                                                      nan   \n",
       "\n",
       "                             Author Followers  Author Following  \\\n",
       "Author ID    Author Name                                          \n",
       "0.000000e+00 0                            NaN      1.384355e+18   \n",
       "1.000000e+00 0                            NaN      1.398276e+18   \n",
       "2.000000e+00 0                            NaN      1.396578e+18   \n",
       "3.000000e+00 0                            NaN      1.396701e+18   \n",
       "             1                            NaN               NaN   \n",
       "...                                       ...               ...   \n",
       "1.389722e+18 Neoplasticista              91.0      4.980000e+02   \n",
       "1.389737e+18 JC13177979                  94.0      1.780000e+02   \n",
       "1.389741e+18 JhonatanVRojo              103.0      4.270000e+02   \n",
       "1.389769e+18 VaneLen18                    8.0      9.300000e+01   \n",
       "1.389784e+18 kars0518                    53.0      8.700000e+01   \n",
       "\n",
       "                             Author Tweets  \\\n",
       "Author ID    Author Name                     \n",
       "0.000000e+00 0                         NaN   \n",
       "1.000000e+00 0                         NaN   \n",
       "2.000000e+00 0                         NaN   \n",
       "3.000000e+00 0                         NaN   \n",
       "             1                         NaN   \n",
       "...                                    ...   \n",
       "1.389722e+18 Neoplasticista         3534.0   \n",
       "1.389737e+18 JC13177979             7083.0   \n",
       "1.389741e+18 JhonatanVRojo          1257.0   \n",
       "1.389769e+18 VaneLen18              1179.0   \n",
       "1.389784e+18 kars0518                768.0   \n",
       "\n",
       "                                                               Author Verified  \n",
       "Author ID    Author Name                                                        \n",
       "0.000000e+00 0               nan, https://pbs.twimg.com/media/E2C38-kXEAIkE...  \n",
       "1.000000e+00 0               nan, https://pbs.twimg.com/media/E19UAtWXsAYjz...  \n",
       "2.000000e+00 0               https://pbs.twimg.com/ext_tw_video_thumb/14011...  \n",
       "3.000000e+00 0               https://pbs.twimg.com/media/E0ysfTuWUAUo8by.jp...  \n",
       "             1                 https://pbs.twimg.com/media/E1dlhtaXEAYTwol.jpg  \n",
       "...                                                                        ...  \n",
       "1.389722e+18 Neoplasticista                                              False  \n",
       "1.389737e+18 JC13177979                                                  False  \n",
       "1.389741e+18 JhonatanVRojo                                               False  \n",
       "1.389769e+18 VaneLen18                                                   False  \n",
       "1.389784e+18 kars0518                                                    False  \n",
       "\n",
       "[37344 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should correct this\n",
    "concat_users_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:03<00:00, 36.65s/it]\n"
     ]
    }
   ],
   "source": [
    "tweets_paro = glob('/mnt/disk2/Data/Tweets_DataFrames/tweets_paro_*')\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets_df = pd.read_pickle(file, compression = \"gzip\")\n",
    "\n",
    "    tweets = pd.concat([tweets, tweets_df], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets Lite\n",
    "We create a reduced version of the Paro data frame. This will have the same amount of rows but we will only store four columns: 'Author ID', 'Date', 'Reference Type', 'Referenced Tweet Author ID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the columns that we need for the Graph construction\n",
    "cols = ['Author ID','Author Name', 'Date', 'Reference Type', 'Referenced Tweet Author ID']\n",
    "tweets_lite = tweets[cols].reset_index(drop = True)\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "tweets_lite.to_pickle(os.path.join(path, \"Tweets_DataFrames/tweets_lite.gzip\"), compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outoputs\n",
    "\n",
    "The output of this Notebook are stored \"/mnt/disk2/Data/Tweets_DataFrames\" and are listed below:\n",
    "\n",
    "- **tweets_jan21.gzip**: Dataframe for the Tweets for our users during January of 2021. 3 Months before the Paro\n",
    "- **tweets_oct19.gzip**: Dataframe for the Tweets for our users during October of 2019. Regional elections Period\n",
    "- **tweets_paro_i.gzip**: 5 dataframes for the tweets of our users between April 28 to June 30 of 2021\n",
    "- **tweets_lite.pkl**: Lite version of **tweets_Usuarios_V1.gzip** that contains just the colmns needed for the graph construction. Which is Author ID, Reference Type, Date and Retweet Author"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
