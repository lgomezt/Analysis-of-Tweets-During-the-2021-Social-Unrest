{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate tweets\n",
    "\n",
    "In this notebook, we will consolidate all the tweet files into a single compressed pickle file for further analysis. We have three main sets of data that we need to store: \n",
    "\n",
    "1. Data from January 2021.\n",
    "2. Data from October 2021.\n",
    "3. Data from April 28 to June 30.\n",
    "\n",
    "Each of these samples corresponds to a specific moment relevant for our analysis. The October data is used for analyzing our community during election periods, specifically the regional elections in Colombia that took place in October 2019. The data from January 2021 represents the period three months before the \"Paro Nacional,\" allowing us to track our community before the social outbreak. Finally, we have the data from the time of the \"Paro Nacional,\" which will be the focal point of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from time import perf_counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/mnt/disk2/Data\"\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file:str):\n",
    "    # Dtypes for IDs\n",
    "    tipos = {\n",
    "        'Author ID': 'float64',\n",
    "        'Referenced Tweet Author ID': 'float64',\n",
    "        'ID': 'float64',\n",
    "        'Referenced Tweet':'float64'\n",
    "    }\n",
    "    try:\n",
    "        df = pd.read_csv(file, dtype=tipos)\n",
    "        if df.empty:\n",
    "            return None, file\n",
    "        return df, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {str(e)}\")\n",
    "        return None, file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regional elections: October 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25125/25125 [00:25<00:00, 983.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished concatenating in 0 minutes with 15.13 seconds\n",
      "Finished sorting in 0 minutes with 16.62 seconds\n",
      "Finished saving in 8 minutes with 49.07 seconds\n",
      "\n",
      "Processed 25,125 files.\n",
      "Found 11 empty files.\n",
      "Total tweets: 5,424,132\n",
      "Finish whole cell in 9.0 minutes and 59 secs.\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Before Paro Nacional: January 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34048/34048 [00:36<00:00, 942.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished concatenating in 0 minutes with 22.30 seconds\n",
      "Finished sorting in 0 minutes with 20.74 seconds\n",
      "Finished saving in 9 minutes with 37.54 seconds\n",
      "\n",
      "Processed 34,048 files.\n",
      "Found 5 empty files.\n",
      "Total tweets: 5,893,802\n",
      "Finish whole cell in 11.0 minutes and 10 secs.\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Finish presample in 18.0 minutes and 34 secs.\n",
      "Everything took 39.0 minutes and 42 secs.\n"
     ]
    }
   ],
   "source": [
    "def main(files:list[str],savefile:str):\n",
    "    tweets_aux = []\n",
    "    empties = []\n",
    "\n",
    "    # Use ProcessPoolExecutor for I/O bound operations\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        # Submit all file processing tasks\n",
    "        futures = [executor.submit(process_file, file) for file in files]\n",
    "\n",
    "        # Process results as they complete\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(files)):\n",
    "            df, empty_file = future.result()\n",
    "            if df is not None:\n",
    "                tweets_aux.append(df)\n",
    "            if empty_file:\n",
    "                empties.append(empty_file)\n",
    "\n",
    "    tic = perf_counter()\n",
    "    # Concatenate all dataframes\n",
    "    tweets = pd.concat(tweets_aux, ignore_index=True)\n",
    "    del tweets_aux\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished concatenating in {(toc-tic)//60:,.0f} minutes with {(toc-tic)%60:,.2f} seconds\")\n",
    "\n",
    "    # Sort and reset index\n",
    "    tic = perf_counter()\n",
    "    tweets = tweets.sort_values('ID').reset_index(drop=True)\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished sorting in {(toc-tic)//60:,.0f} minutes with {(toc-tic)%60:,.2f} seconds\")\n",
    "    \n",
    "    # Store results\n",
    "    tic = perf_counter()\n",
    "    tweets.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{savefile}.gzip\"), compression=\"gzip\")\n",
    "    toc = perf_counter()\n",
    "    \n",
    "    print(f\"Finished saving in {(toc-tic)//60:,.0f} minutes with {(toc-tic)%60:,.2f} seconds\")\n",
    "    print(\"\")\n",
    "    print(f\"Processed {len(files):,} files.\")\n",
    "    print(f\"Found {len(empties):,} empty files.\")\n",
    "    print(f\"Total tweets: {len(tweets):,}\")\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tic_total = perf_counter()\n",
    "    tic = perf_counter()\n",
    "    print(\"Regional elections: October 2019\")\n",
    "    files_oct = glob(os.path.join(path, 'RawData', 'users_oct_19/*.csv'))\n",
    "    tweets_oct19 = main(files_oct,\"tweets_oct19\")\n",
    "    toc = perf_counter()\n",
    "    time = toc - tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")\n",
    "    \n",
    "    print(\"\\n\"+\"*\"*100+\"\\n\")\n",
    "    \n",
    "    tic = perf_counter()\n",
    "    print(\"Before Paro Nacional: January 2021\")\n",
    "    files_jan = glob(os.path.join(path, \"RawData\", \"users_jan/*.csv\"))\n",
    "    tweets_jan21 = main(files_jan,\"tweets_jan21\")\n",
    "    toc = perf_counter()\n",
    "    time = toc - tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {time%60:,.0f} secs.\")\n",
    "    \n",
    "    print(\"\\n\"+\"*\"*100+\"\\n\")\n",
    "    \n",
    "    tic = perf_counter()\n",
    "    pd.concat([tweets_jan21,tweets_oct19],ignore_index=True).to_pickle(os.path.join(path,\"Tweets_DataFrames\",\"tweets_presample.gzip\"), compression = \"gzip\")\n",
    "    toc=perf_counter()\n",
    "    \n",
    "    time = toc-tic\n",
    "    print(f\"Finish saving presample in {time//60} minutes and {time%60:,.0f} secs.\")\n",
    "    time = toc-tic_total\n",
    "    print(f\"Everything took {time//60} minutes and {time%60:,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paro Nacional: April 28 - June 30 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_to_string(x):\n",
    "    unique_values = x.unique()\n",
    "    return ', '.join(map(str, unique_values))\n",
    "\n",
    "def process_file(file):\n",
    "    tipos = {\n",
    "        'Author ID': 'float64',\n",
    "        'Referenced Tweet Author ID': 'float64',\n",
    "        'ID': 'float64',\n",
    "        'Referenced Tweet':'float64'\n",
    "    }\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            # Ignore nanmean error\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            \n",
    "            # Ignore Dtype errors, check in any case\n",
    "            #warnings.simplefilter(\"ignore\", category=pd.errors.DtypeWarning)\n",
    "            \n",
    "            df = pd.read_csv(file,low_memory=False, dtype=tipos)\n",
    "            if df.empty:\n",
    "                return None, file, None\n",
    "            \n",
    "            # Fix some datatypes\n",
    "            df[['Author Followers', 'Author Following', 'Author Tweets']] = df[['Author Followers', 'Author Following', 'Author Tweets']].map(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "            \n",
    "            # Save user information\n",
    "            user_information = df.groupby(['Author ID', 'Author Name']).agg({\n",
    "                'Author Location': unique_to_string,\n",
    "                'Author Description': unique_to_string,\n",
    "                'Author Followers': lambda x: np.nanmean(x),\n",
    "                'Author Following': lambda x: np.nanmean(x),\n",
    "                'Author Tweets': lambda x: np.nanmax(x),\n",
    "                'Author Verified': unique_to_string})\n",
    "            \n",
    "            return df, None, user_information\n",
    "    except (ValueError, KeyError) as e:\n",
    "        return None, None, file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 5792/37324 [07:14<38:18:14,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 1 in 7 minutes with 15.519305424764752 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|‚ñà‚ñà‚ñà       | 11509/37324 [13:41<50:30,  8.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 2 in 6 minutes with 27.193555446341634 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 17392/37324 [20:06<28:47, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 3 in 6 minutes with 25.350479869171977 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 23019/37324 [26:33<18:45, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 4 in 6 minutes with 27.075258273631334 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 28816/37324 [32:57<10:27, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 5 in 6 minutes with 23.962212254293263 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37324/37324 [39:27<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished chunk 6 in 6 minutes with 29.920094214379787 seconds\n",
      "Processing remaining data\n",
      "Finished chunk 7 in 3 minutes with 5.160846663638949 seconds\n",
      "Finished processing Tweets. Now process users info\n",
      "Finished saving users_information in 21 minutes with 20.4131678044796 seconds\n",
      "\n",
      "Processed 37324 files.\n",
      "Found 17 empty files.\n",
      "Encountered problems with 0 files.\n",
      "Created 7 tweet files.\n",
      "Total users processed: 37307\n"
     ]
    }
   ],
   "source": [
    "def main(files):\n",
    "    df_list = []\n",
    "    users_information = []\n",
    "    empties = []\n",
    "    problems = []\n",
    "\n",
    "    count = 0  # Amount of Tweets\n",
    "    n = 0  # Number of Checkpoint\n",
    "    tic = perf_counter()\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        future_to_file = {executor.submit(process_file, file):file for file in files}\n",
    "        \n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_file), total=len(files)):\n",
    "            \n",
    "            # Process the future task\n",
    "            file = future_to_file[future]\n",
    "            df, empty, user_info = future.result()\n",
    "            \n",
    "            # SAve info of empty, corrputed and correct files\n",
    "            if df is not None:\n",
    "                df_list.append(df)\n",
    "                count += len(df)\n",
    "                users_information.append(user_info)\n",
    "            elif empty:\n",
    "                empties.append(empty)\n",
    "            else:\n",
    "                problems.append(file)\n",
    "            \n",
    "            # If we reach or exceed 7 million rows, save the file and reset\n",
    "            if count >= 7_000_000:\n",
    "                n += 1\n",
    "                concat_df = pd.concat(df_list)\n",
    "                output_filename = f\"tweets_paro_{n}.gzip\"\n",
    "                concat_df.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{output_filename}\"), compression='gzip')\n",
    "                toc = perf_counter()\n",
    "                tqdm.write(f\"Finished chunk {n} in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "                # Reset counter,list and tic for performance\n",
    "                count = 0\n",
    "                df_list = []\n",
    "                tic = perf_counter()\n",
    "\n",
    "    # Process any remaining data\n",
    "    if len(df_list)>0:\n",
    "        print(f\"Processing remaining data\")\n",
    "        n += 1\n",
    "        concat_df = pd.concat(df_list)\n",
    "        output_filename = f\"tweets_paro_{n}.gzip\"\n",
    "        concat_df.to_pickle(os.path.join(path, f\"Tweets_DataFrames/{output_filename}\"), compression='gzip')\n",
    "        toc = perf_counter()\n",
    "        print(f\"Finished chunk {n} in {(toc-tic)/60:,.0f} minutes with {(toc-tic)%60} seconds\")\n",
    "        \n",
    "    del df_list\n",
    "    print(\"Finished processing Tweets. Now process users info\")\n",
    "    # Combine all user information\n",
    "    tic = perf_counter()\n",
    "    all_users_info = pd.concat(users_information)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        # Ignore nanmean error\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        all_users_info = (\n",
    "            all_users_info.groupby(['Author ID', 'Author Name'])\n",
    "            .agg({'Author Location': unique_to_string,\n",
    "                'Author Description': unique_to_string,\n",
    "                'Author Followers': lambda x: np.nanmean(x),\n",
    "                'Author Following': lambda x: np.nanmean(x),\n",
    "                'Author Tweets': lambda x: np.nanmax(x),\n",
    "                'Author Verified': unique_to_string})\n",
    "            .to_pickle(os.path.join(path, \"Tweets_DataFrames/users_information.gzip\"), \n",
    "                                    compression = 'gzip')\n",
    "        )\n",
    "    toc = perf_counter()\n",
    "    time = toc-tic\n",
    "    print(f\"Finished saving users_information in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")\n",
    "    print(\"\")\n",
    "    print(f\"Processed {len(files)} files.\")\n",
    "    print(f\"Found {len(empties)} empty files.\")\n",
    "    print(f\"Encountered problems with {len(problems)} files.\")\n",
    "    print(f\"Created {n} tweet files.\")\n",
    "    print(f\"Total users processed: {len(users_information)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tic = perf_counter()\n",
    "    files_v1 = glob(os.path.join(path, 'RawData/Usuarios_V1/*.csv'))\n",
    "    main(files_v1)\n",
    "    toc = perf_counter()\n",
    "    time = toc - tic\n",
    "    \n",
    "    print(f\"Finish whole cell in {time//60} minutes and {round(time%60,2):,.0f} secs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: PRESAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving tweets_lite_pre of presample in 5 minutes with 42.43 seconds\n",
      "Finished saving retweets_pre in 3 minutes with 18.94 seconds\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_pickle(os.path.join(path,\"Tweets_DataFrames\",\"tweets_presample.gzip\"), compression = \"gzip\")\n",
    "\n",
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Referenced Tweet Author ID',\n",
    "    'Date',\n",
    "    'Reference Type',\n",
    "    'Referenced Tweet'\n",
    "]\n",
    "\n",
    "tweets_lite = tweets[cols].reset_index(drop = True)\n",
    "tweets_lite.rename(columns={'ID': 'Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "tweets_lite.to_pickle(os.path.join(path, \"Tweets_DataFrames\",\"tweets_lite_pre.gzip\"), compression = \"gzip\")\n",
    "del tweets_lite\n",
    "toc = perf_counter()\n",
    "time = toc-tic\n",
    "print(f\"Finished saving tweets_lite_pre of presample in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")\n",
    "\n",
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "def get_reference_author_name(x):\n",
    "    try:\n",
    "        return x.split(': ')[0].split('@')[1]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Extraer Retweets\n",
    "retweets = tweets[tweets['Reference Type'] == 'retweeted'].drop(columns='Reference Type')\n",
    "\n",
    "# Extraer nombre del Usuario Retwiteado\n",
    "retweets['Referenced Tweet Author Name'] = retweets['Text'].apply(get_reference_author_name)\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Referenced Tweet Author ID',\n",
    "    'Referenced Tweet Author Name',\n",
    "    'Referenced Tweet',\n",
    "    'Date'\n",
    "]\n",
    "\n",
    "retweets = retweets[cols].reset_index(drop = True)\n",
    "retweets.rename(columns={'ID': 'Tweet ID', 'Referenced Tweet':'Referenced Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "retweets.to_pickle(os.path.join(path, \"Tweets_DataFrames\",\"retweets_pre.gzip\"), compression = \"gzip\")\n",
    "del retweets\n",
    "toc = perf_counter()\n",
    "time = toc - tic\n",
    "\n",
    "print(f\"Finished saving retweets_pre in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: CARGAR TWEETS COMPLETOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [02:42<00:00, 23.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading whole tweets in 3 minutes with 15.39 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Author Location</th>\n",
       "      <th>Author Description</th>\n",
       "      <th>Author Followers</th>\n",
       "      <th>Author Following</th>\n",
       "      <th>Author Tweets</th>\n",
       "      <th>Author Profile Image</th>\n",
       "      <th>Author Verified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>is Retweet?</th>\n",
       "      <th>Reply To User Name</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Media URLs</th>\n",
       "      <th>Media Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.409619e+18</td>\n",
       "      <td>/hmauriciojg/status/1409618955283668996</td>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/28 16:05:23</td>\n",
       "      <td>@DanielSamperO A vida hp!!. @IvanDuque fue y s...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>DanielSamperO</td>\n",
       "      <td>DanielSamperO IvanDuque petrogustavo</td>\n",
       "      <td>1.409586e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.348553e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.409575e+18</td>\n",
       "      <td>/hmauriciojg/status/1409574993596452867</td>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/28 13:10:41</td>\n",
       "      <td>@alejarojas_g A bueno de pronto si @petrogusta...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>alejarojas_g</td>\n",
       "      <td>alejarojas_g petrogustavo</td>\n",
       "      <td>1.409192e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1.131821e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.409302e+18</td>\n",
       "      <td>/hmauriciojg/status/1409302180847292417</td>\n",
       "      <td>138377765.0</td>\n",
       "      <td>hmauriciojg</td>\n",
       "      <td>Bucaramanga, Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/154468480...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/06/27 19:06:38</td>\n",
       "      <td>@gabodelascasas Ah√≠ la tiene https://t.co/2WJZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>gabodelascasas</td>\n",
       "      <td>gabodelascasas</td>\n",
       "      <td>1.409298e+18</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>6.233750e+07</td>\n",
       "      <td>https://pbs.twimg.com/media/E47Y3H4XMAMtHHu.jpg</td>\n",
       "      <td>3_1409302174933397507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                Permalink    Author ID  \\\n",
       "0  1.409619e+18  /hmauriciojg/status/1409618955283668996  138377765.0   \n",
       "1  1.409575e+18  /hmauriciojg/status/1409574993596452867  138377765.0   \n",
       "2  1.409302e+18  /hmauriciojg/status/1409302180847292417  138377765.0   \n",
       "\n",
       "   Author Name        Author Location Author Description  Author Followers  \\\n",
       "0  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "1  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "2  hmauriciojg  Bucaramanga, Colombia                NaN              22.0   \n",
       "\n",
       "   Author Following  Author Tweets  \\\n",
       "0             558.0          873.0   \n",
       "1             558.0          873.0   \n",
       "2             558.0          873.0   \n",
       "\n",
       "                                Author Profile Image Author Verified  \\\n",
       "0  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "1  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "2  https://pbs.twimg.com/profile_images/154468480...           False   \n",
       "\n",
       "                  Date                                               Text  \\\n",
       "0  2021/06/28 16:05:23  @DanielSamperO A vida hp!!. @IvanDuque fue y s...   \n",
       "1  2021/06/28 13:10:41  @alejarojas_g A bueno de pronto si @petrogusta...   \n",
       "2  2021/06/27 19:06:38  @gabodelascasas Ah√≠ la tiene https://t.co/2WJZ...   \n",
       "\n",
       "   Replies  Retweets  Favorites  Quotes is Retweet? Reply To User Name  \\\n",
       "0      0.0       0.0        0.0     0.0       False      DanielSamperO   \n",
       "1      0.0       0.0        0.0     0.0       False       alejarojas_g   \n",
       "2      0.0       0.0        0.0     0.0       False     gabodelascasas   \n",
       "\n",
       "                                Mentions  Referenced Tweet Reference Type  \\\n",
       "0   DanielSamperO IvanDuque petrogustavo      1.409586e+18     replied_to   \n",
       "1              alejarojas_g petrogustavo      1.409192e+18     replied_to   \n",
       "2                         gabodelascasas      1.409298e+18     replied_to   \n",
       "\n",
       "   Referenced Tweet Author ID  \\\n",
       "0                1.348553e+08   \n",
       "1                1.131821e+09   \n",
       "2                6.233750e+07   \n",
       "\n",
       "                                        Media URLs             Media Keys  \n",
       "0                                              NaN                    NaN  \n",
       "1                                              NaN                    NaN  \n",
       "2  https://pbs.twimg.com/media/E47Y3H4XMAMtHHu.jpg  3_1409302174933397507  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "tweets_paro = glob('/mnt/disk2/Data/Tweets_DataFrames/Tweets_Paro_Total/tweets_paro_*')\n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "tweets_aux=[]\n",
    "tipos = {\n",
    "        'Author ID': 'float64',\n",
    "        'Referenced Tweet Author ID': 'float64',\n",
    "        'ID': 'float64',\n",
    "        'Referenced Tweet':'float64'\n",
    "    }\n",
    "\n",
    "for file in tqdm(tweets_paro):\n",
    "    tweets_df = pd.read_pickle(file, compression = \"gzip\").astype(tipos)\n",
    "    #tweets = pd.concat([tweets, tweets_df], axis = 0)\n",
    "    tweets_aux.append(tweets_df)\n",
    "    del tweets_df\n",
    "tweets = pd.concat(tweets_aux,ignore_index=True)\n",
    "# Fill tweets that doesn't reference anyone as origina\n",
    "tweets[\"Reference Type\"] = tweets[\"Reference Type\"].fillna(\"original tweet\")\n",
    "\n",
    "# Drop Values we don't know anything about\n",
    "tweets.dropna(subset='Author ID', inplace=True)\n",
    "\n",
    "# Reporting time lapsus\n",
    "toc = perf_counter()\n",
    "time = toc-tic\n",
    "print(f\"Finished loading whole tweets in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")\n",
    "\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Permalink</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Author Location</th>\n",
       "      <th>Author Description</th>\n",
       "      <th>Author Followers</th>\n",
       "      <th>Author Following</th>\n",
       "      <th>Author Tweets</th>\n",
       "      <th>Author Profile Image</th>\n",
       "      <th>Author Verified</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Quotes</th>\n",
       "      <th>is Retweet?</th>\n",
       "      <th>Reply To User Name</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Referenced Tweet</th>\n",
       "      <th>Reference Type</th>\n",
       "      <th>Referenced Tweet Author ID</th>\n",
       "      <th>Media URLs</th>\n",
       "      <th>Media Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44542043</th>\n",
       "      <td>1.391113e+18</td>\n",
       "      <td>/radio1040am/status/1391113172245831691</td>\n",
       "      <td>2.434157e+09</td>\n",
       "      <td>radio1040am</td>\n",
       "      <td>Popay√°n Colombia</td>\n",
       "      <td>Emisora de Red Sonora Radio. Pasi√≥n por el Cau...</td>\n",
       "      <td>6054.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>24269.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/821124947...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/05/08 14:30:00</td>\n",
       "      <td>#Noticias1040 \\nEl Fiscal General y el Defenso...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original tweet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45321239</th>\n",
       "      <td>1.391113e+18</td>\n",
       "      <td>/nuevodiaibague/status/1391113172245831692</td>\n",
       "      <td>6.192535e+07</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>Ibague - Colombia</td>\n",
       "      <td>El peri√≥dico de los tolimenses.\\n#Tolima #Ibagu√©</td>\n",
       "      <td>53192.0</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>234956.0</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/144258337...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021/05/08 14:30:00</td>\n",
       "      <td>üëâ El emprendimiento se convirti√≥ en una altern...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>original tweet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                                   Permalink  \\\n",
       "44542043  1.391113e+18     /radio1040am/status/1391113172245831691   \n",
       "45321239  1.391113e+18  /nuevodiaibague/status/1391113172245831692   \n",
       "\n",
       "             Author ID     Author Name    Author Location  \\\n",
       "44542043  2.434157e+09     radio1040am   Popay√°n Colombia   \n",
       "45321239  6.192535e+07  nuevodiaibague  Ibague - Colombia   \n",
       "\n",
       "                                         Author Description  Author Followers  \\\n",
       "44542043  Emisora de Red Sonora Radio. Pasi√≥n por el Cau...            6054.0   \n",
       "45321239   El peri√≥dico de los tolimenses.\\n#Tolima #Ibagu√©           53192.0   \n",
       "\n",
       "          Author Following  Author Tweets  \\\n",
       "44542043             239.0        24269.0   \n",
       "45321239            1829.0       234956.0   \n",
       "\n",
       "                                       Author Profile Image Author Verified  \\\n",
       "44542043  https://pbs.twimg.com/profile_images/821124947...           False   \n",
       "45321239  https://pbs.twimg.com/profile_images/144258337...           False   \n",
       "\n",
       "                         Date  \\\n",
       "44542043  2021/05/08 14:30:00   \n",
       "45321239  2021/05/08 14:30:00   \n",
       "\n",
       "                                                       Text  Replies  \\\n",
       "44542043  #Noticias1040 \\nEl Fiscal General y el Defenso...      0.0   \n",
       "45321239  üëâ El emprendimiento se convirti√≥ en una altern...      0.0   \n",
       "\n",
       "          Retweets  Favorites  Quotes is Retweet? Reply To User Name Mentions  \\\n",
       "44542043       0.0        0.0     0.0       False                NaN      NaN   \n",
       "45321239       0.0        0.0     0.0       False                NaN      NaN   \n",
       "\n",
       "          Referenced Tweet  Reference Type  Referenced Tweet Author ID  \\\n",
       "44542043               NaN  original tweet                         NaN   \n",
       "45321239               NaN  original tweet                         NaN   \n",
       "\n",
       "         Media URLs Media Keys  \n",
       "44542043        NaN        NaN  \n",
       "45321239        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['ID'] == 1391113172245831680]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving tweets_lite in 10 minutes with 43.02 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Referenced Tweet Author ID',\n",
    "    'Date',\n",
    "    'Reference Type',\n",
    "    'Referenced Tweet'\n",
    "]\n",
    "\n",
    "tweets_lite = tweets[cols].reset_index(drop = True)\n",
    "tweets_lite.rename(columns={'ID': 'Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "tweets_lite.to_pickle(os.path.join(path, \"Tweets_DataFrames/tweets_lite.gzip\"), compression = \"gzip\")\n",
    "del tweets_lite\n",
    "toc = perf_counter()\n",
    "time = toc-tic\n",
    "print(f\"Finished saving tweets_lite in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving retweets in 8 minutes with 17.75 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "def get_reference_author_name(x):\n",
    "    try:\n",
    "        return x.split(': ')[0].split('@')[1]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Extraer Retweets\n",
    "retweets = tweets[tweets['Reference Type'] == 'retweeted'].drop(columns='Reference Type')\n",
    "\n",
    "# Extraer nombre del Usuario Retwiteado\n",
    "retweets['Referenced Tweet Author Name'] = retweets['Text'].apply(get_reference_author_name)\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Referenced Tweet Author ID',\n",
    "    'Referenced Tweet Author Name',\n",
    "    'Referenced Tweet',\n",
    "    'Date'\n",
    "]\n",
    "\n",
    "retweets = retweets[cols].reset_index(drop = True)\n",
    "retweets.rename(columns={'ID': 'Tweet ID', 'Referenced Tweet':'Referenced Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "retweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/retweets.gzip\"), compression = \"gzip\")\n",
    "del retweets\n",
    "toc = perf_counter()\n",
    "time = toc - tic\n",
    "\n",
    "print(f\"Finished saving retweets in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished saving original tweets in 0 minutes with 48.74 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start counter\n",
    "tic = perf_counter()\n",
    "\n",
    "# Extraer tweets originales\n",
    "original_tweets = tweets[tweets['Reference Type'] == 'original tweet'].drop(columns='Reference Type')\n",
    "\n",
    "# Get just the columns that we need for the Graph construction\n",
    "cols = [\n",
    "    'ID',\n",
    "    'Author ID',\n",
    "    'Author Name',\n",
    "    'Date',\n",
    "]\n",
    "\n",
    "original_tweets = original_tweets[cols].reset_index(drop = True)\n",
    "original_tweets.rename(columns={'ID': 'Tweet ID'}, inplace=True)\n",
    "\n",
    "# Store results\n",
    "# run sudo chmod 777 Data/Tweets_DataFrames in bash if it is needed\n",
    "original_tweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/original_tweets.gzip\"), compression = \"gzip\")\n",
    "del original_tweets\n",
    "toc = perf_counter()\n",
    "time = toc - tic\n",
    "\n",
    "print(f\"Finished saving original tweets in {time//60:,.0f} minutes with {round(time%60,2):,.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECKPOINT: Cargar Tweets Originales y Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Retweets\n",
    "retweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames/retweets.gzip\"), compression='gzip')\n",
    "\n",
    "retweets = retweets.astype({\n",
    "    'Author ID': 'float64',\n",
    "    'Referenced Tweet Author ID': 'float64'\n",
    "})\n",
    "retweets[\"Date\"] = pd.to_datetime(retweets[\"Date\"], errors='coerce')\n",
    "\n",
    "# Load Original tweets\n",
    "original_tweets = pd.read_pickle(os.path.join(path, \"Tweets_DataFrames/original_tweets.gzip\"), compression='gzip')\n",
    "\n",
    "original_tweets = original_tweets.astype({\n",
    "    'Author ID': 'float64'\n",
    "})\n",
    "original_tweets[\"Date\"] = pd.to_datetime(original_tweets[\"Date\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941999</th>\n",
       "      <td>11611502.0</td>\n",
       "      <td>KRLS</td>\n",
       "      <td>9.486508e+08</td>\n",
       "      <td>2021-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19122990</th>\n",
       "      <td>20322929.0</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>1.222422e+09</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047346</th>\n",
       "      <td>18369876.0</td>\n",
       "      <td>manibeto</td>\n",
       "      <td>1.307903e+09</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870085</th>\n",
       "      <td>14497313.0</td>\n",
       "      <td>SonyPictures</td>\n",
       "      <td>1.316942e+09</td>\n",
       "      <td>2021-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20694672</th>\n",
       "      <td>31927467.0</td>\n",
       "      <td>pitbull</td>\n",
       "      <td>1.756103e+09</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author ID   Author Name      Tweet ID        Date\n",
       "5941999   11611502.0          KRLS  9.486508e+08  2021-05-26\n",
       "19122990  20322929.0    wizkhalifa  1.222422e+09  2021-04-30\n",
       "9047346   18369876.0      manibeto  1.307903e+09  2021-05-11\n",
       "8870085   14497313.0  SonyPictures  1.316942e+09  2021-05-08\n",
       "20694672  31927467.0       pitbull  1.756103e+09  2021-05-09"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a buscar la primera instancia de cada retweet. Esto nos llevar√° al tweet original que tenemos que encontrar\n",
    "cols = ['Referenced Tweet Author ID','Referenced Tweet Author Name','Referenced Tweet ID', 'Date']\n",
    "original_retweets = retweets[cols].sort_values(by=['Referenced Tweet ID', 'Date'])\n",
    "original_retweets['row_number'] = original_retweets.groupby('Referenced Tweet ID').cumcount()\n",
    "\n",
    "# Seleccionamos la primera instancia de cada Retweet\n",
    "original_retweets = original_retweets[original_retweets['row_number'] == 0]\n",
    "\n",
    "# Nombrar columnas\n",
    "original_retweets = original_retweets.rename(columns = {\n",
    "    'Referenced Tweet ID': 'Tweet ID',\n",
    "    'Referenced Tweet Author ID': 'Author ID',\n",
    "    'Referenced Tweet Author Name': 'Author Name',\n",
    "})\n",
    "\n",
    "# Eliminar fila de rank\n",
    "original_retweets = original_retweets.drop(columns = 'row_number')\n",
    "original_retweets['Date'] = original_retweets['Date'].dt.date\n",
    "original_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Author ID, Author Name, Tweet ID, Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos que no hayan tweets duplicados para coger el n√∫mero exacto de tweets originales que sabemos fueron retweeteados\n",
    "original_retweets[original_retweets.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75855</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75862</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75875</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75886</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83589</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531386</th>\n",
       "      <td>1.389584e+18</td>\n",
       "      <td>370873343.0</td>\n",
       "      <td>aleltbd</td>\n",
       "      <td>2021-05-04 09:14:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538223</th>\n",
       "      <td>1.403106e+18</td>\n",
       "      <td>455212894.0</td>\n",
       "      <td>leonacassiani7</td>\n",
       "      <td>2021-06-10 16:44:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541332</th>\n",
       "      <td>1.405531e+18</td>\n",
       "      <td>61925350.0</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>2021-06-17 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541917</th>\n",
       "      <td>1.395057e+18</td>\n",
       "      <td>61925350.0</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>2021-05-19 11:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4542175</th>\n",
       "      <td>1.391113e+18</td>\n",
       "      <td>61925350.0</td>\n",
       "      <td>nuevodiaibague</td>\n",
       "      <td>2021-05-08 14:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID    Author ID     Author Name                Date\n",
       "75855    0.000000e+00          0.0               0                 NaT\n",
       "75862    0.000000e+00          0.0               0                 NaT\n",
       "75875    0.000000e+00          0.0               0                 NaT\n",
       "75886    0.000000e+00          0.0               0                 NaT\n",
       "83589    0.000000e+00          0.0               0                 NaT\n",
       "...               ...          ...             ...                 ...\n",
       "4531386  1.389584e+18  370873343.0         aleltbd 2021-05-04 09:14:36\n",
       "4538223  1.403106e+18  455212894.0  leonacassiani7 2021-06-10 16:44:40\n",
       "4541332  1.405531e+18   61925350.0  nuevodiaibague 2021-06-17 09:20:00\n",
       "4541917  1.395057e+18   61925350.0  nuevodiaibague 2021-05-19 11:40:00\n",
       "4542175  1.391113e+18   61925350.0  nuevodiaibague 2021-05-08 14:30:00\n",
       "\n",
       "[582 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos que hay Tweet IDs duplicados. Ya que encontramos duplicados, procedemos a borrarlos\n",
    "original_tweets[original_tweets.duplicated(subset = 'Tweet ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de tweets originales (Retweeteados y no retweeteados) 10,455,352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5941999</th>\n",
       "      <td>11611502.0</td>\n",
       "      <td>KRLS</td>\n",
       "      <td>9.486508e+08</td>\n",
       "      <td>2021-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19122990</th>\n",
       "      <td>20322929.0</td>\n",
       "      <td>wizkhalifa</td>\n",
       "      <td>1.222422e+09</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9047346</th>\n",
       "      <td>18369876.0</td>\n",
       "      <td>manibeto</td>\n",
       "      <td>1.307903e+09</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8870085</th>\n",
       "      <td>14497313.0</td>\n",
       "      <td>SonyPictures</td>\n",
       "      <td>1.316942e+09</td>\n",
       "      <td>2021-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20694672</th>\n",
       "      <td>31927467.0</td>\n",
       "      <td>pitbull</td>\n",
       "      <td>1.756103e+09</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Author ID   Author Name      Tweet ID        Date\n",
       "5941999   11611502.0          KRLS  9.486508e+08  2021-05-26\n",
       "19122990  20322929.0    wizkhalifa  1.222422e+09  2021-04-30\n",
       "9047346   18369876.0      manibeto  1.307903e+09  2021-05-11\n",
       "8870085   14497313.0  SonyPictures  1.316942e+09  2021-05-08\n",
       "20694672  31927467.0       pitbull  1.756103e+09  2021-05-09"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tweets.drop_duplicates(subset = 'Tweet ID', inplace=True)\n",
    "original_tweets['Date'] = original_tweets['Date'].dt.date\n",
    "\n",
    "# Obtenemos lo Tweets originales y los tweets originales Retweiteados\n",
    "original = pd.concat([original_retweets, original_tweets])\n",
    "\n",
    "print(f\"Total de tweets originales (Retweeteados y no retweeteados) {len(original):,.0f}\")\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7.778842e+07</td>\n",
       "      <td>JavierDMC_</td>\n",
       "      <td>1.393037e+18</td>\n",
       "      <td>2021-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>7.778842e+07</td>\n",
       "      <td>JavierDMC_</td>\n",
       "      <td>1.388348e+18</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.211572e+08</td>\n",
       "      <td>andresmpn</td>\n",
       "      <td>1.395863e+18</td>\n",
       "      <td>2021-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.211572e+08</td>\n",
       "      <td>andresmpn</td>\n",
       "      <td>1.391517e+18</td>\n",
       "      <td>2021-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>7.608689e+17</td>\n",
       "      <td>DANILO25031974</td>\n",
       "      <td>1.404770e+18</td>\n",
       "      <td>2021-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543182</th>\n",
       "      <td>2.562833e+08</td>\n",
       "      <td>MJVGaray</td>\n",
       "      <td>1.401578e+18</td>\n",
       "      <td>2021-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543190</th>\n",
       "      <td>2.562833e+08</td>\n",
       "      <td>MJVGaray</td>\n",
       "      <td>1.390106e+18</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543222</th>\n",
       "      <td>1.395573e+09</td>\n",
       "      <td>PerdomoPilar</td>\n",
       "      <td>1.398728e+18</td>\n",
       "      <td>2021-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543230</th>\n",
       "      <td>1.395573e+09</td>\n",
       "      <td>PerdomoPilar</td>\n",
       "      <td>1.396171e+18</td>\n",
       "      <td>2021-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4543239</th>\n",
       "      <td>1.395573e+09</td>\n",
       "      <td>PerdomoPilar</td>\n",
       "      <td>1.390037e+18</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811479 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Author ID     Author Name      Tweet ID        Date\n",
       "137      7.778842e+07      JavierDMC_  1.393037e+18  2021-05-13\n",
       "161      7.778842e+07      JavierDMC_  1.388348e+18  2021-04-30\n",
       "168      1.211572e+08       andresmpn  1.395863e+18  2021-05-21\n",
       "182      1.211572e+08       andresmpn  1.391517e+18  2021-05-09\n",
       "192      7.608689e+17  DANILO25031974  1.404770e+18  2021-06-15\n",
       "...               ...             ...           ...         ...\n",
       "4543182  2.562833e+08        MJVGaray  1.401578e+18  2021-06-06\n",
       "4543190  2.562833e+08        MJVGaray  1.390106e+18  2021-05-05\n",
       "4543222  1.395573e+09    PerdomoPilar  1.398728e+18  2021-05-29\n",
       "4543230  1.395573e+09    PerdomoPilar  1.396171e+18  2021-05-22\n",
       "4543239  1.395573e+09    PerdomoPilar  1.390037e+18  2021-05-05\n",
       "\n",
       "[811479 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos por tweets duplicados\n",
    "# Esto puede pasar por que en la tabla original_retweets algunos de esos tweets retweeteados estaban en base de datos\n",
    "# Al cominar las tabla original_tweets con original_retweets, estos saldr√°n duplicados\n",
    "original[original.duplicated(subset = 'Tweet ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 5,912,692 Retweets √∫nicos y 4,542,660 Tweets originales √∫nicos.\n",
      "De los 4,542,660 Tweets originales que tenemos, 811,479 fueron retweeteados y los tenemos en base de datos.\n"
     ]
    }
   ],
   "source": [
    "# Cuantos Tweets originales y retweets tenemos\n",
    "retweets_id = retweets['Referenced Tweet ID'].unique()\n",
    "original_tweets_id = original_tweets['Tweet ID'].unique()\n",
    "print(f\"Tenemos {len(retweets_id):,} Retweets √∫nicos y {len(original_tweets_id):,} Tweets originales √∫nicos.\")\n",
    "\n",
    "# De los retweets, cuantos de esos tenemos en su versi√≥n originales\n",
    "original_tweets_retweeted = set(retweets_id).intersection(set(original_tweets_id))\n",
    "print(f\"De los {len(original_tweets_id):,} Tweets originales que tenemos, {len(original_tweets_retweeted):,} fueron retweeteados y los tenemos en base de datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar DataFrames\n",
    "original.to_pickle(os.path.join(path, \"Tweets_DataFrames/original.gzip\"), compression = \"gzip\")\n",
    "original_retweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/original_retweets.gzip\"), compression = \"gzip\")\n",
    "original_tweets.to_pickle(os.path.join(path, \"Tweets_DataFrames/original_tweets.gzip\"), compression = \"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
