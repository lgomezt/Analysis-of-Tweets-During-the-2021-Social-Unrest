{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Construction: Network X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we construct the graph of the Rt's Users during the Paro Nacional. Each graph corresponds to the Rt Network in moving windows of three days between April 28 of 2021 and June 30 of 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/disk2/Data/Pickle/user_indices.pkl','rb') as file:\n",
    "    user_indices = pickle.load(file)\n",
    "\n",
    "with open('/mnt/disk2/Data/Pickle/user_to_party_paro.pkl','rb') as file:\n",
    "    user_to_party_paro = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from user_indices we transform the keys as values and the values as keys\n",
    "user_indices_2 = {value: key for key, value in user_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of the Paro Nacional\n",
    "v1_start = '2021-04-28 00:00:00'\n",
    "v1_end = '2021-06-27 00:00:00'\n",
    "date1 = pd.date_range(start = v1_start, end = v1_end, freq = 'D')\n",
    "\n",
    "v2_start = '2021-04-30 23:59:59'\n",
    "v2_end = '2021-06-29 23:59:59'\n",
    "date2 = pd.date_range(start = v2_start, end = v2_end, freq = 'D')\n",
    "datestr = list(date2.strftime(\"%d-%m\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After declaring our constructor function, we now proceed to create the loop over the adjcency matrices to create the graphs\n",
    "\n",
    "Because Graph_tool doesn't have permissions to access the directories and creeate the files in the folder, run this line of code in the Linus Terminal to run the This code Below.\n",
    "\n",
    "```\n",
    "sudo ~/.conda/envs/gt/bin/python \"/mnt/disk2/fcastrillon/Analysis-of-Tweets-During-the-2021-Social-Unrest/Code/utils/Graph Tool Saves.py\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "files = glob('/mnt/disk2/Data/Matrices/*.npz')\n",
    "for file in tqdm(files):\n",
    "    \n",
    "    # First, we load the stored info into a normal CSR matrix.\n",
    "    data = np.load(file)\n",
    "    indices = data['indices']\n",
    "    indptr = data['indptr']\n",
    "    shape = data['shape']\n",
    "    data = data['data']\n",
    "    A = csr_matrix((data, indices, indptr), shape = shape)\n",
    "    \n",
    "    # Now we can create the graph using 'graph_tool'.\n",
    "    idx = A.nonzero()\n",
    "    weights = A[idx]\n",
    "    g = gt.Graph(directed = False)\n",
    "    g.add_edge_list(np.transpose(idx))\n",
    "    ew = g.new_edge_property(\"double\")\n",
    "    ew.a = weights \n",
    "    g.ep['edge_weight'] = ew\n",
    "\n",
    "    date = date_list[k] # This gets the end of day date of every graph to store it.\n",
    "    date = datetime.strftime(date, '%d-%m-%Y')\n",
    "    \n",
    "    # Finally we save the graph in .graphml format.\n",
    "    filename = f'graph_{date}.graphml'\n",
    "    output_filepath = '/mnt/disk2/Data/Graphs_2/' + filename\n",
    "    print(output_filepath)\n",
    "    g.save(output_filepath)\n",
    "    print(f\"File '{filename}' successfully created and stored.\")\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [21:54, 21.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the graph files first. (24 minutes to load)\n",
    "files = glob('/mnt/disk2/Data/Graphs/*.graphml')\n",
    "    \n",
    "graph_list = []  # List to store the loaded graphs\n",
    "\n",
    "for i, file in tqdm(enumerate(files)):\n",
    "    graph_name = file[file.find('graph_'):file.find('.graph')].replace('-','_')\n",
    "    graph = nx.read_graphml(file)\n",
    "    graph_list.append(graph)\n",
    "    globals()[graph_name] = graph\n",
    "    \n",
    "del graph  \n",
    "del graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEPS TO LOAD DYNAMIC GRAPH IN GEPHI\n",
    "##### 1) Open Gephi\n",
    "##### 2) Import spreadsheet - nodes.csv\n",
    "##### 3) Import timeset as TimeStamp\n",
    "##### 4) Import spreadsheet - edges.csv\n",
    "##### 5) Import timeset as TimeStamp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
